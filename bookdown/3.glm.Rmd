# Linear and Generalised Linear Models {#glm}

## Linear Model (LM)

A linear model is one in which unknown parameters are multiplied by (functions of) observed variables and then added together to give a prediction for the response variable. As an example, lets take the results from a Swedish experiment from the sixties:

``` {r label=traffic, echo=TRUE, include=FALSE}
data(Traffic, package="MASS")
Traffic$year<-as.factor(Traffic$year)
Traffic[c(1,2,184),]
```

The experiment involved enforcing speed limits on Swedish roads on some days, but on other days letting everyone drive as fast as they liked. The response variable (`y`) is the number of accidents recorded. The experiment was conducted in 1961 and 1962 for 92 days in each year. As a first attempt we could specify the linear model:

``` r
y ~ limit + year + day
```

but what does this mean?

### Linear Predictors {#lm-sec}

The model formula defines a set of simultaneous (linear) equations

$$\begin{array}{cl}
E[y\texttt{[1]}] &=\beta_{1}+\beta_{2}(\texttt{limit[1]=="yes"})+\beta_{3}(\texttt{year[1]=="1962"})+\beta_{4}\texttt{day[1]}\\
E[y\texttt{[2]}] &= \beta_{1}+\beta_{2}(\texttt{limit[2]=="yes"})+\beta_{3}(\texttt{year[2]=="1962"})+\beta_{4}\texttt{day[2]}\\
\vdots&=\vdots\\
E[y\texttt{[184]}] &= \beta_{1}+\beta_{2}(\texttt{limit[184]=="yes"})+\beta_{3}(\texttt{year[184]=="1962"})+\beta_{4}\texttt{day[184]}\\
\end{array}
\label{SE-eq}   (\#eq:SE-eq)$$

where the $\beta$'s are the unknown coefficients to be estimated, and the variables in $\texttt{this font}$ are observed predictors. Continuous predictors such as `day` remain unchanged, but categorical predictors are expanded into a series of binary variables of the form '*do the data come from 1961, yes or no?*', '*do the data come from 1962, yes or no?*', and so on for as many years for which there are data.

It is cumbersome to write out the equation for each data point in this way, and a more compact way of representing the system of equations is

$$
E[{\bf y}] = {\bf X}{\boldsymbol{\mathbf{\beta}}}
(\#eq:lm)
$$

where ${\bf X}$ is called a design matrix and contains the predictor information for all observations, and ${\boldsymbol{\mathbf{\beta}}} = [\beta_{1}\ \beta_{2}\ \beta_{3}\ \beta_{4}]^{'}$ is the vector of parameters.  Here,  $E[{\bf y}]$ is a vector of the 184 expected values.

``` {r echo=TRUE}
X<-model.matrix(y~limit+year+day, data=Traffic)
X[c(1,2,184),]
```

The binary predictors *do the data come from 1961, yes or no?* and *there was no speed limit, yes or no?* do not appear. These are the first factor levels of `year` and `limit` respectively, and are absorbed into the global intercept ($\beta_{1}$) which is fitted by default in R. Hence the expected number of accidents for the four combinations (on day zero) are $\beta_{1}$ for 1961 with no speed limit, $\beta_{1}+\beta_{2}$ for 1961 with a speed limit, $\beta_{1}+\beta_{3}$ for 1962 with no speed limit and $\beta_{1}+\beta_{2}+\beta_{3}$ for 1962 with a speed limit.

The simultaneous equations defined by Equation \@ref(eq:lm) cannot be solved directly because we do not know the left-hand side - expected values of $y$. We only know the observed value, which we assume is distributed around the expected value with some error. In a normal linear model we assume that these errors (residuals) are normally distributed:

$${\bf y}-{\bf X}{\boldsymbol{\mathbf{\beta}}} = {\bf e} \sim N(0, \sigma^{2}_{e}{\bf I})$$

${\bf I}$ is a $184\times 184$ identity matrix. It has ones along the diagonal, and zeros in the off-diagonals. The zero off-diagonals imply that the residuals are uncorrelated, and the ones along the diagonal imply that they have the same variance ($\sigma^{2}_{e}$). Thinking about the distribution of residuals is less helpful when we move on to GLM's and so I prefer to think about the model in the form:


$${\bf y}\sim N({\bf X}{\boldsymbol{\mathbf{\beta}}}, \sigma^{2}_{e}{\bf I})$$

and say the response is *conditionally* normal, with the conditioning on the model (${\bf X}{\boldsymbol{\mathbf{\beta}}}$). It is important to note that this is different from saying the response is normal. If having a speed limit had a very strong effect the (marginal) distribution of the response may be bimodal and far from normal, and yet by including speed-limit as a predictor, conditional normality may be achieved.

We could use `MCMCglmm` to fit this model, but to connect better with what comes next, let's use `glm` to estimate ${\bf \beta}$ and $\sigma^{2}_{e}$ assuming that the number of accidents follow a conditional normal distribution (the `MCMCglmm` syntax is identical):

``` {r echo=TRUE}
m2a.1<-glm(y ~ limit + year + day, data=Traffic)
summary(m2a.1)
```

On day zero in 1961 in the absence of a speed limit we expect `r round(coef(m2a.1)["(Intercept)"],1)` accidents (the intercept). With a speed limit we expect `r round(abs(coef(m2a.1)["limityes"]),1)` fewer accidents and we can quite confidently reject the null-hypothesis of no effect - particularly if we were willing to use a one-tailed test, which seems reasonable. There are `r round(abs(coef(m2a.1)["year1962"]),1)` fewer accidents in 1962, although this could just be due to chance, and for every unit increase in $\texttt{day}$ the number of accidents is predicted to go up by `r round(coef(m2a.1)["day"],2)`. The $\texttt{day}$ variable is encoded as integers from 1 to 92 with the same $\texttt{day}$ in different years being comparable (for example, the same day of the week and roughly the same date). If $\texttt{day}$'s are evenly spaced throughout the year the $\texttt{day}$ effect is roughly the effect of increasing calender date by four (365/92) days. The estimate of the residual variance, $\sigma^2_e$, is the dispersion parameter (`r round(sigma(m2a.1)^2,1)`). 

Because the number of accidents are count data we might worry about the assumption of conditional normality, and indeed the residuals show the typical right skew:

``` {r label=hist-traffic, echo=TRUE, include=TRUE, fig.cap="Histogram of residuals from model `m2a.1` which assumed they followed a Normal distribution."}
hist(resid(m2a.1))
```

It's not extreme, and the conclusions probably won't change, but we could assume that the data follow some other distribution.

## Generalised Linear Model (GLM)

Generalised linear models extend the linear model to non-normal data. They are essentially the same as the linear model described above, except they differ in two aspects. First, it is not necessarily the mean response that is predicted, but some function of the mean response. This function is called the link function. For example, with a log link we are trying to predict the logged expectation:

$$\textrm{log}(E[{\bf y}]) = {\bf X}{\boldsymbol{\mathbf{\beta}}}$$

or alternatively

$$E[{\bf y}] = \textrm{exp}({\bf X}{\boldsymbol{\mathbf{\beta}}})$$

where $\textrm{exp}$ is the inverse of the log link function- exponentiating. The second difference is that many distributions are single parameter distributions for which a variance does not need to be estimated because it can be inferred from the mean. For example, we could assume that the number of accidents are Poisson distributed, in which case we also make the assumption that the variance is equal to the expected value. Technically, GLM's only apply to a restricted set of distributions (those in the exponential family) but $\texttt{MCMCglmm}$ can accommodate a range of GLM-like models for other distributions (see Table \@ref(tab:dist)). 

### Poisson GLM

For now we will concentrate on a Poisson GLM with log link (the default link function for the Poisson distribution):

``` {r echo=TRUE}
m2a.2<-glm(y ~ limit + year + day, family=poisson, data=Traffic)
summary(m2a.2)
```

While the sign of the effects are comparable to that seen in the linear model, their numerical values are completely different and the significance of all effects has increased dramatically. Should we worry? The model is defined on the log scale and so to get back to the data scale we need to exponentiate. Exponentiating the intercept gives us the predicted number of accidents on day zero in 1961 without a speed limit:

``` {r echo=TRUE}
exp(m2a.2$coef["(Intercept)"])
```

which is very close to the intercept in the linear model (`r round(m2a.1$coef["(Intercept)"], 3)`), which is reassuring. 

To get the prediction for the same day with a speed limit we need to add the $\texttt{limityes}$ coefficient

``` {r echo=TRUE}
exp(m2a.2$coef["(Intercept)"]+m2a.2$coef["limityes"])
```

With a speed limit there are expected to be `r formatC(exp(m2a.2$coef["(Intercept)"]+m2a.2$coef["limityes"])/exp(m2a.2$coef["(Intercept)"]), format="f", 3)` as many accidents than if there was no speed limit. This value can be more directly obtained:

``` {r echo=TRUE}
exp(m2a.2$coef["limityes"])
```

and holds true for any given day in either year. The proportional change is identical because the model is *linear* on the log scale and $exp(\beta+\dots)=exp(\beta)exp(\dots)$. There is not always a direct relationship with the corresponding coefficients from the linear model but we can reassure ourselves that the parameters have the same qualitative meaning. For example, for $\texttt{day}$ 0 in 1961 the linear model predicts a drop from `r round(m2a.1$coef["(Intercept)"],1)` to `r round(m2a.1$coef["(Intercept)"]+m2a.1$coef["limityes"],1)` accidents when a speed limit is in place - around  `r round(1+m2a.1$coef["limityes"]/m2a.1$coef["(Intercept)"],2)` as many accidents, comparable to that predicted in the log-linear model.    

So in terms of the reported coefficients, the linear model and the Poisson log-linear model are roughly consistent with each other. However, in terms of accurately quantifying the uncertainty in those coefficients the Poisson model has a serious problem - it is very over confident.

## Overdispersion

Most count data do not conform to a Poisson distribution because the variance in the response exceeds the expectation.  In the summary to `m2a.2` the ratio of the residual deviance to the residual degrees of freedom is `r formatC(m2a.2$deviance/m2a.2$df.residual, format="f",3)` which means, roughly speaking, there is `r formatC(m2a.2$deviance/m2a.2$df.residual, format="f",1)` times more variation in our response (after conditioning on the model) than what we expect. This is known as overdispersion and it is easy to see how it arises, and why it is so common. 

If the predictor data had not been available to us then the only model we could have fitted was one with just an intercept:

``` {r echo=TRUE}
m2a.3<-glm(y ~ 1, data=Traffic, family="poisson")
summary(m2a.3)
```

for which the residual variance exceeds that expected by a factor of `r formatC(m2a.3$deviance/m2a.2$df.residual, format="f",1)`. Of course, the variability in the residuals must go up if there are factors that influence the number of accidents, but which we hadn't measured. It's likely that in most studies there are things that influence the response that haven't been measured, and even if each thing has a small effect individually, in aggregate they can cause substantial overdispersion.

### Multiplicative Overdispersion

There are two ways of dealing with overdispersion. With `glm` the distribution name can be prefixed with `quasi` and a dispersion parameter estimated:

``` {r echo=TRUE}
m2a.4<-glm(y ~ limit + year + day, family=quasipoisson, data=Traffic)
summary(m2a.4)
```

`glm` uses a multiplicative model of overdispersion and so the estimate of the dispersion parameter is roughly equivalent to how many times greater the variance is than expected, after taking into account the predictor variables. You will notice that although the parameter estimates have changed very little, the standard errors have gone up and the significance gone down. Overdispersion, if not dealt with, can result in extreme anti-conservatism. For example, the second lowest number of accidents (8) occurred on $\texttt{day}$ 91 of 1961 without a speed limit. Our model predicts this should have been the second worst day for accidents over the whole two years, and the probability of observing 8 or less accidents on this day is predicted to be approximately 3 in a 100,000:

``` {r echo=TRUE}
ppois(8, exp(m2a.2$coef["(Intercept)"]+91*m2a.2$coef["day"]))
```

If we did not accommodate the overdispersion, anything additional we put in in the model that could potentially explain such an improbable occurrence would come out as significant even if in reality it wasn't important. This is because there simply isn't any flexibility in the null model to accommodate such occurrences.  For example, if the extreme value happened to be associated with a particular level of a categorical predictor or happened to be associated with an extreme value of some continuous predictor, then the coefficients associated with these predictors may well come out as significant. However, under a more plausible null model the extreme observations may not be too surprising and there may be little support for the predictors having an effect on the response. A more plausible model, and one that we've alluded to, would be to allow the \emph{expected} number of accidents to vary across sampling points due to unmeasured variables. This would allow the variation in the number of \emph{observed} accidents to exceed the predicted mean based on the measured variables (the assumption of the standard Poisson). 

### Additive Overdispersion {#addod-sec}

I believe that a model assuming all relevant variables have been measured or controlled for, should **not** be the default model, and so when you specify `family=poisson` in $\texttt{MCMCglmm}$, overdispersion is always dealt with[^3.1]. However, $\texttt{MCMCglmm}$ does not use a multiplicative model, but an additive model.


``` {r m2a.5}
prior<-list(R=list(V=1, nu=0.002))
m2a.5<-MCMCglmm(y ~ limit + year + day, family="poisson", data=Traffic, prior=prior, pl=TRUE)
```

The element `Sol` contains the posterior distribution of the coefficients of the linear model, and we can plot their marginal distributions:

``` {r label=mcmc-traffic, echo=FALSE, include=TRUE, fig.width=7, fig.height=10,  fig.cap="MCMC summary plot for the coefficients from a Poisson glm (model `m2a.5`)."}
plot(m2a.5$Sol)
```

Note that the posterior distribution for the `year1962` spans zero, in agreement with the quasipoisson `glm` model, and that in general the estimates for the two models (and their uncertainty - see Section \@ref(intervals-sec)) are broadly similar:

``` {r }
summary(m2a.4)
```

With additive overdispersion the linear predictor includes a 'residual', for which a residual variance is estimated (hence our prior specification).

$$E[{\bf y}] = \textrm{exp}({\bf X}{\boldsymbol{\mathbf{\beta}}}+{\bf e})$$

At this point it will be handy to represent the linear model in a new way:

$${\bf l} = {\boldsymbol{\mathbf{\eta}}}+{\bf e}$$

where ${\bf l}$ is a vector of latent variables ($\textrm{log}(E[{\bf y}])$ in this case) and ${\boldsymbol{\mathbf{\eta}}}$ is the usual symbol for the linear predictor (${\bf X}{\boldsymbol{\mathbf{\beta}}}$). The data we observe are assumed to be Poisson variables with expectation equal to the exponentiated latent variables:

$${\bf y} \sim Pois(\textrm{exp}({\bf l}))$$

Note that the latent variable does not exactly predict $y$, as it would if the data were Normal, because there is additional variability in the Poisson process[^3.2]. In the call to $\texttt{MCMCglmm}$ I specified `pl=TRUE` to indicate that I wanted to store the posterior distributions of the latent variables (also known as the liabilities). This is not usually necessary and can require a lot of memory (we have 1000 posterior samples for each of the 182 data points). However, as an example we can obtain the posterior mean residual for data point 92 which is the data from $\texttt{day}$ 92 in 1961 when there was no speed limit:

``` {r echo=TRUE}
lat92<-m2a.5$Liab[,92]
# posterior distribution of the 92nd latent variable (liability)

eta92<-m2a.5$Sol[,"(Intercept)"]+m2a.5$Sol[,"day"]*Traffic$day[92]
# posterior distribution of X\beta for the 92nd observation

resid92<-lat92-eta92
# posterior distribution of e for the 92nd observation

mean(resid92)
# posterior mean of e for the 92nd observation
```

This particular observation has a negative expected residual indicating that the probability of getting injured was less than expected for this *particular* realisation of that $\texttt{day}$ in that year without a speed limit. If that combination of predictors ($\texttt{day}$=92, $\texttt{year}$=1961 and $\texttt{limit}$=$\texttt{no}$) could be repeated it does not necessarily mean that the actual number of accidents would always be less than expected, because it would follow a Poisson distribution with a mean equal to `exp(lat92)` (`r formatC(exp(mean(lat92)), format="f", 3)`). 

Like residuals in a standard linear model, the residuals are assumed to be independently and normally distributed with an expectation of zero and an estimated variance. If the residual variance was zero then ${\bf e}$ would be a vector of zeros and the model would conform to the standard Poisson GLM. However, the posterior distribution of the residual variance is located well away form zero:

```{r label=vcv-traffic, echo=TRUE, include=TRUE, fig.cap="MCMC summary plot for the residual (`units`) variance from a Poisson glm (model `m2a.5`). The residual variance models any overdispersion, and a residual variance of zero would imply that the response conforms to a standard Poisson."}
plot(m2a.5$VCV)
```

## Prediction in GLM

To get the expected number of accidents for the 92nd observation we simply exponentiated the latent variable: exp(`lat92`). However, it is important to realise that this is the expected number had the residual been exactly equal to the observed residual for that observation (`resid92`): we are calculating the expected number conditional on the set of unmeasured variables that affected that *particular* realisation of $\texttt{day}$ 92 in 1961 without a speed limit.  When calculating a prediction we usually aim to average over these residuals (or random effects - see \@ref(ranpred-sec)) since we would like to know what the average response would be for observations made on a $\texttt{day}$ of *type* 92 in 1961 without a speed limit. On the log-scale the expectation is simply the linear predictor ($\eta$):

$$
log(E_e[y]) = E_e[l] = E_e[\eta+e] =  \eta+E_e[e]=\eta
$$

since the residuals have zero expectation (here I have subscripted the expectation with the variable we are averaging over). The `predict` function can be applied to `MCMCglmm` objects and if we specify `type="terms"` we get the prediction of the link scale - the log scale in this case:

```{r }
predict(m2a.5, type="terms")[92]
```

which is equal to the posterior mean of `eta92` obtained earlier. We can see this visually in Figure \@ref(fig:prediction2) where I have plotted the distribution of the latent variable on a $\texttt{day}$ of type 92 in 1961 without a speed limit.

```{r pred-var, echo=FALSE}
resid.var<-mean(m2a.5$VCV)
intercept.coef<-mean(m2a.5$Sol[,"(Intercept)"])
day.coef<-mean(m2a.5$Sol[,"day"])
pos.ly<-seq(intercept.coef+day.coef*92-sqrt(resid.var), intercept.coef+day.coef*92+sqrt(resid.var), length=100)
d.ly<-dnorm(pos.ly,intercept.coef+day.coef*92, sqrt(resid.var))
d.y<-dlnorm(exp(pos.ly),intercept.coef+day.coef*92, sqrt(resid.var))
```

```{r label=prediction2, echo=FALSE, include=TRUE, fig.width=7, fig.height=5, eval.after = "fig.cap", fig.cap="The estimated distribution for the number of accidents on the log scale for a $\\texttt{day}$ of type 92 in 1961 without a speed limit (in red). On the log scale the distribution is assumed to be normal around the linear predictor ($\\eta=$) with a variance of $\\sigma^{2}_e$. As a consequence the mean, median and mode of the distribution are equal to the linear predictor on the log scale."}

plot(d.ly~pos.ly,type="l", col="red",, xlab="log(y)", ylab="Density", ylim=c(min(d.ly), max(d.ly)*1.1))
abline(v=intercept.coef+day.coef*92, col="black", lwd=2)
text(intercept.coef+day.coef*92, max(d.ly)*1.05,expression(paste(E[e], paste("[log(y)]=",eta))), pos=4)
```

To get the prediction on the data scale (i.e. in terms of the actual number of accidents) it is tempting to think we could just calculate `exp(eta92)`. However, this is the expected number of accidents had the residual been exactly zero. If we wish to average over the residuals we require:

$$
E_e[y] = E_e[\textrm{exp}(l)] = E_e[\textrm{exp}(\eta+e)]
$$


and because exponentiation is a non-linear function this average will deviate from $\textrm{exp}(\eta)$ (Figure \@ref(fig:prediction3). 

```{r label=prediction3, echo=FALSE, include=TRUE, fig.width=7, fig.height=5, eval.after = "fig.cap", fig.cap="The predicted distribution for the number of accidents on the data scale for a $\\texttt{day}$ of type 92 in 1961 without a speed limit (in red).  On the log scale the distribution is assumed to be normal around the linear predictor ($\\eta$) with a variance of $\\sigma^{2}_e$ (see \\@ref(fig:prediction2)). However when transforming to the data scale (by exponentiating) the symmetry is lost and the different measures of central tendency do not coincide. Since the residuals are normal on the log scale, the distribution on the data scale is log-normal and so analytical solutions exist for the mean, mode and median."}

plot(d.y~exp(pos.ly),type="l", col="red", xlab="y", ylab="Density", ylim=c(min(d.y), max(d.y)*1.1), xlim=c(min(exp(pos.ly))*0.95, max(exp(pos.ly))))
med<-exp(intercept.coef+day.coef*92)
mu<-exp(intercept.coef+day.coef*92+0.5*resid.var)
mod<-exp(intercept.coef+day.coef*92-resid.var)
abline(v=med, col="black", lwd=2)
text(med+2.23, max(d.y)*0.8,pos=2, expression(paste(MED[e], paste("[y] =  ",exp(eta)))))
abline(v=mu, lwd=1, lty=1)
text(mu, max(d.y)*0.6,expression(paste(E[e], paste("[y]=",exp(eta+scriptstyle(frac(1,2))*sigma[e]^2)))), pos=4)
abline(v=mod, lwd=1, lty=1)
text(mod, max(d.y)*1.05,expression(paste(MODE[e], paste("[y]=",exp(eta-sigma[e]^2)))), pos=2)
```

To obtain predictions on the data scale we can specify `type="response"` (the default) when using `predict`:

```{r }
predict(m2a.5)[92]
```

which is slightly greater than `exp(eta92)` (`r round(mean(exp(eta92)),3)`). For all link-functions, the median value on the data scale can be easily calculated by taking the inverse-link transform of the linear predictor. However, obtaining the mean and mode is often more challenging than it is for log-link, and numerical integration or approximations are required. 

The `predict` function is returning a single number for observation 92 yet the model object contains 1,000 samples from the posterior distribution of all model parameters. This is because the `predict` function returns the posterior mean of the predicted value. Since we have the complete posterior distribution we can also place a 95\% credible interval on the prediction (see Section \@ref(intervals-sec)):

```{r }
predict(m2a.5, interval="confidence")[92,]
```

### Posterior Predictive Distribution


```{r }
predict(m2a.5, interval="prediction")[92,]
```

When `interval="prediction"` `predict` is calling `simulate` with `nsim` set to the number of posterior samples saved: 

```{r }
ypred<-simulate(m2a.5)
```



## Bernoulli and Binomial GLM

Response variables consisting of levels of some categorical factor are best analysed using `family="categorical"` if the levels have no natural ordering, or `family="ordinal"` if the levels do have a natural ordering, such as never $<$ sometimes $<$ always. The simplest variable of this type is binary data where the response variable is either a zero or a one, and can be analysed as `family="categorical"` (logit link) or `family="ordinal"` (probit link). A binary distribution is a special case of the binomial distribution where the number of trials (`size`) is equal to 1. One way of interpreting a binomial response is to expand it into a series of binary variables and treat the zero's and ones as repeated measures. For example, we could generate two binomial variates each with 5 trials:

``` {r echo=TRUE}
success<-rbinom(2, size=5, prob=c(0.4, 0.6))
failure<-5-success
binom<-rbind(success, failure)
colnames(binom)<-c("u.1", "u.2")
binom
```

and then expand them into success or failure:

``` {r echo=TRUE}
binary<-matrix(rep(c(1,0,1,0), binom), 1,10)
colnames(binary)<-rep(c("u.1", "u.2"), each=5)
binary
```

We can then interpret the `units` variance in a binomial GLMM as accounting for any similarity between repeated measurements made within the same observational unit. If the binary variables within the binomial observation are correlated, this means that the underlying probability for each binomial response differs to a greater degree than can be predicted from the linear predictor. In this example the two probabilities were 0.4 and 0.6 which means that the repeated binary measures would be correlated if we only fitted the intercept (0.5).

If the original data are already binary then there is no information to measure how repeatable trials are within a binomial unit because we only have a single trial per observation. This does not necessarily mean that heterogeneity in the underlying probabilities does not exist, only that we can't estimate it. Imagine we are in a room of 100 people and we are told that 5% of the people will be dead the following day. If the people in the room were a random sample from the UK population I would worry - *I* probably have a 5% chance of dying. If on the other hand the room was a hospital ward and I was a visitor, I may not worry too much for *my* safety. The point is that in the absence of information, the binary data look the same if each person has a 5% chance of dying or if 5 people have a 100% chance of dying. Most programs set the residual variance to zero and assume the former, but it is important to understand that this is a convenient but arbitrary choice. Given this, it is desirable that any conclusions drawn from the model do not depend on this arbitrary choice. Worryingly, both the location effects (fixed and random) and variance components are completely dependent on the magnitude of the residual variance.

To demonstrate we will use some data from a pilot study on the Indian meal moth (*Plodia interpunctella*) and its granulosis virus (PiGV) collected by Hannah Tidbury & Mike Boots at the University of Sheffield.

``` {r echo=TRUE}
data(PlodiaRB)
```

The data are taken from 874 moth pupae for which the `Pupated` variable is zero if they failed to pupate (because they were infected with the virus) or one if they successfully pupated. The 874 individuals are spread across 49 full-sib families, with family sizes ranging from 6 to 38.

To start we will fix the residual variance at 1:

``` {r echo=TRUE, cache=TRUE}
prior.m2b.1=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0.002)))
m2b.1<-MCMCglmm(Pupated~1, random=~FSfamily, family="categorical", data=PlodiaRB, prior=prior.m2b.1)
```

and then fit a second model where the residual variance is fixed at 2:

``` {r echo=TRUE, cache=TRUE}
prior.m2b.2=list(R=list(V=2, fix=1), G=list(G1=list(V=1, nu=0.002)))
m2b.2<-MCMCglmm(Pupated~1, random=~FSfamily, family="categorical", data=PlodiaRB, prior=prior.m2b.2)
```

The posterior distribution for the intercept differs between the two models (see Figure \@ref(fig:Bin1)):

``` {r label=Bin1, echo=TRUE, include=TRUE, fig.cap="MCMC summary plots for the intercept of a binary GLMM where the residual variance was fixed at one (black) and two (red)."}
plot(mcmc.list(m2b.1$Sol,m2b.2$Sol))
```

as do the variance components (see Figure \@ref(fig:Bin2)):

``` {r label=Bin2, echo=TRUE, include=TRUE, fig.width=7, fig.height=5, fig.cap="MCMC summary plots for the between family variance component of a binary GLMM where the residual variance was fixed at one (black) and two (red)."}
plot(mcmc.list(m2b.1$VCV,m2b.2$VCV))
```

Should we worry? Not really. We just have to be careful about how we express the results. Stating that the family variance is `r formatC(posterior.mode(m2b.1$VCV[,1]), 3, format="f")` is meaningless without putting it in the context of the assumed residual variance. It is therefore more appropriate to report the intraclass correlation which in this context is the expected correlation between the state Pupated/Not Pupated, for members of the same family. It can be
calculated as:

$$\texttt{IC} =  \frac{\sigma^{2}_{\texttt{FSfamily}}}{\sigma^{2}_{\texttt{FSfamily}}+\sigma^{2}_{\texttt{units}}+\pi^{2}/3}$$

for the logit link, which is used when `family=categorical`, or

$$\texttt{IC} =  \frac{\sigma^{2}_{\texttt{FSfamily}}}{\sigma^{2}_{\texttt{FSfamily}}+\sigma^{2}_{\texttt{units}}+1}$$

for the probit link, which is used if `family=ordinal` was specified.

Obtaining the posterior distribution of the intra-class correlation for each model shows that they are sampling very similar posterior distributions (see Figure \@ref(fig:IC))

``` {r label=IC, echo=TRUE, include=TRUE, fig.cap="MCMC summary plots for the intra-family correlation from  a binary GLMM where the residual variance was fixed at one (black) and two (red).", fig.width=7, fig.height=5}
IC.1<-m2b.1$VCV[,1]/(rowSums(m2b.1$VCV)+pi^2/3)
IC.2<-m2b.2$VCV[,1]/(rowSums(m2b.2$VCV)+pi^2/3)
plot(mcmc.list(IC.1,IC.2))
```

Using the approximation due to @Diggle.2004 described earlier we can also rescale the estimates by the estimated residual variance ($\sigma^{2}_{\texttt{units}}$) in order to obtain the posterior distributions of the parameters under the assumption that the actual residual variance ($\sigma^{2}_{e}$) is equal to some other value. For location effects the posterior distribution needs to be multiplied by $\sqrt{\frac{1+c^{2}\sigma^{2}_{e}}{1+c^{2}\sigma^{2}_{\texttt{units}}}}$ and for the variance components the posterior distribution needs to be multiplied by $\frac{1+c^{2}\sigma^{2}_{e}}{1+c^{2}\sigma^{2}_{\texttt{units}}}$ where $c$ is some constant that depends on the link function. For the probit $c=1$ and for the logit $c=16\sqrt{3}/15\pi$. We can obtain estimates
under the assumption that $\sigma^{2}_{e}=0$:

``` {r label=ICI, echo=TRUE, include=TRUE, fig.cap="MCMC summary plots for the expected proportion of caterpillars pupating from  a binary GLMM where the residual variance was fixed at one (black) and two (red).", fig.width=7, fig.height=5}
c2 <- ((16 * sqrt(3))/(15 * pi))^2
Int.1 <- m2b.1$Sol/sqrt(1 + c2 * m2b.1$VCV[, 2])
Int.2 <- m2b.2$Sol/sqrt(1 + c2 * m2b.2$VCV[, 2])
plot(mcmc.list(as.mcmc(Int.1), as.mcmc(Int.2)))
```

The posteriors should be virtually identical under a flat prior (See Figure \@ref(fig:ICI)) although with different priors this is not always the case. Remarkably, @vanDyk.2001 show that leaving a diffuse prior on
$\sigma^{2}_{\texttt{units}}$ and rescaling the estimates each iteration, a Markov chain with superior mixing and convergence properties can be obtained (See section \@ref(parameter-expansion)).

It should also be noted that a diffuse prior on the logit scale is not necessarily weakly informative on the probability scale. For example, the default setting for the prior on the intercept is $N(0, 10^{8})$ on the logit scale, which although relatively flat across most of the probability scale, has a lot of density close to zero and one:

``` {r label=invlogit, echo=TRUE, include=TRUE, fig.cap="Histogram of 1000 random deviates from a normal distribution with a mean of zero and a large variance ($10^8$) after undergoing an inverse logit transformation."}
hist(plogis(rnorm(1000, 0, sqrt(1e+8))))
```

This diffuse prior can cause problems if there is complete (or near complete) separation. Generally this happens when the binary data associated with some level of a categorical predictor are all success or all failures. For example, imagine we had 50 binary observations from an experiment with two treatments, for the first treatment the probability of success is 0.5 but in the second it is only one in a thousand:

``` {r echo=TRUE}
treatment<-gl(2,25)
y<-rbinom(50,1,c(0.5, 0.001)[treatment])
data.bin<-data.frame(treatment=treatment, y=y)
table(data.bin)
```

if we analyse using `glm` we see some odd behaviour:

``` {r echo=TRUE}
m2c.1<-glm(y~treatment, data=data.bin, family="binomial")
summary(m2c.1)
```

the effect of treatment does not appear significant despite the large effect size. This is in direct contrast to an exact binomial test:

``` {r echo=TRUE}
m2c.2<-binom.test(table(data.bin)[2,2], 25)
m2c.2
```

where the 95% confidence interval for the probability of success is `r formatC(m2c.2$conf.int[1], 3, format="f")` to
`r formatC(m2c.2$conf.int[2], 3, format="f")`.

The default $\texttt{MCMCglmm}$ model also behaves oddly (see Figure \@ref(fig:separation1)):

``` {r echo=TRUE, eval=FALSE}
prior.m2c.3=list(R=list(V=1, fix=1))
m2c.3<-MCMCglmm(y~treatment, data=data.bin, family="categorical", prior=prior.m2c.3)
plot(m2c.3$Sol)
```

``` {r echo=FALSE, cache=TRUE}
prior.m2c.3=list(R=list(V=1, fix=1))
m2c.3<-MCMCglmm(y~treatment, data=data.bin, family="categorical", prior=prior.m2c.3)
```

``` {r label=separation1, echo=FALSE, include=TRUE, fig.cap="MCMC summary plots for the intercept and treatment effect in a binary GLM. In treatment 2 all 25 observations were failures and so the ML estimator on the probability scale is zero and $-\\infty$ on the logit scale. With a flat prior on the treatment effect the posterior distribution is improper, and with a diffuse prior (as used here) the posterior is dominated by the high prior densities at extreme values.", fig.width=7, fig.height=5}
plot(m2c.3$Sol)
```

For these types of problems, I usually remove the global intercept (`-1`) and use the prior $N(0, \sigma^{2}_{\texttt{units}}+\pi^2/3)$ because this is reasonably flat on the probability scale when a logit link is used. For example,

``` {r echo=TRUE, eval=FALSE}
prior.m2c.4=list(B=list(mu=c(0,0), V=diag(2)*(1+pi^2/3)), R=list(V=1, fix=1))
m2c.4<-MCMCglmm(y~treatment-1, data=data.bin, family="categorical", prior=prior.m2c.4)
plot(m2c.4$Sol)
```

looks a little better (see Figure \@ref(fig:separation1)), and the posterior distribution for the probability of success in treatment 2 is consistent with the exact binomial test for which the 95% CI were (`r formatC(m2c.2$conf.int[1], 3, format="f")` -`r formatC(m2c.2$conf.int[2], 3, format="f")`). With such a simple model, the prediction for observation 26 is equal to the treatment 2 effect and so we can get the the credible interval (on the data scale) for treatment 2 using the predict function:

``` {r echo=FALSE, cache=TRUE}
prior.m2c.4=list(B=list(mu=c(0,0), V=diag(2)*(pi^2/3+1)), R=list(V=1, fix=1))
m2c.4<-MCMCglmm(y~treatment-1, data=data.bin, family="categorical", prior=prior.m2c.4)
```

``` {r label=separation2, echo=FALSE, include=TRUE, fig.width=7, fig.height=5, fig.cap="MCMC summary plots for the intercept and treatment effect in a binary GLM. In treatment 2 all 25 observations were failures and so the ML estimator on the probability scale is zero and $-\\infty$ on the logit scale. A flat prior on the probability scale was used and the posterior distribution is better behaved than if a flat prior on the logit scale had been used (see Figure \\ref{separation1-fig})."}
plot(m2c.4$Sol)
```

``` {r echo=TRUE}
predict(m2c.4, interval = "confidence")[26, ]
```

[^3.1]: This is a bit disingenuous. The MCMC algorithm implemented in \texttt{MCMcglmm} depends on a non-zero residual variance to ensure mixing  -  if the residual variance was set to zero (i.e. no overdispersion in GLM(M)) then the Markov chain would be reducible.

[^3.2]: Since the residuals are assumed normal the exponentiated residuals are log-normal, and so this model is often referred to as the Poisson log-normal [@Hinde.1982]. The Negative Binomial distribution is a commonly used alternative for overdispersed count data. The Negative Binomial is conceptually identical to the Poisson log-normal except the exponentiated residuals are assumed to be gamma distributed. The log-normal and gamma distributions are so similar that for most data sets it would be hard to distinguish between the Negative Binomial and the Poisson log-normal.  


