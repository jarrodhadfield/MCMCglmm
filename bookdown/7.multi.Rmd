# Multi-response Models {#multi}

So far we have only fitted models to a single response variable, and even then, each response variable came from a distribution that only required one location parameter to be estimated, such as the mean of the Poisson or the probability of the binomial. In this section we will first cover multi-response models and then move on to models of multi-parameter distributions.

Since they are much less widely used than single-response models, let's start by motivating why anyone would want to use them.  Imagine we knew how much money 200 people had spent on their holiday and on their car in each of four years, and we want to know whether a relationship exists between the two. A simple correlation would be one possibility, but then how do we control for the repeated measures? An often used solution to this problem is to choose one variable as the response (lets say the amount spent on a car) and have the other variable as a predictor (the amount spent on a holiday) for which a fixed effect is estimated. The choice is essentially arbitrary, highlighting the belief that any relationship between the two types of spending maybe in part due to unmeasured variables, rather than being completely causal.

In practice does this matter? Let's imagine there was only one unmeasured variable: disposable income. There are repeatable differences between individuals in their disposable income, but also some variation within individuals across the four years. Likewise, people vary in what proportion of their disposable income they are willing to spend on a holiday versus a car, but this also changes from year to year. We can simulate some toy data to get a feel for the issues:

```{r echo=TRUE, tidy=FALSE}
id<-gl(200,4)   # 200 people recorded four times                      

av_wealth<-rlnorm(200, 0, 1)               
ac_wealth<-rlnorm(800, log(av_wealth[id]), 1/4) 
# expected disposable incomes + some year to year variation

av_ratio<-rbeta(200,10,10)                 
ac_ratio<-rbeta(800, 3*(av_ratio[id]), 3*(1-av_ratio[id])) 
# expected proportion spent on car + some year to year variation

y.car<-ac_wealth*ac_ratio      # disposable income * proportion spent on car
y.hol<-ac_wealth*(1-ac_ratio)  # disposable income * proportion spent on holiday                              

Spending<-data.frame(y.hol=log(y.hol), y.car=log(y.car), id=id)
```

A simple model suggests the two types of spending (on the log-scale) are positively related:

```{r }
mspending.1<-MCMCglmm(y.car~y.hol, data=Spending)
summary(mspending.1)
```

This conclusion seems to be supported by just looking at a scatter plot of the two variables (Figure \@ref(fig:spending)).

```{r spending, echo=FALSE, fig=TRUE, include=TRUE, fig.width=7, fig.height=5, fig.cap="Money spent on car versus money spent on holiday (both logged) with the regression line from a simple regression (model `mspending.1`)"}
plot(Spending$y.car~Spending$y.hol, ylab="Money spent on car (logged)", xlab="Money spent on holiday (logged)")
abline(mean(mspending.1$Sol[,1]), mean(mspending.1$Sol[,2]), lwd=2)
```

An obvious problem with the model is that we have repeated measures (the spending habits of each individual have been recorded for each of four years) and yet we haven't dealt with any possible non-independence. We can remedy this by fitting `id` effects as random:

```{r }
mspending.2<-MCMCglmm(y.car~y.hol, random=~id, data=Spending)
summary(mspending.2)
```

Strangely, and in contradiction to the scatter plot, the model suggests that spending more on a holiday means less is spent on a car  - the regression slope is negative. If I hadn't looked at the raw data, I would probably report the negative relationship and move on. But I have looked at the raw data and simply reporting a negative relationship without caveats makes me feel uneasy.

Lets proceed with a multi-response model of the problem to see what is going on. The two responses are passed as a matrix using `cbind()`, and the rows of this matrix are indexed by the reserved variable `units`, and the columns by the reserved variable `trait`. It is useful to think of a new data frame where the response variables have been stacked column-wise and the other predictors duplicated accordingly. Below is the original data frame on the left (`Spending`) and the stacked data frame on the right when `cbind(y.hol, y.car)` is passed as the response:

$$\begin{array}{cc}
\begin{array}{cccc}
&{\color{blue}{\texttt{y.hol}}}&{\color{blue}{\texttt{y.car}}}&\texttt{id}\\
{\color{red}{\texttt{1}}}&\texttt{`r formatC(Spending[,1][1],format="f", 6)`}&\texttt{`r formatC(Spending[,2][1],format="f", 6)`}&\texttt{`r Spending[,3][1]`}\\
{\color{red}{\texttt{2}}}&\texttt{`r formatC(Spending[,1][2],format="f", 6)`}&\texttt{`r formatC(Spending[,2][2],format="f", 6)`}&\texttt{`r Spending[,3][2]`}\\
\vdots&\vdots&\vdots\\
{\color{red}{\texttt{800}}}&\texttt{`r formatC(Spending[,1][800],format="f", 6)`}&\texttt{`r formatC(Spending[,2][800],format="f", 6)`}&\texttt{`r Spending[,3][800]`}\\
\end{array}&
\Longrightarrow
\begin{array}{ccccc}
&\texttt{y}&{\color{blue}{\texttt{trait}}}&\texttt{id}&{\color{red}{\texttt{units}}}\\
1&\texttt{`r formatC(Spending[,1][1],format="f", 6)`}&{\color{blue}{\texttt{y.hol}}}&\texttt{`r Spending[,3][1]`}&{\color{red}{\texttt{1}}}\\
2&\texttt{`r formatC(Spending[,1][2],format="f", 6)`}&{\color{blue}{\texttt{y.hol}}}&\texttt{`r Spending[,3][2]`}&{\color{red}{\texttt{2}}}\\
\vdots&\vdots&\vdots&\vdots\\
800&\texttt{`r formatC(Spending[,1][800],format="f", 6)`}&{\color{blue}{\texttt{y.hol}}}&\texttt{`r Spending[,3][800]`}&{\color{red}{\texttt{800}}}\\
801&\texttt{`r formatC(Spending[,2][1],format="f", 6)`}&{\color{blue}{\texttt{y.car}}}&\texttt{`r Spending[,3][1]`}&{\color{red}{\texttt{1}}}\\
802&\texttt{`r formatC(Spending[,2][2],format="f", 6)`}&{\color{blue}{\texttt{y.car}}}&\texttt{`r Spending[,3][2]`}&{\color{red}{\texttt{2}}}\\
\vdots&\vdots&\vdots&\vdots\\
1600&\texttt{`r formatC(Spending[,2][800],format="f", 6)`}&{\color{blue}{\texttt{y.car}}}&\texttt{`r Spending[,3][800]`}&{\color{red}{\texttt{800}}}\\
\end{array}
\end{array}
\label{multi-eq}   (\#eq:multi)$$


From this we can see that fitting a multi-response model is a direct extension to how we fitted models with categorical random interactions (Chapter \@ref(cat-int)):

```{r multi.1, echo=TRUE}
prior.mspending.3<-list(R=IW(1, 0.002),G=F(2,1000))

mspending.3<-MCMCglmm(cbind(y.hol, y.car)~trait-1, random=~us(trait):id, rcov=~us(trait):units, data=Spending, prior=prior.mspending.3, family=c("gaussian", "gaussian"))
```

The only real difference is that we must now specify the distribution for each response in $\texttt{family}$. While the interpretation of the model is identical to that covered in Chapter \@ref(cat-int), it does take a little time to get used to working with the new categorical factor, $\texttt{trait}$.

I have fitted a fixed $\texttt{trait}$ effect so that the two types of spending can have different intercepts. I usually suppress the global intercept (`-1`) for these types of models so the second coefficient is not the difference between the intercept for the first level of $\texttt{trait}$ (`y.hol`) and the second level (`y.car`) but the actual trait specific intercepts. Note that the levels of $\texttt{trait}$ are ordered as they appear in the response ($\texttt{y.hol}$ then $\texttt{y.car}$ in this instance). A $2\times2$ covariance matrix is estimated for the random term where the diagonal elements are the variance in consistent individual ($\texttt{id}$) effects for each type of spending. The off-diagonal is the covariance between these effects which if positive suggests that people that consistently spend more on their holidays consistently spend more on their cars. A $2\times2$ residual covariance matrix is also fitted. In Section\@ref(idh-sec) we fitted heterogeneous error models using `idh():units` which made sense for single-response models because each level of `unit` was specific to a particular observation and so any covariances could not be estimated. In multi-response models this is not the case because both traits have often been measured on the same observational unit and so the covariance can be measured. In the context of this example a positive covariance would indicate that in those years an individual spent a lot on their car they also spent a lot on their holiday. Let's take a look at the model summary:

```{r }
summary(mspending.3)
```

we can see that the between-individual covariance ($\texttt{traity.car:traity.hol.id}$) is strongly positive but the with-individual covariance ($\texttt{traity.car:traity.hol.unit}$) is strongly negative.

With a single predictors, a regression is defined as the covariance between the response and the predictor divided by the variance in the predictor[^multi-reg]. We can therefore obtain the coefficients of a regression of $\texttt{y.car}$ on $\texttt{y.hol}$ at the level of both $\texttt{id}$ and $\texttt{units}$[^ante-reg]: 

[^multi-reg]: If the model has >2 responses and you want to regress response $\texttt{i}$ effects on the remainder (i.e. a multiple regression), the coefficients can be obtained as `solve(V[-i,-i], V[i,-i])` where $\texttt{V}$ is the (co)variance matrix of effects. 

[^ante-reg]: We could also have parameterised the model directly as a regression using $\texttt{ante1(trait):id}$ $\texttt{ante1(trait):units}$ - see Section \@ref(ante-sec).

```{r }
id.regression<-mspending.3$VCV[,"traity.car:traity.hol.id"]
# covariance between individuals
id.regression<-id.regression/mspending.3$VCV[, "traity.hol:traity.hol.id"]
# regression across individual

units.regression<-mspending.3$VCV[,"traity.car:traity.hol.units"]
# covariance within individuals
units.regression<-units.regression/mspending.3$VCV[,"traity.hol:traity.hol.units"]
# regression within individuals
```

Conceptually, the regression at the level of $\texttt{id}$ is a regression of average expenditures across people, whereas the regression at the level of $\texttt{units}$ is a regression of yearly expenditures within individuals. We can compare these two regression with those that we got from the single response models that did (`mspending.2`) or did not (`mspending.1`) fit $\texttt{id}$ effects (Figure \@ref(fig:asUV)).

```{r label=asUV, echo=FALSE, include=TRUE, fig.cap="MCMC summary plot of the coefficient from a regression of car spending on holiday spending in black. The red and green traces are from a model where the regression coefficient is estimated at two levels: within an individual (blue) and across individuals (red). The relationship between the two types of spending is in part mediating by a third unmeasured variable, disposable income.", fig.width=7, fig.height=5}

muv1<-max(mspending.1$Sol[,"y.hol"])
muv2<-max(mspending.2$Sol[,"y.hol"])
mid<-max(id.regression)
mu<-min(units.regression)
plot(mcmc.list(mspending.1$Sol[,"y.hol"], mspending.2$Sol[,"y.hol"], id.regression,units.regression), density=FALSE, ylim=c(mu, mid), col=c("black", "black", "red", "blue"))
text(13000, muv1, "univariate regression (no id)", pos=2)
text(13000, muv2, "univariate regression (id)", pos=2)
text(13000, mid,  "id regression", pos=2, col="red")
text(13000, mu, "units regression", pos=2, col="blue")
```

The regression coefficients differ substantially at the within individual (blue) and between
individual (red) levels, and neither is entirely consistent with the regression coefficient from the single response models (black). The process by which we generated the data gives rise to this phenomenon - large variation between individuals in their disposable income means that people who are able to spend a lot on their holiday can also afford to spend a lot on their holidays (hence positive covariation between $\texttt{id}$ effects). However, a person that spent a large proportion of their disposable income in a particular year on a holiday, must have less to spend that year on a car (hence negative residual (within year) covariation).


When fitting the simpler single-response models we make the assumption that the effect of spending money on a holiday directly effects how much you spend on a car. If this relationship was purely causal then the regression coefficients at the level of $\texttt{id}$ and $\texttt{units}$ would have the same expectation, and the simpler model would be justified. For example, we could simulate data where the expected car expenditure depends directly on holiday expenditure (using a regression coefficient of -0.3) with some variation around this due to between and within-individual effects: 

```{r echo=TRUE, eval=TRUE}
Spending$y.car2<-Spending$y.hol*-0.3+rnorm(200,0,1)[Spending$id]+rnorm(800,0,sqrt(2))

```

We can fit the univariate and multivariate models to these data, and compare the regression coefficients as we did before. Figure \@ref(fig:MVvUV2) shows that the regression coefficients are all similar and a value of -0.3 has a reasonably high posterior probability. 

```{r echo=FALSE, eval=TRUE, cache=TRUE}
mspending.4<-MCMCglmm(y.car2~y.hol, random=~id, data=Spending)
mspending.5<-MCMCglmm(cbind(y.hol, y.car2)~trait-1, random=~us(trait):id, rcov=~us(trait):units, data=Spending, family=c("gaussian", "gaussian"))
```

```{r label=MVvUV2, echo=FALSE, include=TRUE, fig.cap="MCMC trace plot of the coefficient from a regression of car spending on holiday spending in black. The red and blue traces are from a model where the regression coefficient is estimated at two levels: within an individual (blue) and across individuals (red). In simulated data the relationship between the two types of spending is causal and the regression coefficients have the same expectation. However, the posterior standard deviation from the simple regression is smaller because information from the two different levels is pooled.", fig.width=7, fig.height=5}
md<-max(c(mspending.4$Sol[,2], mspending.5$VCV[,2]/mspending.5$VCV[,1],mspending.5$VCV[,6]/mspending.5$VCV[,5]))+0.075
mind<-min(c(mspending.4$Sol[,2], mspending.5$VCV[,2]/mspending.5$VCV[,1],mspending.5$VCV[,6]/mspending.5$VCV[,5]))
plot(mcmc.list(mspending.4$Sol[,2], mspending.5$VCV[,2]/mspending.5$VCV[,1],mspending.5$VCV[,6]/mspending.5$VCV[,5]), density=FALSE, ylim=c(mind, md), col=c("black", "red", "blue"))
text(13000, md, "Posterior Standard Deviation", pos=2)
text(13000, md-0.035, paste("univariate regression =", formatC(sd(mspending.4$Sol[,2]),format="f", 3)), pos=2)
text(13000, md-0.065, paste("id regression =", formatC(sd(mspending.5$VCV[,2]/mspending.5$VCV[,1]),format="f",3)), pos=2, col="red")
text(13000, md-0.095, paste("units regression =", formatC(sd(mspending.5$VCV[,6]/mspending.5$VCV[,5]),format="f",3)), pos=2, col="blue")
```

However, it should be noted that the posterior standard deviation is smaller in the simpler model because the more strict assumptions have allowed us to pool information across the two levels to get a more precise answer. This is one of the downsides of multi-response models - if the regressions at each level are the same we can get a more precise estimate using a standard single-response model. The other major benefit of the single-response model is that we only have to worry whether the conditional distribution of the response variable is modelled well ($\texttt{y.car}$ in this case) . In a multi-response model, we have to consider whether the model for the joint distribution of all responses is doing a good job.


## Multi-response Non-Gaussian Models

Model specification for multi-response models does not depend on whether the response variables are Gaussian or not. However, there is an important difference between models involving non-Gaussian variables and those involving only Gaussian variables. For Gaussian responses, the linear predictor is defined as

$$\boldsymbol{\eta} = E[{\bf y}|{\bf X}\boldsymbol{\beta}+{\bf Z}{\bf u}]$$  

and any observation-level deviations from this expectation appear as $\texttt{units}$ effects:

$${\bf e} = {\bf y}-\boldsymbol{\eta}$$  

For non-Gaussian data the linear predictor is defined

$$\boldsymbol{\eta} = E[{\bf l}|{\bf X}\boldsymbol{\beta}+{\bf Z}{\bf u}+{\bf e}]$$ 

where ${\bf l}$ is a vector of latent variables (Section \@ref(addod-sec)). Here the $\texttt{units}$ effects appear inside the linear predictor and model any overdispersion with respect to the named distribution. The 'residual' due to the named distribution is then

$${\bf y} -\textrm{link}^{-1}(\boldsymbol{\eta})$$

Consequently, with non-Gaussian data the covariances are set up in terms of the underlying parameters of the distribution (on the link scale) not in terms of the response directly. This is not always appropriate. Let's take the example of the Sweedish road accident data analysed in Chapter \@ref(glm). We saw that the number of accidents per day can be modelled using an overdispersed Poisson. Let's say we also had data on how much money car insurance companies paid out each day. A sensible way of modelling insurance pay-outs would to treat it as Gaussian and include the number of accidents as a covariate. However, if we analysed the accident and insurance pay-out data in a multi-response model, we would be measuring the covariance between insurance pay-outs and the *expected* number of accidents per day ($l$). Insurance companies don't pay settlements to hypothetical accidents but actual accidents ($\texttt{y}$) and so the multi-response model is questionable. In contrast, let's say we also had data on how icy the road was on each day. Here, I would be quite happy to say that iciness determines the *expected* number of accidents per day ($l$) but the actual number of accidents ($\texttt{y}$) will vary around this expectation. However, even here care still needs to be taken.

In Section \@ref(od-sec) we saw that overdispersion arises if there are unmeasured variables that affect the response of interest. If iciness ($\texttt{ice}$) was an important predictor of the number of accidents, then including it as a covariate in a single-response model of the number of accidents would bring the overdsipsersion, and hence $\sigma^2_\texttt{units}$, down.  In a multi-response model we can obtain the shift in the $\texttt{units}$ variance had we done this. The $\texttt{units}$ variance for road accidents ($\sigma^2_\texttt{traity.unit}$) would be equivalent to the units variance in a single-response model *without* iciness as a covariate. However, $\sigma^2_\texttt{traity.unit}-\sigma^2_\texttt{traity:traitice.unit}/\sigma^2_\texttt{traitice.unit}$ is equivalent to the units variance in the single-response model had iciness been fitted[^schur]. Let's call this $\sigma^2_\texttt{traity|ice.unit}$ since it is the $\texttt{units}$ variance in $\texttt{y}$ after conditioning on $\texttt{ice}$. If, in the single-response model, the number of accidents had become underdispersed when adding $\texttt{ice}$, the best estimate of $\sigma^2_\texttt{traity|ice.unit}$ is negative (Section \@ref(sec-underdispersion)). However, because covariance matrices are constrained to be positive-definite, $\sigma^2_\texttt{traity|ice.unit}$ is constrained to be positive and we would see that the estimate of $\sigma^2_\texttt{traity|ice.unit}$ is at the boundary (zero) and the residual correlation between the two responses ($\sigma_\texttt{traity:traitice.unit}/\sigma_\texttt{traity.unit}\sigma_\texttt{traitice.unit}$) is at 1 or -1[^pd]. In practice this rarely happens, but when it does I would argue that it arises because the number of accidents, $\texttt{y}$, is incompatible with a Poisson distribution and alternative distribution should be sought (Section \@ref(sec-underdispersion)). 


[^schur]: If we had an additional covariate, let's say $\texttt{rain}$, we can also obtain the $\texttt{units}$ variance had we fitted both  $\texttt{rain}$ and $\texttt{ice}$. Define ${\bf c}$ as the $2\times 1$ vector of residual covariances between road accidents and the weather variables and ${\bf V}$ as the  $2\times 2$ residual covariance matrix for the weather variables. Then $\sigma^2_\texttt{traity|weather.unit} = \sigma^2_\texttt{traity.unit}-{\bf c}^{\top}{\bf V}^{-1}{\bf c}$. 

[^pd]: For a $2\times 2$ covariance matrix, positive-definitness requires both variances to be positive and the correlation to lie between -1 and 1. For covariance matrices of larger dimension, the conditions for positive-definitness are more complicated. Perhaps the simplest definition is that all eigenvalues are positive. The function $\textttt{posterior.evals}$ returns the posterior distribution of the $k$ eigenvalues given the posterior samples of a $k$ dimensional covariance matrix (obtained for the appropriate $k^2$ columns of the $\texttt{VCV}$ element of the $\texttt{MCMCglmm}$ model object.) 

## Multi-response Bernoulli Models

As in single-response models, Bernoulli responses require some thought because the $\texttt{units}$ variance is not identifiable in the likelihood. However, the $\texttt{units}$ correlation between a Bernoulli response and other responses (including other Bernoulli responses) is identifiable. To explore multi-response Bernoulli models we will use longitudinal data collected on patients with primary biliary cirrhosis from the Mayo Clinic. The data are available from the $\texttt{survival}$ package 

```{r }
data(pbc)
head(pbcseq[,c("id", "age", "sex", "ascites", "bili", "hepato")])
```

The data consist of `r nrow(pbcseq)` records from `r length(unique(pbcseq$id))` patients ($\texttt{id}$). The age and sex of the patient were recorded and whether they suffered from ascites ($\texttt{ascites}$) and hepatomegaly or enlarged liver ($\texttt{hepato}$). The serum concentration of bilirunbin was also recorded ($\texttt{bili}$). We will consider two multi-response models. 

### Bernoulli-Gaussian {#bern-gaus-sec}

First, we will simultaneously model log($\texttt{bili}$) as Gaussian and $\texttt{ascites}$ as Bernoulli with threshold link (probit). As we will see, in multi-response models, modelling Bernoulli responses as $\texttt{family="threshold"}$ has some nice advantages. 


```{r pbc}
prior.pbc1<-list(R=list(V=diag(2),nu=1.002, fix=2), G=F(2,1000))

m.pbc1<-MCMCglmm(cbind(log(bili), ascites)~trait-1+trait:(age+sex), random=~us(trait):id, rcov=~us(trait):units, data=pbcseq, family=c("gaussian", "threshold"), prior=prior.pbc1, longer=10)
```

One difference from the previous model on car and holiday expenditure is that I've added some predictors to the fixed effect model. Interacting $\texttt{trait}$ with `age+sex` fits an $\texttt{age}$ effect for each trait and a $\texttt{sex}$ effect for each trait. If `age+sex` had not been interacted with $\texttt{trait}$ the effects of the predictors are assumed to be the same for the two traits. It is also possible to specify response-specific fixed-effect models using the function $\texttt{at.level}$.  For example, $\texttt{at.level(trait, 1):(age+sex)+at.level(trait, 2):(sex)}$ would fit an age and sex effect for $\texttt{trait}$ 1 (log($\texttt{bili}$)) and a sex effect for $\texttt{trait}$ 2 ($\texttt{ascites}$)[^at.level]. The main difference, however, from the previous model of two Gaussian responses is that `fix=2` has been added to the prior specification. For a $2\times 2$ covariance matrix this simply fixes the second variance (the $\texttt{units}$ variance for the Bernoulli trait, $\texttt{ascites}$) at whatever is specified in $\texttt{V}$ (1 in this case)[^3.4]. However, the $\texttt{units}$ variance for the Gaussian trait, and the $\texttt{units}$ covariance between the Gaussian and Bernoulii trait, are still estimated. 

[^at.level]: $\texttt{at.level}$ takes the name of categorical variable together with a vector of specified levels. It creates an $n\times k$ incidence matrix where $n$ is the length of the categorical variable and $k$ the number of specified levels. The matrix element $ij$ has a one if the categorical variable for observation $i$is of level $j$, and zero otherwise. When $\texttt{at.level}$ is used in a model formula, and interacted with other terms, it restricts those terms to only having effects when the observations are associated with the $k$ specified levels.  For example, imagine a categorical variable $\texttt{fac}$ with three levels $\texttt{a}$, $\texttt{b}$, and $\texttt{c}$ and a continuous variable $\texttt{x}$. $\texttt{at.level(fac, c("a", "c")):x}$ would fit two effects - an effect of $x$ when $\texttt{fac}=\texttt{a}$ and an effect of $x$ when $\texttt{fac}=\texttt{c}$. $\texttt{at.set}$ is similar although it creates an $n\times 1$ incidence matrix where element $i$ is one if the categorical variable for observation $i$ is *any* of the specified levels. The term $\texttt{at.set(fac, c("a", "c")):x}$ would then fit *one* effect - the effect of $x$ when $\texttt{fac}$ is equal to $\texttt{a}$ *or* $\texttt{c}$.


```{r }
summary(m.pbc1)
```

We can see that the covariance between the traits is strongly positive both across and within patients. Patients with constitutively high concentrations of bilirunbin are prone to ascites, and periods when a patient has high concentrations of bilirunbin they are more prone to ascites. Looking at the correlations can give a better feel for the magnitude of the associations. 

```{r pbc1-cor, echo=FALSE, include=TRUE, fig.cap="Posterior distributions for the correlations between log($\\texttt{bili}$) and the presence of ascites (on the latent scale).", fig.width=7, fig.height=5}

col_unit <- rgb(33, 113, 181, maxColorValue = 255, alpha = 120)  # blue,  ~47% opaque
col_id <- rgb(251, 106,  74, maxColorValue = 255, alpha = 120)  # red/orange

h1<-hist(c(posterior.cor(m.pbc1$VCV[,1:4])[,2],posterior.cor(m.pbc1$VCV[,1:4+4])[,2]), plot=FALSE, breaks=50)

hist(posterior.cor(m.pbc1$VCV[,1:4+4])[,2],
     breaks = h1$breaks,
     col    = col_unit,
     freq   =FALSE,
     xlab   = "Correlation",
     main   = "")


hist(posterior.cor(m.pbc1$VCV[,1:4])[,2],
     breaks = h1$breaks,
     col    = col_id,
     freq   =FALSE,
     xlab   = "Correlation",
     add    = TRUE)

     
legend("topright",
       legend = c("unit-level", "id-level"),
       fill   = c(col_unit, col_id),
       border = NA,
       bty    = "n")
```

In the model with two Gaussian responses we also thought about the association between the two traits in terms of regression. If we follow the same recipe for the Bernoulii response ($\texttt{ascites}$) regressed on the Gaussian response (log($\texttt{bili}$)) we end up with regression coefficients had we fitted log($\texttt{bili}$) as a predictor and also the true expected log($\texttt{bili}$) of each patient (which of course we don't know, but constitute the $\texttt{id}$ effects for that trait). The change in the risk of $\texttt{acites}$ when increasing a patient's log($\texttt{bili}$) by one unit is greater than the difference in risk between two patient's that on average differ in log($\texttt{bili}$) by one unit (Figure \@ref(fig:pbc1-reg)). 


```{r label=pbc1-reg, echo=FALSE, include=TRUE, fig.cap="MCMC trace plot of the coefficient from a probit regression of ascites presence ($\\texttt{ascites}$) on log serum concentration of bilirunbin ($\\texttt{bili}$). The red and blue traces are from a model where the regression coefficient is estimated at two levels: within an individual (blue) and across individuals (red).", fig.width=7, fig.height=5}

plot(mcmc.list(m.pbc1$VCV[,2]/m.pbc1$VCV[,1],m.pbc1$VCV[,6]/m.pbc1$VCV[,5]), density=FALSE, col=c("red", "blue"), ylab="Probit regression coefficient")
```


Note that this conclusion is opposite to the one you might draw from looking at the correlations. Why? The reason is that the proportion of variation that is within patients (Section \@ref(ICC)) is quite different for the two traits: for log($\texttt{bili}$) the posterior mean is `r round(mean(m.pbc1$VCV[,5]/(m.pbc1$VCV[,1]+m.pbc1$VCV[,5])),2)` and for $\texttt{acites}$ it is `r round(mean(m.pbc1$VCV[,8]/(m.pbc1$VCV[,4]+m.pbc1$VCV[,8])),2)`. The within-patient effects for log($\texttt{bili}$) have proportionally little variation yet they still strongly correlate with the within-patient $\texttt{acites}$ effects which have proportionally greater variation. We can also more formally assess whether the within-patient ($\texttt{units}$) regression is stronger than the between-patient regression:


```{r }
preg.id<-m.pbc1$VCV[,"traitbili:traitascites.id"]/m.pbc1$VCV[,"traitbili:traitbili.id"]
preg.units<-m.pbc1$VCV[,"traitbili:traitascites.units"]/m.pbc1$VCV[,"traitbili:traitbili.units"]
HPDinterval(preg.units-preg.id)
```

The 95% credible interval overlaps zero, just. 

If we consider the opposite regression -  the Gaussian response (log($\texttt{bili}$)) on the Bernoulii response ($\texttt{ascites}$) things aren't quite as straight forward. In a single response-model the actual presence or not of $\texttt{ascites}$ would be fitted, yet in the multi response-model the association is at the level of the latent variable. As noted above for car accidents and insurance payouts, there is an important distinction between measuring an association directly on the data scale versus the latent scale. However, when Bernoulli models are conceptualised in terms of threshold models we can make this distinction disappear.  If we designate the Gaussian response as $y$ and the Bernoulli response as $x$ (0 or 1) with associated latent variable $l$, we can calculate the two expectations 

$$E[y|x=1]=E[y | l>0]$$

and 

$$E[y|x=0]=E[y | l<0]$$

The difference between these expectations is the coefficient you would obtain by fitting the Bernoulli variable ($\texttt{ascites}$) as a predictor in a model for the Gaussian response (log($\texttt{bili}$)).  The difference is given by

$$E[y|x=1]-E[y|x=0]=\frac{f_N(\alpha)\sigma^2_{y,l}}{F_N(\alpha)(1-F_N(\alpha))\sigma_{l}}$$

where $f_N$ and $F_N$ are the density and cumulative density functions for the unit normal, and $\alpha = \mu_l/\sigma_{l}$[^condE]. 


[^condE]: Obtaining this expression is involved. We can express the expected value of $y$ given $l$ is less than, or greater than, some value $c$ using the law of total expectation

	$$E[y | l>c] = E[E[y|l] | l>c]$$

	and

	$$E[y | l<c] = E[E[y|l] | l<c]$$

	$E[y|l]$ is the mean of a conditional normal which has a well known form: $\mu_y+\frac{\sigma_{y,l}}{\sigma^2_{l}}(l-\mu_l)$. The expectation of this when $l>c$ is then $\mu_y+\frac{\sigma_{y,l}}{\sigma^2_{l}}(E[l|l>c]-\mu_l)$.  $E[l|l>c]$ can be obtained using the inverse Mills ratio:

	$$E[l|l>c] = \mu_l + \sigma_{l}\frac{f_N(\alpha)}{(1 - F_N(\alpha))}$$

	and when $l<c$ we have 

	$$E[l|l<c] = \mu_l - \sigma_{l}\frac{f_N(\alpha)}{F_N(\alpha)}$$

	where $f_N$ and $F_N$ are the density and cumulative density functions for the unit normal, and $\alpha = \mu_l/\sigma_{l}$. Code for obtaining $E[y | l>c]$ and $E[y | l>c]$ can be found <details><summary>here</summary>

	```{r condE}
	condE <- function(mu, V, c=0, greater=TRUE) {

  		# A bivariate normal with mean vector mu and covariance matrix V is assumed.
  		# condE give expectation of 1st variable given 2nd variable is > c (greater=TRUE) or < c (greater=FALSE)

  		if(nrow(V)!=ncol(V) | nrow(V)!=2){
			stop("V should be a 2x2 matrix")
  		}
  
  		if(length(mu)!=2){
    		stop("mu should be length 2")
  		}

  		alpha  <- (c - mu[2]) /sqrt(V[2,2])

  		if(greater){ 
  			lambda <- dnorm(alpha)/(1 - pnorm(alpha))
  			# inverse Mills ratio
  			expectation<- mu[2] + sqrt(V[2,2])*lambda
  		}else{
  			lambda <- dnorm(alpha)/pnorm(alpha)
  			expectation<- mu[2] - sqrt(V[2,2])*lambda 
  		}
  		# Expectation that E[l|l>0] or E[l|l<0]

  		expectation<-mu[1]+(expectation-mu[2])*V[1,2]/V[2,2]
  		# Expectation of x given l|l>0.

  		# The whole thing simplifies to 
  		# mu[1] \pm lambda*V[1,2]/sqrt(V[2,2])
  		# but easier to see the logic without the simplification

  		return(expectation)  
	}
	```
	</details><br> 

We can visualise what we have done. Figure \@ref(fig:biserial) plots the 95% prediction interval for the latent variable associated with $\texttt{ascites}$ presence (x-axis) and log($\texttt{bili}$) (y-axis) assuming the mean is at the central black point (this is the posterior mean prediction for the data). Conditioning on the posterior mean estimates of ${\bf V}_{\texttt{id}}$ and ${\bf V}_{\texttt{units}}$, the predictive distribution is multivariate normal with covariance matrix ${\bf V}_{\texttt{id}}+{\bf V}_{\texttt{units}}$ and so the 95% prediction interval is an ellipse. When the latent variable exceeds zero (vertical dashed line) the $y=1$ ($\texttt{ascites}$ is present). Consequently, the blue shaded area is the region of the predictive distribution for individuals with $\texttt{ascites}$ and the white region of the ellipse is for individuals without $\texttt{ascites}$. The expectation of $log(\texttt{bili})$ for these two groups are plotted as arrows. 


```{r biserial, echo=FALSE, include=TRUE, fig.cap="", fig.width=7, fig.height=5, fig.cap="Representation of a Gaussian ($log(\\texttt{bili})$) and Bernoulli ($\\texttt{ascites}$) multi-response model. The ellipse is the 95% prediction interval for the Gaussian trait and the Bernoulli latent variable (on the probit scale). Observations to the right of the threshold (vertical dashed line) are successes and have $\\texttt{ascites}$ and those to the left do not. The means of the Gaussian variable in these two groups are plotted as arrows."}

mu<-c(0,0)

mu[1]<-mean(predict(m.pbc1, type="terms")[1:nrow(pbcseq)])
mu[2]<-mean(predict(m.pbc1, type="terms")[nrow(pbcseq)+1:nrow(pbcseq)]) 

V<-matrix(colMeans(m.pbc1$VCV[,1:4]),2,2)+matrix(colMeans(m.pbc1$VCV[,4+1:4]),2,2)                        
                  
ell <- ellipse(V, centre = mu, level = 0.95, npoints = 361)


plot(ell[,2:1], type = "n", ylab = "log(bili)", xlab = "ascites", xlim=1.1*range(ell[,2]) , ylim=1.1*range(ell[,1]))

polygon(ell[,2:1], border = 1)                       
points(mu[2], mu[1], pch = 19)           
abline(v = 0, lty = 2) 
                  
polygon(ell[which(ell[,2]>=0),2], ell[which(ell[,2]>=0),1],             
        col    = rgb(0.2, 0.6, 0.8, 0.40),   
        border = NA)

arrows(x0=0, y0=condE(mu, V, c=0, greater=TRUE), x1 = 1.1*min(ell[,2]), col=rgb(0.2, 0.6, 0.8, 0.40))
arrows(x0=0, y0=condE(mu, V, c=0, greater=FALSE), x1 = 1.1*min(ell[,2]))
```

We can also plot the MCMC trace of the difference, and we can see that the difference is large and certainly not zero.


```{r label=pbc1-reg2, echo=FALSE, include=TRUE, fig.cap="MCMC trace plot of the regression coefficient of log serum concentration of bilirunbin ($\\texttt{bili}$) on ascites presence ($\\texttt{ascites}$) as obtained from a multi-response model. ", fig.width=7, fig.height=5}
post.reg<-1:1000

for(i in 1:1000){

	mu<-tapply(m.pbc1$X%*%m.pbc1$Sol[i,],  m.pbc1$error.term, mean)

	V.id<-matrix(m.pbc1$VCV[i,1:4],2,2)
    V.units<-matrix(m.pbc1$VCV[i,1:4+4],2,2)

	post.reg[i]<-condE(mu=mu, V=V.id+V.units, c=0, greater=TRUE)-condE(mu=mu, V=V.id+V.units, 0, greater=FALSE)
}

plot(as.mcmc(post.reg))
```

### All Bernoulli

We can also consider a bivariate model of the two Bernoulli variables $\texttt{ascites}$ and $\texttt{hepato}$. The model set-up is almost identical, although we need to add the constraint that the residual variances of both traits are not identifiable in the likelihood but the residual correlation is: we need o restrict the residual covariance matrix to a residual correlation matrix. Replacing the $\texttt{us}$ variance structure with $\texttt{corg}$ achieves this. The prior specification only requires a degree-belief parameter $\texttt{nu}$ which results in a beta distribution for each correlation with shape and scale equal to $(\texttt{nu}-k+1)/2$. Since $k=2$, I set $\texttt{nu}=3$ which results in a flat prior for the correlation. Note that specifying the marginal prior `F(2,1000)` for the (co)variance matrix of $\texttt{id}$ effects also results in $\texttt{nu}=3$ (See Section \@ref(VCVprior-r-sec)). 

```{r }
prior.pbc2<-list(R=list(V=diag(2),nu=3), G=F(2,1000))

m.pbc2<-MCMCglmm(cbind(hepato, ascites)~trait-1+trait:(age+sex), random=~us(trait):id, rcov=~corg(trait):units, data=pbcseq, family=c("threshold", "threshold"), prior=prior.pbc2, longer=10)
```

On the latent scale we see a reasonably strong correlation between the two outcomes:

```{r }
summary(m.pbc2)
```

If we wish, we can also characterise the relationship in terms of a contingency table. The model defines a multivariate normal distribution of latent variables around the fixed-effect prediction, and the probability of falling in any of the four quadrants defined by the origin can be calculated. We can imagine a population of individuals all of which have the same expected latent variables (the weighted average of the male and female means at the average age, where the weights are the frequencies of males and females in the data frame): 

```{r }
mu<-c(0,0)
nobs<-nrow(pbcseq) # number of obseravtions

mu[1]<-mean(predict(m.pbc2, type="terms")[1:nobs])
# predicted mean for hepato latent variable

mu[2]<-mean(predict(m.pbc2, type="terms")[nobs+1:nobs])
# predicted mean for ascites latent variable
```

Around these means the latent variables for a particular individual at a particular time (as a vector are) ${\bf u}_i+{\bf e}_{ij}$. These vectors are a drawn from a multivariate normal with zero mean and (co)variance ${\bf V}_{\texttt{id}}+{\bf V}_{\texttt{units}}$:


```{r }
V<-matrix(colMeans(m.pbc2$VCV[,1:4]+m.pbc2$VCV[,4+1:4]),2,2)
# posterior mean covariance matrix
```  

Figure \@ref(fig:terachoric) gives a visual representation of this distribution, and the quadrants that correspond to different outcomes.


```{r terachoric, echo=FALSE, include=TRUE, fig.cap="", fig.width=7, fig.height=5, fig.cap="Representation of a bivariate Bernoulli model. The solid point  represents the means of the two Bernoulli latent variables and the ellipse is the 95% prediction interval for the latent variables. The pair of latent variable lie in one of the four quadrants corresponding to the observed outcome (white: hepato=0 and ascites=0, pink: 1/0, blue: 0/1 and purple: 1/1)."}
                                    
ell <- ellipse(V, centre = mu, level = 0.95, npoints = 361)

plot(ell[,2:1], type = "n", ylab = "hepato", xlab = "ascites", xlim=1.1*range(ell[,2]) , ylim=1.1*range(ell[,1]))

polygon(ell[,2:1], border = 1)                       
points(mu[2], mu[1], pch = 19)           
abline(v = 0, lty = 2) 
abline(h = 0, lty = 2)      

polygon(ell[which(ell[,2]>=0),2], ell[which(ell[,2]>=0),1],             
        col    = rgb(0.2, 0.6, 0.8, 0.40),   
        border = NA)

polygon(ell[which(ell[,1]>=0),2], ell[which(ell[,1]>=0),1],             
        col    = rgb(0.8, 0.6, 0.8, 0.40),   
        border = NA)
```

The raw contingency table for the data is: 

```{r }
prop.table(table(hepato=pbcseq$hepato, ascites=pbcseq$ascites))
```

The $\texttt{pmnorm}$ function in the package $\texttt{mnorm}$ calculates the cumulative density function for the multivariate normal, and we can use this to calculate the four probabilities. I've done this in a rather long winded way so that the code could be extended to ordinal data that falls into more than two categories (Section \@ref(ordinal-sec)):

```{r }
n<-2
m<-2
P<-matrix(NA, n, m)

thresh1<-c(-Inf, 0, Inf)
thresh2<-c(-Inf, 0, Inf)

for(i in 1:n){
	for(j in 1:m){
		lower<-c(thresh1[i], thresh2[j])
		upper<-c(thresh1[i+1], thresh2[j+1])
		P[i,j]<-mnorm::pmnorm(lower, upper, mean = mu, sigma = V)$prob
	}
}
```

We don't expect the predicted probabilities to perfectly match what is observed since the data are unbalanced (individuals vary in how many times they are observed) and individuals vary in their sex and age but our prediction is for a population of individuals that are in some way average. Nevertheless, the predicted probabilities are close:    

```{r }
P
```

## Wide versus Long Format

In the multi-response models we have fitted so far, all responses have been observed for every unit of observation. For example, there were no cases where a patient was assessed for $\texttt{ascites}$ but $\texttt{bili}$ was not measured. If there had been missing observations, these could have been recorded as $\texttt{NA}$ and $\texttt{MCMCglmm}$ will treat them as unknown observations to be sampled and averaged over. If the amount of missingness is low then this is generally not an issue. However, if there is a lot of missing data then updating the missing observations can be slow and result in poor mixing. In these cases it is usually best to store the data in long-format and remove the missing values [^missing]. When fitting multi-response models to long-format data it needs to be in a format shown in Equation \@ref(eq:multi). There needs to be two columns in the data-frame: $\texttt{family}$ specifying the distribution for each observation and $\texttt{trait}$ which has factors indexing the observation type. In such cases the $\texttt{family}$ argument to $\texttt{family}$ should be $\texttt{NULL}$.

In the next section we will fit a bivariate model to log($\texttt{bili}$) and the categorical variable $\texttt{status}$. $\texttt{status}$ has three levels indicating whether the final outcome for the patient was censored (0) had a liver transplant (1) or died (2). Let's reshape the data and add the necessary columns:

[^missing]: I should really have an na.option in the call to $\texttt{MCMCglmm}$ that simply ignores missing values in the wide-format. 


```{r tidy = FALSE}
pbcseq_long <- tidyr::pivot_longer(pbcseq,
  cols      = c(status, bili),
  values_to = "y",
  names_to = "trait",
  cols_vary = "slowest")
# merge status and bili columns into a single column: y
# trait is the column indicating if y belongs to status or bili

pbcseq_long$trait<-as.factor(pbcseq_long$trait)

pbcseq_long$family <- dplyr::recode(pbcseq_long$trait, bili = "gaussian", status = "threshold")
# family specifies the distribution type for the two sets of observations.
```  

## Covariances between random and residual terms ($\texttt{covu}$) {#covu-sec}

In the previous section we generated a long-format data-frame $\texttt{pbcseq_long}$ with the response variable $\texttt{y}$ being associated with two traits: $\texttt{status}$ with three levels and then the continuous variable $\texttt{bili}$. In reality, $\texttt{status}$ is not a repeat-measure trait, it is the final outcome (censored, transplant or dead) duplicated across all of the patients records. Consequently we should only retain a single record: 

```{r tidy=FALSE}
remove<-with(pbcseq_long, duplicated(id) & trait=="status")
# cols_vary = "slowest" in pivot_longer means status records are followed by bili
# Then, `remove` is TRUE for all status observations except the first for each id.

pbcseq_long<-pbcseq_long[-which(remove),]

# rows of data-frame for first patient
subset(pbcseq_long[,c("y", "trait", "family", "id")], id==1)
```

In addition lets log transform $\texttt{bili}$ and turn  $\texttt{status}$ into a 2-level outcome dead (1) or not (0):

```{r }
pbcseq_long <- pbcseq_long %>% mutate(y = if_else(trait == "bili", log(y),y))
pbcseq_long <- pbcseq_long %>% mutate(y = if_else(trait == "status", as.numeric(y == 2),y))
```

If we wish to model death and $\texttt{bili}$ simultaneously, the Bernoulli-Gaussian model covered in Section \@ref(bern-gaus-sec) seems appropriate. However, since we only have a single-record of $\texttt{status}$ for each patient, it doesn't make sense to fit $\texttt{id}$ effects for $\texttt{status}$ as they are not identifiable from the $\texttt{unit}$ effects (which themselves have non-identifiable variance because $\texttt{status}$ is Bernoulli). However, $\texttt{bili}$ is repeat-measure and so it does make sense to fit $\texttt{id}$ effects for this traits. In addition, allowing the $\texttt{id}$ effects for $\texttt{bili}$ to be correlated with the $\texttt{unit}$ effects of $\texttt{status}$ also seems reasonable - perhaps the long-term concentration of bilirunbin dictates whether a patient will live or not.  In Section \@ref(link-func-sec) we covered ways in which we could link two (or more) sets of random effects and estimate their covariance matrix. Here, we need to link a set of random effects with a set of residuals. $\texttt{MCMCglmm}$ allows the set of random effects appearing in the final random term of the `random` specification to be correlated with the set of residuals appearing in the first residual term of the `rcov` specification.  The linking is specified by adding a `covu=TRUE` to the prior specification for the first residual term. 

```{r covu, tidy=FALSE}
prior.pbc_long<-list(R=list(R1=list(V=diag(2),nu=3, covu=TRUE, fix=2), 
							R2=IW(1, 0.002)))

m.pbc_long<-MCMCglmm(y~trait-1+at.level(trait, "bili"):(age+sex)-1+at.level(trait, "status"):sex, 
     			random=~us(at.level(trait, "bili")):id, 
         		rcov=~us(at.level(trait, "status")):id+us(at.level(trait, "bili")):units, 
             	data=pbcseq_long, family=NULL, prior=prior.pbc_long)
```

The model specification requires a bit of unpacking. `trait-1` fits intercepts for both traits. `at.level(trait, "bili"):(age+sex)` fits an age effect and a sex effect to (log) $\texttt{bili}$ and `at.level(trait, "status"):sex` fits a sex effect for $\texttt{status}$. `random=~us(at.level(trait, "bili")):id` fits $\texttt{id}$ effects for $\texttt{bili}$. This works because `at.level(trait, "bili")` defines a vector of zero's (if $\texttt{trait}=\texttt{status}$) and one's (if $\texttt{trait}=\texttt{bili}$) for which random slopes are defined (see Chapter \@ref(cont-int)). Consequently, when $\texttt{trait}=\texttt{status}$ the model is $0\times u =0$ and when $\texttt{trait}=\texttt{bili}$ the model is $1\times u =u$, where $u$ is the $\texttt{id}$ effect.  Similarly, the first part of the residual specification `us(at.level(trait, "status")):id` defines a complementary set of residuals for $\texttt{status}$. This works because for $\texttt{status}$ there is only one observation per level of $\texttt{id}$ and so the specification satisfies the condition for a residual: the effect must be unique to an observation.  Using `us(at.level(trait, "status")):units` would also have satisfied this condition, but the levels in the residual specification need to correspond to those in the random term for them to be linked, hence $\texttt{id}$ was used rather than $\texttt{units}$. Finally, we have a second residual component that defines the residuals for $\texttt{bili}$: `us(at.level(trait, "bili")):units`. The prior for the first residual term ($\texttt{R1}$) contains the argument `covu=TRUE` indicating that covariances between the set of residuals and the set of random effects defined by the final random term are present. The prior for the resulting ($2\times 2$) covariance matrix is also specified here and the prior for the final random term (the only random term in this model) is omitted. Note that the variance structure is that specified by the residual term ($\texttt{us}$ in this instance). We have fixed the second variance in this covariance matrix to one, since these are the $\texttt{unit}$ effects for a Bernoulli trait and so the variance isn't identified. Using $\texttt{nu=3}$ places a flat prior on the correlation (Section \@ref(VCVprior-r-sec)) but the marginal prior for the variance of the $\texttt{id}$ effects on $\texttt{bili}$ is inverse-Wishart with $\texttt{V=1.5}$ and $\texttt{nu=2}$. Not ideal, but it is not possible to use parameter-expansion (Section \@ref(PXprior-sec)) with $\texttt{covu}$ structures.


```{r }
summary(m.pbc_long)
```

There is a strong positive association between the expected long-term value of (log) $\texttt{bili}$ and whether a patient dies before the end of the study. Figure \@ref(fig:covu-r) shows the posterior distribution for the correlation in $\texttt{id}$ effects.

```{r covu-r, echo=FALSE, include=TRUE, fig.cap="Posterior distribution of the correlation between patient effects on (log) $\\texttt{bili}$ and residual $\\texttt{status}$ (death) from model $\\texttt{m.pbc_long}$.", fig.width=7, fig.height=5}

hist(posterior.cor(m.pbc_long$VCV[,1:4])[,2], main="", freq=FALSE, xlab="Correlation")
```

A more usual way to fit this type of model is to use a single-response for death and simply fit the average of each patient's (log) $\texttt{bili}$ as a predictor.

```{r }
pbcseq_status<-subset(pbcseq_long, trait=="status")
pbcseq_status$mean.bili<-with(pbcseq, tapply(log(bili), id, mean))[pbcseq_status$id]

m.pbc_status<-MCMCglmm(y~mean.bili, data=pbcseq_status, family=NULL, prior=list(R=list(V=1, fix=1)))
```

In Figure \@ref(fig:mu-vs-sing) the regression coefficient from the multi-response model (in black) is compared to that from the single-response model (in red) and we can see that the multi-response model gives a regression coefficient that is greater in magnitude[^probit-rescale]. 

[^probit-rescale]: Obtaining comparable regression coefficients between the single and multi-response models is fairly involved. The reason for this is that the standard single-response probit model assumes a $\texttt{units}$ variance of one after conditioning on the predictors, yet the multiple-response model assumes a $\texttt{units}$ variance of one before conditioning on the predictors. Nevertheless, we can easily move between the two parameterisations. As detailed at the start of this Chapter and in the footnote[^schur], the  $\texttt{units} variance for death after conditioning on the $\texttt{id}$ effects for $log(\texttt{bili})$ is $V_{2|1}=V_{2,2}-V_{1,2}^2/V_{1,1}$ where ${\bf V}$ is the \texttt{id-units} covariance matrix.  As covered in Section \@ref(bernoulli-sec) and in footnote[^3.5] we can then rescale the regression coefficient from the multi-response model by $\sqrt{2/(1+V_{2|1})}$ to obtain the value we get if we could have set $V_{2|1}=1$ as in the single-response model.


```{r mu-vs-sing, echo=FALSE, include=TRUE, fig.cap="Posterior distributions for the probit regression of $\\texttt{status}$ (death) on a patient's (log) $\\texttt{bili}$ value. The black trace is obtained from a multi-response model and the predictor is the expected value of log $\\texttt{bili}$ for each patient, whereas the red trace is obtained from a single-response model and the predictor is the sample mean of log $\\texttt{bili}$ for each patient.", fig.width=7, fig.height=5}

multi.reg<-m.pbc_long$VCV[,2]/m.pbc_long$VCV[,1]
uni.reg<-m.pbc_status$Sol[,"mean.bili"]
# regression coefficients from multi and uni models.

V2.1.multi<-1-(m.pbc1$VCV[,2]^2)/m.pbc1$VCV[,2] 
V2.1.uni<-1
# conditional variances from multi and uni models.									

rescale<-sqrt((1+V2.1.uni)/(1+V2.1.multi))
# scaling factor to make multi.reg comparable to uni.reg 

multi.reg<-multi.reg*rescale

plot(mcmc.list(multi.reg,uni.reg), density=FALSE, ylab="Probit regression of death on log(bili)")
```

The reason for this pattern is that the coefficient in the single-response model is attenuated because of the measurement error in the expected (log) $\texttt{bili}$. If $r$ is the correlation between the true value of a predictor and its measured value, we expect the regression using measured values to be equal to the regression obtained from the true values multiplied by $r^2$ (see Chapter \@ref(measurement)).  However, the attenuation is small in this example because on average $\texttt{bili}$ has been measured `r round(mean(with(pbcseq, tapply(log(bili), id, length))))` times per patient and the within-patient variability is quite low - the intra-class correlation for log $\texttt{bili}$ from the multi-response model is `r round(mean(m.pbc_long$VCV[,1]/(m.pbc_long$VCV[,1]+m.pbc_long$VCV[,5])),2)`. Together the $r^2$ is predicted to be `r round(mean(m.pbc_long$VCV[,1]/(m.pbc_long$VCV[,1]+m.pbc_long$VCV[,5]/6)),2)` ($\sigma^2_\texttt{bili.id}/(\sigma^2_\texttt{bili.id}+\sigma^2_\texttt{bili.units}/6)$) - almost identical to the attenuation seen. In addition to dealing with the attenuation, the multi-response model also makes more efficient use of the data when the design is unbalanced (some patients only have a single measurement whereas others have up to `r round(max(with(pbcseq, tapply(log(bili), id, length))))`) and the posterior standard deviation of the regression coefficient is `r round(sd(multi.reg),2)` from the multi-response model but `r round(sd(uni.reg),2)` from the standard single response model. 

## Scaled linear predictors: $\texttt{theta_scale}$

In the previous sections of this Chapter we've often thought about multi-response models in terms of regression. In some cases, the regression coefficient was different at different levels. For example, in Section \@ref(bern-gaus-sec) the regression within patients differed from the regression across patients. In other cases, the regression coefficient was only fitted for specific levels.  For example, in Section \@ref(covu-sec) the regression was only fitted across patients not within. Although we parameterised the model in terms of unstructured covariance matrices ($\texttt{us}$) we could have fitted the same model parameterised in terms of regression coefficients and innovation variances using antedependence structures (see Section \@ref(ante-sec)). Sometimes, however, we would like a model where the regression is held constant across two or more levels but is allowed to be different (or zero) at others.  The $\texttt{theta_scale}$ argument in $\texttt{MCMCglmm}$ allows two sets of parameters to be fitted that differ by a common scaling factor. For example, we may have two vectors of random effects $\{{\bf u}_1 {\bf u}_2\}$ that appear in the linear predictor of one set of observations and would like to fit the effects $\{\theta_s{\bf u}_1 \theta_s{\bf u}_2\}$ for another set of observations. By fitting the first set of effects for one trait (the predictor) and the second set of effects to the other trait (the response) we can hold the regression constant ($\theta_s$) at the two levels defined by the random effects.

```{r }
#library(mlmRev)
#data(star)
```


## Multinomial Models

The previous sections of this chapter have covered multi-response models where each response comes from a single parameter distribution.  $\texttt{MCMCglmm}$ also allows some distributions that are multi-parameter such as the multinomial and a range of zero-flated distributions. The syntax for fitting these models is similar to that for multi-response models with $\texttt{trait}$ indexing the different parameters of the distribution and $\texttt{units}$ indexing the observation.

We will start with multinomial models where the response is the number of counts in two or more nominal categories. When the number of categories is two we have the binomial which was covered in Section \@ref(binom-sec). In binomial models we condition on the total number of counts (the size) and the model is parameterised in terms of the probability of success, with failure being the base-line category. In multinomial models we also condition on the total number of counts and model the probabilities of belonging to each category. However, as with the binomial, if we have $K$ categories we only need to model $K-1$ parameters: if we know $K-1$ probabilities the final probability is known since the sum of all probabilities must equal one. Consequently, we chose a base-line category to which the other categories are compared to. As with binomial models the number in each category can be passed as columns using cbind or, if the total number of counts is one, the response can be passed as a single vector of categories for each observation. In both cases a logit-link is used and the base-line category is either the category associated with the final column or the first factor level if a single column is passed as the response.   

[^multinomial]: As with the binomial, in versions <4.0 family="multinomial" was not an option. `family="categorical"` had to be used when a single column of outcomes was specified as the response and `family="multinomialK"` had to be used when $\texttt{K}$ columns of counts were specified. In multi-response models where additional traits are also fitted, "categorical" and "multinomialK" still need to be used.

To explore multinomial models we will analyse data collected by the Alaska Science Center on the prey items of seabirds breeding on Middleton Island in the Gulf of Alaska - [see here](https://www.sciencebase.gov/catalog/item/64134381d34eb496d1ce3c82). We will restrict ourselves to data obtained on the chicks of the wonderful Tufted Puffin:

```{r }
data(tufted_puffin)
head(tufted_puffin)
```

Each row corresponds to one of `r nrow(tufted_puffin)` samples with their collection year and month recorded.  The following four columns are the number of Capelin ($\texttt{Capelin}$), Pacific herring ($\texttt{Herring}$), Walleye pollock ($\texttt{Pollock}$) and Pacific sand lance ($\texttt{SandLance}$) in each sample. An additional 40 prey taxa were also recorded and their combined counts per sample are in the final column ($\texttt{Other}$). Figure \@ref(fig:tufted-num) plots the number of prey items for 150 random samples.


```{r tufted-num, echo=FALSE, include=TRUE, fig.cap="", fig.width=9, fig.height=5, fig.cap="Number of prey items of different types in 150 randomly selected samples from Tufted Puffin chicks. The tick-marks on the x-axis delimit samples taken in the same year."}

mean_prop<-colMeans(prop_counts)

tot_counts<-rowSums(tufted_puffin[,-c(1:2)])
prop_counts<-tufted_puffin[,-c(1:2)]/tot_counts

ranking<-rank(tufted_puffin$year*1.1+prop_counts[,"SandLance"], ties.method="random")
sample_save<-sample(1:nrow(tufted_puffin), 150)
sample_save<-sample_save[order(ranking[sample_save])]

tot_counts<-tot_counts[sample_save]
prop_counts<-prop_counts[sample_save,]

xmid <-barplot(t(tufted_puffin[sample_save,-c(1:2)]),  
        beside      = FALSE,        
        col         = rainbow(5),
        ylab        = "Counts",
        xlab        = "Sample", names.arg=rep("", 150), ylim=c(0,45))

years           <- tufted_puffin$year[sample_save] 
year_centres    <- tapply(xmid, years, mean)            
year_separators <- tapply(xmid, years, max) + 0.5     

axis(1, at = year_centres , labels = unique(years), tick = FALSE, line = 0.5)

axis(1,                                         
     at   = year_separators[-length(year_separators)],    
     labels = FALSE,
     tcl  = -0.6)                             

legend("top",                       
       legend = colnames(tufted_puffin)[-c(1:2)],
       fill   = rainbow(5),
       ncol   = 5) 
```

In terms of numbers, Capelin and the Pacific sand lance are the most common prey items, with 'Other' being the rarest

```{r }
colMeans(tufted_puffin[,-c(1:2)])
```

However, there is tremendous variation in the total number of prey items per sample and it looks as if those samples with many prey items are dominated by Capelin. The multinomial ignores (conditions on) the total number of prey items and essentially works with the proportions of each prey item, as shown in Figure \@ref(fig:tufted-prop). 


```{r tufted-prop, echo=FALSE, include=TRUE, fig.cap="", fig.width=9, fig.height=5, fig.cap="Proportion of prey items that are of each type in 150 randomly selected samples from Tufted Puffin chicks. The tick-marks on the x-axis delimit samples taken in the same year."}

xmid<-barplot(t(prop_counts),    
        beside      = FALSE,       
        col         = rainbow(5),
        ylab        = "Counts",
        xlab        = "Sample", names.arg=rep("", 150), ylim=c(0,1.1))

legend("top",                     
       legend = colnames(tufted_puffin)[-c(1:2)],
       fill   = rainbow(5),
       ncol   = 5) 

years           <- tufted_puffin$year[sample_save] 
year_centres    <- tapply(xmid, years, mean)            
year_separators <- tapply(xmid, years, max) + 0.5     

axis(1, at = year_centres , labels = unique(years), tick = FALSE, line = 0.5)

axis(1,                                         
     at   = year_separators[-length(year_separators)],    
     labels = FALSE,
     tcl  = -0.6)                             
```

Once we control for the total number of prey items we see that Capelin actually makes up the lowest proportion of the diet and Pacific sand lance dominates:

```{r }
total_counts<-rowSums(tufted_puffin[,-c(1:2)])
colMeans(tufted_puffin[,-c(1:2)]/total_counts)
```

It is also apparent from Figure \@ref(fig:tufted-prop) (and Figure \@ref(fig:tufted-num)) that samples from the same year seem to have very similar compositions. Although less obvious, it also looks like there will be overdispersion - even within years, samples seem to vary in composition more than you would expect from multinomial sampling alone. In Figure \@ref(fig:tufted-sim) I have sampled from the multinomial with the probabilities given above and the observed total number of prey items for each of the 150 samples. It is clear that the simulated data are much less structured than the real data.


```{r tufted-sim, echo=FALSE, include=TRUE, fig.cap="", fig.width=9, fig.height=5, fig.cap="Simulated proportion of prey items that are of each type assuming that the probability of a prey item is constant over the samples. The tick-marks on the x-axis delimit samples taken in the same year."}

sim_counts<-t(sapply(tot_counts, FUN=function(x){rmultinom(1, prob=mean_prop, size=x)}))

xmid<-barplot(t(sim_counts/tot_counts),    
        beside      = FALSE,       
        col         = rainbow(5),
        ylab        = "Counts",
        xlab        = "Sample", names.arg=rep("", 150), ylim=c(0,1.1))

legend("top",                     
       legend = colnames(tufted_puffin)[-c(1:2)],
       fill   = rainbow(5),
       ncol   = 5) 

years           <- tufted_puffin$year[sample_save] 
year_centres    <- tapply(xmid, years, mean)            
year_separators <- tapply(xmid, years, max) + 0.5     

axis(1, at = year_centres , labels = unique(years), tick = FALSE, line = 0.5)

axis(1,                                         
     at   = year_separators[-length(year_separators)],    
     labels = FALSE,
     tcl  = -0.6)                             


```

Let's fit a multinomial model to these data, using $\texttt{Other}$ as the base-line category. We will also fit fully unstructured, $4\times 4$, covariance matrices at the level of year and sample ($\texttt{unit}$): 

```{r m-tufted}
prior.tufted<-list(R=IW(1, 2), G=F(2,1000))
m.tufted<-MCMCglmm(cbind(Capelin, Herring, Pollock, SandLance, Other)~trait-1, data=tufted_puffin, random=~us(trait):year, rcov=~us(trait):units, family="multinomial", longer=20, prior=prior.tufted, pr=TRUE)
```

With two $4\times 4$ covariance matrices, the model summary is pretty overwhelming. To get a feel for the broad patterns, in Table \@ref(tab:puffin) I have summarised the two matrices in terms of correlations (off-diagonals) and variances (diagonals). The posterior means together with the 95% credible interval (in square brackets) are reported.

```{r echo=FALSE, results="asis"}

sum.post<-function(x, digits=2){paste0(formatC(round(mean(x),digits), digits=digits, format="f"), " [",formatC(round(HPDinterval(x)[1],digits), digits=digits, format="f"), "-", formatC(round(HPDinterval(x)[2],digits), digits=digits, format="f"), "]")}

V_year<-V_units<-matrix("", 4, 4)
for(i in 1:4){
	for(j in i:4){
		if(i==j){
			V_year[i,j]<-sum.post(m.tufted$VCV[,(i-1)*4+i])
			V_units[i,j]<-sum.post(m.tufted$VCV[,16+(i-1)*4+i])
		}else{
			V_year[i,j]<-sum.post(m.tufted$VCV[,(i-1)*4+j]/sqrt(m.tufted$VCV[,(i-1)*4+i]*m.tufted$VCV[,(j-1)*4+j]))
			V_units[i,j]<-sum.post(m.tufted$VCV[,16+(i-1)*4+j]/sqrt(m.tufted$VCV[,16+(i-1)*4+i]*m.tufted$VCV[,16+(j-1)*4+j]))
		}
	}		
}

V<-rbind(V_year, V_units)
rownames(V)<-rep(colnames(tufted_puffin)[3:6],2)
colnames(V)<-colnames(tufted_puffin)[3:6]

kable(V, "html", escape = FALSE, row.names = TRUE, caption = "Posterior mean and 95\\% credible intervals for the variances (diagonal) and correlations (off-diagonal) in year effects (top) and sample effects (bottom) from model $\\texttt{m.tufted}$", label="puffin") %>%
  pack_rows("${\\bf V}_\\texttt{year}$",  1, 4) %>%         
  pack_rows("${\\bf V}_\\texttt{units}$",  5, 8) %>%   
	column_spec(1, bold = TRUE) %>%
  kable_styling(full_width = FALSE, font_size=14)
```
<br>

There seems to be substantial variation, both between years and between samples for the linear predictors for each prey item. Although credible intervals are wide, it seems generally that between year variation exceeds the between sample variation.  Correlations between the linear predictors for different prey items have wide credible intervals, but in generally are fairly modest. The exception to this is between the $\texttt{Herring}$ and $\texttt{SandLance}$ predictors where the correlation is moderately positive particular at the level of samples ($\texttt{units}$).



```{r tufted-sim2, echo=FALSE, include=TRUE, fig.cap="", fig.width=9, fig.height=5, fig.cap="A posterior predictive simulation using model $\\texttt{m.tufted}$ for the proportion of prey items that are of each type in 150 randomly selected samples. The tick-marks on the x-axis delimit samples taken in the same year and samples within years have been sorted in increasing proportion of Pacific sand lance."}

sim_counts<-matrix(simulate(m.tufted, marginal=NULL), nrow(tufted_puffin), 4)[sample_save,]
sim_counts<-cbind(sim_counts, tot_counts-rowSums(sim_counts))

xmid<-barplot(t(sim_counts/tot_counts),    
        beside      = FALSE,       
        col         = rainbow(5),
        ylab        = "Counts",
        xlab        = "Sample", names.arg=rep("", 150), ylim=c(0,1.1))

legend("top",                     
       legend = colnames(tufted_puffin)[-c(1:2)],
       fill   = rainbow(5),
       ncol   = 5) 

years           <- tufted_puffin$year[sample_save] 
year_centres    <- tapply(xmid, years, mean)            
year_separators <- tapply(xmid, years, max) + 0.5     

axis(1, at = year_centres , labels = unique(years), tick = FALSE, line = 0.5)

axis(1,                                         
     at   = year_separators[-length(year_separators)],    
     labels = FALSE,
     tcl  = -0.6)                             


xmid<-barplot(t(prop_counts),    
        beside      = FALSE,       
        col         = rainbow(5),
        ylab        = "Counts",
        xlab        = "Sample", names.arg=rep("", 150), ylim=c(0,1.1))

legend("top",                     
       legend = colnames(tufted_puffin)[-c(1:2)],
       fill   = rainbow(5),
       ncol   = 5) 

years           <- tufted_puffin$year[sample_save] 
year_centres    <- tapply(xmid, years, mean)            
year_separators <- tapply(xmid, years, max) + 0.5     

axis(1, at = year_centres , labels = unique(years), tick = FALSE, line = 0.5)

axis(1,                                         
     at   = year_separators[-length(year_separators)],    
     labels = FALSE,
     tcl  = -0.6)                             



```

Multinomial models are difficult - both to fit and interpret. With $K=5$ categories we have $K-1=4$ latent variables (traits) that are the log-odds ratio of observing a particular prey item versus the base-line prey item, in this case $\texttt{Other}$. Abbreviating the prey types by their initial the latent variables for sample $i$ in year $j$ are

$$
\begin{array}{rcl}
l_{ij,\texttt{C}} =& \textrm{log}\left(\frac{Pr(\texttt{C}_{ij})}{Pr(\texttt{O}_{ij}}\right)&= \beta^{(0)}_\texttt{C}+u_{j, \texttt{C}}+e_{ij, \texttt{C}}\\
l_{ij,\texttt{H}} =& \textrm{log}\left(\frac{Pr(\texttt{H}_{ij})}{Pr(\texttt{O}_{ij})}\right)&= \beta^{(0)}_\texttt{H}+u_{j, \texttt{H}}+e_{ij, \texttt{H}}\\
l_{ij,\texttt{P}} =& \textrm{log}\left(\frac{Pr(\texttt{P}_{ij})}{Pr(\texttt{O}_{ij})}\right)&= \beta^{(0)}_\texttt{P}+u_{j, \texttt{P}}+e_{ij, \texttt{P}}\\
l_{ij,\texttt{S}} =& \textrm{log}\left(\frac{Pr(\texttt{S}_{ij})}{Pr(\texttt{O}_{ij}}\right)&= \beta^{(0)}_\texttt{S}+u_{j, \texttt{S}}+e_{ij, \texttt{S}}\\
\end{array}
$$

where the $\beta^{(0)}$ are trait-specific intercepts, the $u$ are trait-specific year effects and and the $e$ are trait-observation specific $\texttt{unit}$ effects that capture overdispersion.  

The difficulty, I think, is that the effects are comparisons with the base-line category, yet it is easy to forget this. For example, let's imagine that Capelin and Herring appear in the diet completely independently of each other and so knowing there are many Capelin in a particular year is not informative about the abundance of Herring. It might then be tempting to assume that two sets of year effects, $u_{\texttt{C}}$ and $u_{\texttt{H}}$ are uncorrelated. However, they may be correlated through their shared dependence on 'Other' prey items: 

$$
\begin{array}{rl}
Cov(l_{\texttt{C}}, l_{\texttt{H}}) =& Cov(\textrm{log}(Pr(\texttt{C}))-\textrm{log}(Pr(\texttt{O})), \textrm{log}(Pr(\texttt{H}))-\textrm{log}(Pr(\texttt{O})))\\
=& Cov(\textrm{log}(Pr(\texttt{C})), \textrm{log}(Pr(\texttt{H})))-Cov(\textrm{log}(Pr(\texttt{C})), \textrm{log}(Pr(\texttt{O})))\\
 &-Cov(\textrm{log}(Pr(\texttt{O})), \textrm{log}(Pr(\texttt{H})))+Var(\textrm{log}(Pr(\texttt{O})))\\
\end{array}
$$

Even if the (log) probabilities are uncorrelated between all pairs of prey items, the log-contrasts between pairs (the latent variables) are expected to be correlated. For example, if the probabilities of Capelin, Herring and Other are all uncorrelated the above equation simplifies to  

$$
Cov(l_{\texttt{C}}, l_{\texttt{H}}) =Var(\textrm{log}(Pr(\texttt{O})))\\
$$

and a non-zero covariance exists whenever there is variation in the probability of success in the base-line category. Similarly, if we look at the variability in a particular latent variable we have:

$$
\begin{array}{rl}
Var(l_{\texttt{C}})=&Var(\textrm{log}(Pr(\texttt{C}))-\textrm{log}(Pr(\texttt{O}))\\
=&Var(\textrm{log}(Pr(\texttt{C})))+Var(\textrm{log}(Pr(\texttt{O})))-2Cov(\textrm{log}(Pr(\texttt{C})), \textrm{log}(Pr(\texttt{O}))) \\
\end{array}
$$

which simplifies to

$$
Var(l_{\texttt{C}})=Var(\textrm{log}(Pr(\texttt{C})))+Var(\textrm{log}(Pr(\texttt{O})))
$$

when the probabilities of Capelin and Other are uncorrelated. When we fitted multi-response models previously we naturally assumed that a diagonal covariance matrix somehow represents a null - the two traits are independent of each other. However, the above results suggest that we may need to modify our null when thinking about multinomial models. If we think that the log probabilities have the same yearly variation for all categories, and categories are independent then our null for the covariance matrix of year effects would have $2\sigma^2_{u}$ along the diagonal and $\sigma^2_{u}$ on the off-diagonals. We can represent this as ${\bf V}_{\texttt{year}} = \sigma^2_{u}({\bf I}+{\bf J})$ where ${\bf I}$ and ${\bf J}$ are $4\times 4$ identity and unit matrices, respectively[^unit]. If we believe that the amount of yearly variation differs across categories, yet the categories remain independent then our null would be  ${\bf V}_{\texttt{year}} = {\bf D}+\sigma^2_{\texttt{O}}{\bf J}$ where ${\bf D}$ is a diagonal matrix with four variances to be estimated in addition to $\sigma^2_{\texttt{O}}$. 

[^unit]: An identity matrix has ones along the diagonal and zero's on the off-diagonals. A unit matrix is a matrix of all ones.



```{r m-tuftedb}
m.tuftedb<-MCMCglmm(cbind(Capelin, Herring, Pollock, SandLance, Other)~trait-1, data=tufted_puffin, random=~idv(1+trait):year, rcov=~us(trait):units, family="multinomial", longer=20, prior=prior.tufted, pr=TRUE)
```


```{r m-tuftedc}
m.tuftedc<-MCMCglmm(cbind(Capelin, Herring, Pollock, SandLance, Other)~trait-1, data=tufted_puffin, random=~idh(trait):year+year, rcov=~us(trait):units, family="multinomial", longer=20, prior=prior.tufted, pr=TRUE)
```



The two latent variables are indexed as `trait`, and the unit of observation ($i$) as `units`, as in multi-response models. As with binary models the residual variance is not identified, and can be set to any arbitrary value. For reasons that will become clearer later I like to work with the residual covariance matrix $\frac{1}{J}({\bf I}+{\bf J})$ where ${\bf I}$ and ${\bf J}$ are $J-1$ dimensional identity and unit matrices, respectively.

To start we will try a simple model with an intercept:

```{r }
data(SShorns)
Ctable<-table(SShorns$horn, SShorns$sex)
```

```{r }
IJ<-(1/3)*(diag(2)+matrix(1,2,2))
prior=list(R=list(V=IJ, fix=1))
m5c.1<-MCMCglmm(horn~trait-1, rcov=~us(trait):units, prior=prior, data=SShorns, family="categorical")
```

The posterior distribution for the intercepts is shown in Figure \@ref(fig:MN1), and the model
clearly needs to be run for longer (Figure \@ref(fig:MN1). However...

```{r label=MN1, echo=FALSE, include=TRUE, fig.cap="Posterior distribution of fixed effects from model `m5c.1`: a simple multinomial logit model with intercepts only}", fig.width=7, fig.height=8}
plot(m5c.1$Sol)
```

The problem can also be represented using the contrast matrix ${\bf \Delta}$ [@Bunch.1991]:

$${\boldsymbol{\mathbf{\Delta}}}=
\left[
\begin{array}{c c}
-1&-1\\
1&0\\
0&1\\
\end{array}
\right]$$

where the rows correspond to the factor levels (`normal`, `polled` and `scurred`) and the columns to the two latent variables. For example column one corresponds to $l_{i,\textrm{polled}}$ which on the log scale is
$Pr(\texttt{horn[i]}=\textrm{polled}) - Pr(\texttt{horn[i]}=\textrm{normal})$.

$$\textrm{exp}\left(({\boldsymbol{\mathbf{\Delta}}}{\boldsymbol{\mathbf{\Delta}}}^{'})^{-1}{\boldsymbol{\mathbf{\Delta}}}{\bf l}_{i}\right) \propto E\left[\begin{array}{c} Pr(\texttt{horn[i]}=\textrm{normal})\\ Pr(\texttt{horn[i]}=\textrm{polled})\\ Pr(\texttt{horn[i]}=\textrm{scurred}) \end{array} \right]$$

The residual and any random effect covariance matrices are for identifiability purposes estimated on the $J-1$ space with ${\boldsymbol{\mathbf{V}}}={\boldsymbol{\mathbf{\Delta}}}^{'}\tilde{\bf V}{\boldsymbol{\mathbf{\Delta}}}$ where $\tilde{\bf V}$ is the covariance matrix estimated on the $J-1$ space. To illustrate, we will rescale the intercepts as if the residual covariance matrix was zero (see Sections \@ref(pred-sec) and \@ref(cat-int)) and predict the expected
probability for each horn type:

```{r echo=TRUE}
Delta<-cbind(c(-1,1,0), c(-1,0,1))   
c2<-(16*sqrt(3)/(15*pi))^2   
D<-ginv(Delta%*%t(Delta))%*%Delta        
Int<-t(apply(m5c.1$Sol,1, function(x){D%*%(x/sqrt(1+c2*diag(IJ)))}))
summary(mcmc(exp(Int)/rowSums(exp(Int))))
```

which agrees well with those observed:

```{r echo=TRUE}
prop.table(rowSums(Ctable))
```

To test for the effects of sex specific expression we can also fit a model with a sex effect:

```{r echo=TRUE, cache=TRUE}
m5c.2<-MCMCglmm(horn~trait+sex-1, rcov=~us(trait):units, data=SShorns, family="categorical", prior=prior)
```

In this case we have not interacted sex with trait, and so we are estimating the difference between the sexes in their expression of normal and polled+scurred jointly. The posterior distribution is plotted in Figure \@ref(fig:MN2) and clearly shows that males are more likely to express the normal horn phenotype than females.

```{r label=MN2, echo=FALSE, include=TRUE, fig.cap="Posterior distribution of fixed effects from model `m5c.2` in which a main effect of sex was included", fig.width=7, fig.height=5}
plot(m5c.2$Sol)
```

A more general model would be to estimate separate probabilities for each cell, but the contingency table indicates that one cell (polled males) has zero counts which will cause extreme separation problems. We could choose to have a better prior for the fixed effects, that is close to being flat for the two-way (i.e. polled vs scurred, normal vs.scurred & polled vs. normal) marginal probabilities within each sex:

```{r echo=TRUE, cache=TRUE}
prior$B=list(mu=rep(0,4), V=kronecker(IJ,diag(2))*(1.7+pi^2/3))
m5c.3<-MCMCglmm(horn~at.level(sex,1):trait+at.level(sex,2):trait-1, rcov=~us(trait):units, data=SShorns, family="categorical", prior=prior)
```

The female specific probabilities appear reasonable:

```{r echo=TRUE}
Int<-t(apply(m5c.3$Sol[,1:2],1, function(x){D%*%(x/sqrt(1+c2*diag(IJ)))}))
summary(mcmc(exp(Int)/rowSums(exp(Int))))
```

compared to the observed frequencies:

```{r echo=TRUE}
prop.table(Ctable[,1])
```

as do the male probabilities:

```{r echo=TRUE}
Int<-t(apply(cbind(m5c.3$Sol[,3:4]),1, function(x){D%*%(x/sqrt(1+c2*diag(IJ)))}))
summary(mcmc(exp(Int)/rowSums(exp(Int))))
```

compared to the observed frequencies:

```{r echo=TRUE}
prop.table(Ctable[,2])
```

## Zero-inflated Models

Each datum in a zero-inflated model is associated with two latent variables. The first latent variable is associated with the named distribution and the second latent variable is associated with zero inflation. I'll work through a zero-inflated Poisson (ZIP) model to make things clearer. As the name suggests, a ZIP distribution is a Poisson distribution with extra zero's. The observed zeros are modelled as a mixture distribution of zero's originating form the Poisson process and zero's arising through zero-inflation. It is the probability (on the logit scale) that a zero is from the zero-inflation process that we aim to model with the second latent variable. The likelihood has the form:

$$\begin{array}{rl}
Pr(y=0) =& \texttt{plogis}(l_{2})+\texttt{plogis}(-l_{2})\ast \texttt{dpois}(0, \texttt{exp}(l_{1}))\\
Pr(y | y>0) =& \texttt{plogis}(-l_{2})\ast \texttt{dpois}(y, \texttt{exp}(l_{1}))\\
\end{array}$$

$\texttt{pscl}$ fits zero-inflated models very well through the `zeroinfl` function, and I strongly recommend using it if you do not want to fit random effects. To illustrate the syntax for fitting ZIP models in MCMCglmm I will take one of their examples:

```{r echo=TRUE}
data("bioChemists", package = "pscl")
head(bioChemists)
```

`art` is the response variable - the number of papers published by a Ph.D student - and the remaining variables are to be fitted as fixed effects. Naively, we may expect zero-inflation to be a problem given 30% of the data are zeros, and based on the global mean we only expect around 18%.

```{r echo=TRUE}
table(bioChemists$art==0)
ppois(0,mean(bioChemists$art))
```

As with binary models we do not observe any residual variance for the zero-inflated process, and in addition the residual covariance between the zero-inflation and the Poisson process cannot be estimated because both processes cannot be observed in a single data point. To deal with this I've fixed the residual variance for the zero-inflation at 1, and the covariance is set to zero using the idh structure. Setting `V=diag(2)` and `nu=0.002` we have the inverse-gamma prior with `shape=scale=0.001` for the residual component of the Poisson process which captures overdispersion:

```{r echo=TRUE, cache=TRUE}
prior.m5d.1=list(R=list(V=diag(2), nu=0.002, fix=2))
m5d.1<-MCMCglmm(art~trait-1+at.level(trait,1):fem + at.level(trait,1):mar + at.level(trait,1):kid5 + at.level(trait,1):phd + at.level(trait,1):ment, rcov=~idh(trait):units, data=bioChemists, prior=prior.m5d.1, family="zipoisson")
```

As is often the case the parameters of the zero-inflation model mixes poorly (See Figure \@ref(fig:ZIP) especially when compared to equivalent hurdle models (See Section \@ref(Hurdle)). Poor mixing is often associated with distributions that may *not* be zero-inflated but instead overdispersed.

```{r label=ZIP, echo=FALSE, include=TRUE, fig.cap="Posterior distribution of fixed effects from model `m5d.1` in which trait 1 ($\\texttt{art}$) is the Poisson process and trait 2 ($\\texttt{zi.art}$) is the zero-inflation.", fig.width=7, fig.height=8}
plot(m5d.1$Sol[,1:4])
```

The model would have to be run for (much) longer to say something concrete about the level of zero-inflation but my guess would be it's not a big issue, given the probability is probably quite small:

```{r echo=TRUE}
quantile(plogis(m5d.1$Sol[,2]/sqrt(1+c2)))
```

### Posterior predictive checks

Another useful check is to fit the standard Poisson model and use posterior predictive checks to see how many zero's you would expect under the simple model:

```{r echo=TRUE, cache=TRUE}
prior.m5d.2=list(R=list(V=diag(1), nu=0.002))
m5d.2<-MCMCglmm(art~fem + mar + kid5 + phd + ment, data=bioChemists, prior=prior.m5d.2, family="poisson", saveX=TRUE)

nz<-1:1000
oz<-sum(bioChemists$art==0)

for(i in 1:1000){
pred.l<-rnorm(915, (m5d.2$X%*%m5d.2$Sol[i,])@x, sqrt(m5d.2$VCV[i]))
nz[i]<-sum(rpois(915, exp(pred.l))==0)
}
```

Figure \@ref(fig:PPZIP) shows a histogram of the posterior predictive distribution of zero's (`nz`) from the model compared to the observed number of zeros (`oz`). The simpler model seems to be consistent with the data, suggesting that a ZIP model may not be required.

```{r label=PPZIP, echo=FALSE, include=TRUE, fig.cap="Posterior predictive distribution of zeros from model `m5d.2` with the observed number in red.", fig.width=7, fig.height=5}
hist(nz, breaks=30)
abline(v=oz, col="red", lwd=2)
```

## Hurdle Models {#Hurdle}

Hurdle models are very similar to zero-inflated models but they can be used to model zero-deflation as well as zero-inflation and seem to have much better mixing properties in $\texttt{MCMCglmm}$. As in ZIP models each datum
in the hurdle model is associated with two latent variables. However, whereas in a ZIP model the first latent variable is the mean parameter of a Poisson distribution the equivalent latent variable in the hurdle model is the mean parameter of a zero-truncated Possion distribution (i.e. a Poisson distribution without the zeros observed). In addition the second latent variable in a ZIP model is the probability that an observed zero is due to zero-inflation rather than the Poisson process. In hurdle models the second latent variable is simply the probability (on the logit scale) that the response variable is zero or not. The likelihood is:

$$\begin{array}{rl}
Pr(y=0) =& \texttt{plogis}(l_{2})\\
Pr(y | y>0) =& \texttt{plogis}(-l_{2})\ast \texttt{dpois}(y, \texttt{exp}(l_{1}))/(1-\texttt{ppois}(0, \texttt{exp}(l_{1})))\\
\end{array}$$

To illustrate, we will refit the ZIP model (`m5d.1`) as a hurdle-Poisson model.

```{r echo=TRUE, cache=TRUE}
m5d.3<-MCMCglmm(art~trait-1+at.level(trait,1):fem + at.level(trait,1):mar + at.level(trait,1):kid5 + at.level(trait,1):phd + at.level(trait,1):ment, rcov=~idh(trait):units, data=bioChemists, prior=prior.m5d.1, family="hupoisson")
```

Plotting the Markov chain for the equivalent parameters that were plotted for the ZIP model shows that the mixing properties are much better (compare Figure \@ref(fig:ZIP) with Figure \@ref(fig:HU)).

```{r label=HU, echo=FALSE, include=TRUE, fig.cap="Posterior distribution of fixed effects from model `m5d.3` in which trait 1 ($\\texttt{art}$) is the zero-truncated Poisson process and trait 2 ($\\texttt{hu.art}$) is the binary trait zero or non-zero.", fig.width=7, fig.height=8}
plot(m5d.3$Sol[,1:4])
```

The interpretation of the model is slightly different. Fitting just an intercept in the hurdle model implies that the proportion of zeros observed across different combinations of those fixed effects fitted for the Poisson process is constant. Our 95% credible intervals for this proportion is (See section \@ref(pred-sec)):

```{r echo=TRUE}
c2<-(16*sqrt(3)/(15*pi))^2
HPDinterval(plogis(m5d.3$Sol[,2]/sqrt(1+c2))) 
```

and we can compare this to the predicted number of zero's from the Poisson process if it had not been zero-truncated:

```{r echo=TRUE}
HPDinterval(ppois(0, exp(m5d.3$Sol[,1]+0.5*m5d.3$VCV[,1])))  
```

The credible intervals largely overlap, strongly suggesting a standard Poisson model would be adequate. However, our prediction for the number of zero's that would arise form a non-truncated Poisson process only involved the intercept term. This prediction therefore pertains to the number of articles published by single women with no young children who obtained their Ph.D's from departments scoring zero for prestige (`phd`) and whose mentors had published nothing in the previous 3 years. Our equivalent prediction for men is a little lower

```{r echo=TRUE}
HPDinterval(ppois(0, exp(m5d.3$Sol[,1]+m5d.3$Sol[,3]+0.5*m5d.3$VCV[,1])))  
```

suggesting that perhaps the number of zero's is greater than we expected for this group. However, this may just be a consequence of us fixing the proportion of zero's to be constant across these groups. We can relax this assumption by fitting a separate term for the proportion of zeros for men:

```{r echo=TRUE, cache=TRUE}
m5d.4<-MCMCglmm(art~trait-1+at.level(trait,1:2):fem+at.level(trait,1):mar + at.level(trait,1):kid5 + at.level(trait,1):phd + at.level(trait,1):ment, rcov=~idh(trait):units, data=bioChemists, prior=prior.m5d.1, family="hupoisson")
```

which reveals that although this proportion is expected to be (slightly) smaller:

```{r echo=TRUE}
HPDinterval(plogis((m5d.4$Sol[,2]+m5d.4$Sol[,4])/sqrt(1+c2))) 
```

the proportion of zeros expected for men is probably still less than what we expect from a non-truncated Poisson process for which the estimates have changed very little:

```{r echo=TRUE}
HPDinterval(ppois(0, exp(m5d.4$Sol[,1]+m5d.4$Sol[,3]+0.5*m5d.4$VCV[,1])))  
```

This highlights one of the disadvantages of hurdle models. If explanatory variables have been fitted that affect the expectation of the Poisson process then this implies that the proportion of zero's observed will also vary across these same explanatory variables, even in the absence of zero-inflation. It may then be necessary to fit an equally complicated model for both processes even though a single parameter would suffice in a ZIP model. However, in the absence of zero-inflation the intercept of the zero-inflation process in a ZIP model is $-\infty$ on the logit scale causing numerical and inferential problems. An alternative type of model are zero-altered models.

## Zero-altered Models {#ZAP}

Zero-altered Poisson (ZAP) models are identical to Poisson-hurdle models except a complementary log-log link is used instead of the logit link when modelling the proportion of zeros. However for reasons that will become clearer below, the zero-altered process (`za`) is predicting non-zeros as opposed to the ZIP and hurdle-Poisson models where it is
the number of zeros. The likelihood is:

$$\begin{array}{rl}
Pr(y=0) =& 1-\texttt{pexp}(\texttt{exp}(l_{2}))\\
Pr(y | y>0) =& \texttt{pexp}(\texttt{exp}(l_{2}))\ast \texttt{dpois}(y, \texttt{exp}(l_{1}))/(1-\texttt{ppois}(0, \texttt{exp}(l_{1})))\\
\end{array}$$

since the inverse of the complementary log-log transformation is the distribution function of the extreme value (log-exponential) distribution.

It happens that $\texttt{ppois}(0,\texttt{exp}(l)) = \texttt{dpois}(0,\texttt{exp}(l)) = 1-\texttt{pexp}(\texttt{exp}(l))$
so that if $l = l_{1} = l_{2}$ then the likelihood reduces to:

$$\begin{array}{rl}
Pr(y=0) =& \texttt{dpois}(0,\texttt{exp}(l))\\
Pr(y | y>0) =& \texttt{dpois}(y, \texttt{exp}(l))\\
\end{array}$$

which is equivalent to a standard Poisson model.

We can then test for zero-flation by constraining the overdispersion to be the same for both process using a `trait` by `units` interaction in the R-structure, and by setting up the contrasts so that the zero-altered regression coefficients are expressed as differences from the Poisson regression coefficients. When this difference is zero the variable causes no zero-flation, when it is negative it causes zero-inflation and when it is positive it causes zero-deflation:

```{r echo=TRUE, cache=TRUE}
m5d.5<-MCMCglmm(art~trait*(fem +mar + kid5 + phd + ment), rcov=~trait:units, data=bioChemists, family="zapoisson")
summary(m5d.5)
```

we can see from this that the more papers a mentor produces, the more zero-deflation (or conversely the less papers a mentor produces, the more zero-inflation).
