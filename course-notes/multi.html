<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Multi-response Models | MCMCglmm Course Notes</title>
  <meta name="description" content="Extended documentation and course notes for the MCMCglmm R package." />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Multi-response Models | MCMCglmm Course Notes" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Extended documentation and course notes for the MCMCglmm R package." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Multi-response Models | MCMCglmm Course Notes" />
  
  <meta name="twitter:description" content="Extended documentation and course notes for the MCMCglmm R package." />
  

<meta name="author" content="Jarrod Hadfield" />


<meta name="date" content="2026-02-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="cont-int.html"/>
<link rel="next" href="pedigree.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/rglWebGL-binding-1.3.34/rglWebGL.js"></script>
<link href="libs/rglwidgetClass-1.3.34/rgl.css" rel="stylesheet" />
<script src="libs/rglwidgetClass-1.3.34/rglClass.min.js"></script>
<script src="libs/CanvasMatrix4-1.3.34/CanvasMatrix.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>1</b> Overview</a>
<ul>
<li class="chapter" data-level="1.1" data-path="overview.html"><a href="overview.html#outline"><i class="fa fa-check"></i><b>1.1</b> Outline</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>2</b> Bayesian Analysis and MCMC</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bayesian.html"><a href="bayesian.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="bayesian.html"><a href="bayesian.html#likelihood"><i class="fa fa-check"></i><b>2.2</b> Likelihood</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="bayesian.html"><a href="bayesian.html#maximum-likelihood-ml"><i class="fa fa-check"></i><b>2.2.1</b> Maximum Likelihood (ML)</a></li>
<li class="chapter" data-level="2.2.2" data-path="bayesian.html"><a href="bayesian.html#restricted-maximum-likelihood-reml"><i class="fa fa-check"></i><b>2.2.2</b> Restricted Maximum Likelihood (REML)</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="bayesian.html"><a href="bayesian.html#prior-distribution"><i class="fa fa-check"></i><b>2.3</b> Prior Distribution</a></li>
<li class="chapter" data-level="2.4" data-path="bayesian.html"><a href="bayesian.html#posterior-distribution"><i class="fa fa-check"></i><b>2.4</b> Posterior Distribution</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="bayesian.html"><a href="bayesian.html#marginal-posterior-distribution"><i class="fa fa-check"></i><b>2.4.1</b> Marginal Posterior Distribution</a></li>
<li class="chapter" data-level="2.4.2" data-path="bayesian.html"><a href="bayesian.html#intervals-sec"><i class="fa fa-check"></i><b>2.4.2</b> Credible Intervals</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="bayesian.html"><a href="bayesian.html#MCMC"><i class="fa fa-check"></i><b>2.5</b> MCMC</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="bayesian.html"><a href="bayesian.html#starting-values"><i class="fa fa-check"></i><b>2.5.1</b> Starting values</a></li>
<li class="chapter" data-level="2.5.2" data-path="bayesian.html"><a href="bayesian.html#metropolis-hastings-updates"><i class="fa fa-check"></i><b>2.5.2</b> Metropolis-Hastings updates</a></li>
<li class="chapter" data-level="2.5.3" data-path="bayesian.html"><a href="bayesian.html#gibbs-sampling"><i class="fa fa-check"></i><b>2.5.3</b> Gibbs Sampling</a></li>
<li class="chapter" data-level="2.5.4" data-path="bayesian.html"><a href="bayesian.html#diagnostics-sec"><i class="fa fa-check"></i><b>2.5.4</b> MCMC Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="bayesian.html"><a href="bayesian.html#Vprior-sec"><i class="fa fa-check"></i><b>2.6</b> Priors for Residual Variances</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="bayesian.html"><a href="bayesian.html#IP-sec"><i class="fa fa-check"></i><b>2.6.1</b> Improper Priors</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="bayesian.html"><a href="bayesian.html#transform-sec"><i class="fa fa-check"></i><b>2.7</b> Transformations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>3</b> Linear and Generalised Linear Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="glm.html"><a href="glm.html#linear-model-lm"><i class="fa fa-check"></i><b>3.1</b> Linear Model (LM)</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="glm.html"><a href="glm.html#lm-sec"><i class="fa fa-check"></i><b>3.1.1</b> Linear Predictors</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="glm.html"><a href="glm.html#generalised-linear-model-glm"><i class="fa fa-check"></i><b>3.2</b> Generalised Linear Model (GLM)</a></li>
<li class="chapter" data-level="3.3" data-path="glm.html"><a href="glm.html#poisglm-sec"><i class="fa fa-check"></i><b>3.3</b> Poisson GLM</a></li>
<li class="chapter" data-level="3.4" data-path="glm.html"><a href="glm.html#od-sec"><i class="fa fa-check"></i><b>3.4</b> Overdispersion</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="glm.html"><a href="glm.html#multiplicative-overdispersion"><i class="fa fa-check"></i><b>3.4.1</b> Multiplicative Overdispersion</a></li>
<li class="chapter" data-level="3.4.2" data-path="glm.html"><a href="glm.html#addod-sec"><i class="fa fa-check"></i><b>3.4.2</b> Additive Overdispersion</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="glm.html"><a href="glm.html#prediction-in-glm"><i class="fa fa-check"></i><b>3.5</b> Prediction in GLM</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="glm.html"><a href="glm.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>3.5.1</b> Posterior Predictive Distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="glm.html"><a href="glm.html#binom-sec"><i class="fa fa-check"></i><b>3.6</b> Binomial and Bernoulli GLM</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="glm.html"><a href="glm.html#od-binom"><i class="fa fa-check"></i><b>3.6.1</b> Overdispersion</a></li>
<li class="chapter" data-level="3.6.2" data-path="glm.html"><a href="glm.html#binom-pred-sec"><i class="fa fa-check"></i><b>3.6.2</b> Prediction</a></li>
<li class="chapter" data-level="3.6.3" data-path="glm.html"><a href="glm.html#bernoulli-sec"><i class="fa fa-check"></i><b>3.6.3</b> Bernoulli GLM</a></li>
<li class="chapter" data-level="3.6.4" data-path="glm.html"><a href="glm.html#probit-link"><i class="fa fa-check"></i><b>3.6.4</b> Probit link</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="glm.html"><a href="glm.html#ordinal-sec"><i class="fa fa-check"></i><b>3.7</b> Ordinal Data</a></li>
<li class="chapter" data-level="3.8" data-path="glm.html"><a href="glm.html#non-zero-binomial-data"><i class="fa fa-check"></i><b>3.8</b> Non-zero Binomial Data</a></li>
<li class="chapter" data-level="3.9" data-path="glm.html"><a href="glm.html#complete-separation"><i class="fa fa-check"></i><b>3.9</b> Complete Separation</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="glm.html"><a href="glm.html#gelman-prior-sec"><i class="fa fa-check"></i><b>3.9.1</b> The <span class="citation">Gelman, Jakulin, et al. (2008)</span> prior</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ranef.html"><a href="ranef.html"><i class="fa fa-check"></i><b>4</b> Random effects</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ranef.html"><a href="ranef.html#GLMM"><i class="fa fa-check"></i><b>4.1</b> Generalised Linear Mixed Model (GLMM)</a></li>
<li class="chapter" data-level="4.2" data-path="ranef.html"><a href="ranef.html#ranpred-sec"><i class="fa fa-check"></i><b>4.2</b> Prediction with Random Effects</a></li>
<li class="chapter" data-level="4.3" data-path="ranef.html"><a href="ranef.html#overdispersed-binomial-as-a-bernoulli-glmm"><i class="fa fa-check"></i><b>4.3</b> Overdispersed Binomial as a Bernoulli GLMM</a></li>
<li class="chapter" data-level="4.4" data-path="ranef.html"><a href="ranef.html#ICC"><i class="fa fa-check"></i><b>4.4</b> Intra-class Correlations</a></li>
<li class="chapter" data-level="4.5" data-path="ranef.html"><a href="ranef.html#sec-underdispersion"><i class="fa fa-check"></i><b>4.5</b> Underdispersion</a></li>
<li class="chapter" data-level="4.6" data-path="ranef.html"><a href="ranef.html#PXprior-sec"><i class="fa fa-check"></i><b>4.6</b> Priors for Random Effect Variances</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="ranef.html"><a href="ranef.html#f-and-folded-t-priors"><i class="fa fa-check"></i><b>4.6.1</b> <span class="math inline">\(F\)</span> and folded-<span class="math inline">\(t\)</span> priors</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="ranef.html"><a href="ranef.html#Vprior-gen-sec"><i class="fa fa-check"></i><b>4.7</b> Prior Generators</a></li>
<li class="chapter" data-level="4.8" data-path="ranef.html"><a href="ranef.html#priors-on-functions-of-variances"><i class="fa fa-check"></i><b>4.8</b> Priors on Functions of Variances</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="ranef.html"><a href="ranef.html#intra-class-correlation"><i class="fa fa-check"></i><b>4.8.1</b> Intra-class Correlation</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="ranef.html"><a href="ranef.html#fix-or-rand"><i class="fa fa-check"></i><b>4.9</b> Fixed or Random?</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="cat-int.html"><a href="cat-int.html"><i class="fa fa-check"></i><b>5</b> Categorical Random Interactions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="cat-int.html"><a href="cat-int.html#vstruct-sec"><i class="fa fa-check"></i><b>5.1</b> Variance Structures</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="cat-int.html"><a href="cat-int.html#idh-sec"><i class="fa fa-check"></i><b>5.1.1</b> <span class="math inline">\(\texttt{idh}\)</span> Variance Structure</a></li>
<li class="chapter" data-level="5.1.2" data-path="cat-int.html"><a href="cat-int.html#us-sec"><i class="fa fa-check"></i><b>5.1.2</b> <span class="math inline">\(\texttt{us}\)</span> Variance Structure</a></li>
<li class="chapter" data-level="5.1.3" data-path="cat-int.html"><a href="cat-int.html#other-variance-structures"><i class="fa fa-check"></i><b>5.1.3</b> Other Variance Structures</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="cat-int.html"><a href="cat-int.html#link-func-sec"><i class="fa fa-check"></i><b>5.2</b> Linking Functions</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="cat-int.html"><a href="cat-int.html#textttstr-covariances-between-random-terms"><i class="fa fa-check"></i><b>5.2.1</b> <span class="math inline">\(\texttt{str}\)</span>: covariances between random terms</a></li>
<li class="chapter" data-level="5.2.2" data-path="cat-int.html"><a href="cat-int.html#multim-sec"><i class="fa fa-check"></i><b>5.2.2</b> <span class="math inline">\(\texttt{mm}\)</span>: multi-membership models</a></li>
<li class="chapter" data-level="5.2.3" data-path="cat-int.html"><a href="cat-int.html#textttcovu-covariances-between-random-and-residual-terms"><i class="fa fa-check"></i><b>5.2.3</b> <span class="math inline">\(\texttt{covu}\)</span>: covariances between random and residual terms</a></li>
<li class="chapter" data-level="5.2.4" data-path="cat-int.html"><a href="cat-int.html#texttttheta_scale-scaled-linear-predictor"><i class="fa fa-check"></i><b>5.2.4</b> <span class="math inline">\(\texttt{theta_scale}\)</span>: scaled linear predictor</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="cat-int.html"><a href="cat-int.html#VCVprior-sec"><i class="fa fa-check"></i><b>5.3</b> Priors for Covariance Matrices</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="cat-int.html"><a href="cat-int.html#marginal-priors-for-variances"><i class="fa fa-check"></i><b>5.3.1</b> Marginal Priors for Variances</a></li>
<li class="chapter" data-level="5.3.2" data-path="cat-int.html"><a href="cat-int.html#VCVprior-r-sec"><i class="fa fa-check"></i><b>5.3.2</b> Marginal Priors for Covariances and Correlations</a></li>
<li class="chapter" data-level="5.3.3" data-path="cat-int.html"><a href="cat-int.html#full-joint-prior"><i class="fa fa-check"></i><b>5.3.3</b> Full joint prior</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="cont-int.html"><a href="cont-int.html"><i class="fa fa-check"></i><b>6</b> Continuous Random Interactions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="cont-int.html"><a href="cont-int.html#random-regression"><i class="fa fa-check"></i><b>6.1</b> Random Regression</a></li>
<li class="chapter" data-level="6.2" data-path="cont-int.html"><a href="cont-int.html#het-res"><i class="fa fa-check"></i><b>6.2</b> Heterogeneous (Residual) Variances</a></li>
<li class="chapter" data-level="6.3" data-path="cont-int.html"><a href="cont-int.html#autoc-sec"><i class="fa fa-check"></i><b>6.3</b> Autocorrelation</a></li>
<li class="chapter" data-level="6.4" data-path="cont-int.html"><a href="cont-int.html#vstab-sec"><i class="fa fa-check"></i><b>6.4</b> Variance stabilisation</a></li>
<li class="chapter" data-level="6.5" data-path="cont-int.html"><a href="cont-int.html#ante-sec"><i class="fa fa-check"></i><b>6.5</b> Antedependence and Autoregressive Models</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="cont-int.html"><a href="cont-int.html#autoregressive-models"><i class="fa fa-check"></i><b>6.5.1</b> Autoregressive Models</a></li>
<li class="chapter" data-level="6.5.2" data-path="cont-int.html"><a href="cont-int.html#prior-ante-sec"><i class="fa fa-check"></i><b>6.5.2</b> Priors in Antedependence models</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="cont-int.html"><a href="cont-int.html#user-defined-sec"><i class="fa fa-check"></i><b>6.6</b> User-defined Design Matrices</a></li>
<li class="chapter" data-level="6.7" data-path="cont-int.html"><a href="cont-int.html#splines"><i class="fa fa-check"></i><b>6.7</b> Splines</a></li>
<li class="chapter" data-level="6.8" data-path="cont-int.html"><a href="cont-int.html#penalised-signal-regression"><i class="fa fa-check"></i><b>6.8</b> Penalised Signal Regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multi.html"><a href="multi.html"><i class="fa fa-check"></i><b>7</b> Multi-response Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="multi.html"><a href="multi.html#multi-response-non-gaussian-models"><i class="fa fa-check"></i><b>7.1</b> Multi-response Non-Gaussian Models</a></li>
<li class="chapter" data-level="7.2" data-path="multi.html"><a href="multi.html#multi-response-bernoulli-models"><i class="fa fa-check"></i><b>7.2</b> Multi-response Bernoulli Models</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="multi.html"><a href="multi.html#bern-gaus-sec"><i class="fa fa-check"></i><b>7.2.1</b> Bernoulli-Gaussian</a></li>
<li class="chapter" data-level="7.2.2" data-path="multi.html"><a href="multi.html#all-bernoulli"><i class="fa fa-check"></i><b>7.2.2</b> All Bernoulli</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="multi.html"><a href="multi.html#wide-versus-long-format"><i class="fa fa-check"></i><b>7.3</b> Wide versus Long Format</a></li>
<li class="chapter" data-level="7.4" data-path="multi.html"><a href="multi.html#covu-sec"><i class="fa fa-check"></i><b>7.4</b> Covariances between random and residual terms (<span class="math inline">\(\texttt{covu}\)</span>)</a></li>
<li class="chapter" data-level="7.5" data-path="multi.html"><a href="multi.html#scaled-linear-predictors-texttttheta_scale"><i class="fa fa-check"></i><b>7.5</b> Scaled linear predictors: <span class="math inline">\(\texttt{theta_scale}\)</span></a></li>
<li class="chapter" data-level="7.6" data-path="multi.html"><a href="multi.html#multinomial-models"><i class="fa fa-check"></i><b>7.6</b> Multinomial Models</a></li>
<li class="chapter" data-level="7.7" data-path="multi.html"><a href="multi.html#zero-inflated-models"><i class="fa fa-check"></i><b>7.7</b> Zero-inflated Models</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="multi.html"><a href="multi.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>7.7.1</b> Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="multi.html"><a href="multi.html#Hurdle"><i class="fa fa-check"></i><b>7.8</b> Hurdle Models</a></li>
<li class="chapter" data-level="7.9" data-path="multi.html"><a href="multi.html#ZAP"><i class="fa fa-check"></i><b>7.9</b> Zero-altered Models</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="pedigree.html"><a href="pedigree.html"><i class="fa fa-check"></i><b>8</b> Pedigrees and Phylogenies</a>
<ul>
<li class="chapter" data-level="8.1" data-path="pedigree.html"><a href="pedigree.html#pedigree-and-phylogeny-formats"><i class="fa fa-check"></i><b>8.1</b> Pedigree and phylogeny formats</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="pedigree.html"><a href="pedigree.html#pedigrees"><i class="fa fa-check"></i><b>8.1.1</b> Pedigrees</a></li>
<li class="chapter" data-level="8.1.2" data-path="pedigree.html"><a href="pedigree.html#phylogenies"><i class="fa fa-check"></i><b>8.1.2</b> Phylogenies</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="pedigree.html"><a href="pedigree.html#the-animal-model-and-the-phylogenetic-mixed-model"><i class="fa fa-check"></i><b>8.2</b> The animal model and the phylogenetic mixed model</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="measurement.html"><a href="measurement.html"><i class="fa fa-check"></i><b>9</b> Measurement Error, Meta-analysis an Missing Values</a>
<ul>
<li class="chapter" data-level="9.1" data-path="measurement.html"><a href="measurement.html#error-in-the-response"><i class="fa fa-check"></i><b>9.1</b> Error in the Response</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="measurement.html"><a href="measurement.html#meta-sec"><i class="fa fa-check"></i><b>9.1.1</b> Meta-analysis</a></li>
<li class="chapter" data-level="9.1.2" data-path="measurement.html"><a href="measurement.html#interval-estimation"><i class="fa fa-check"></i><b>9.1.2</b> Interval Estimation</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="measurement.html"><a href="measurement.html#error-in-the-predictors"><i class="fa fa-check"></i><b>9.2</b> Error in the Predictors</a></li>
<li class="chapter" data-level="9.3" data-path="measurement.html"><a href="measurement.html#missing-values"><i class="fa fa-check"></i><b>9.3</b> Missing Values</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="path.html"><a href="path.html"><i class="fa fa-check"></i><b>10</b> Path Analysis &amp; Antedependence Structures</a>
<ul>
<li class="chapter" data-level="10.1" data-path="path.html"><a href="path.html#path-anlaysis"><i class="fa fa-check"></i><b>10.1</b> Path Anlaysis</a></li>
<li class="chapter" data-level="10.2" data-path="cont-int.html"><a href="cont-int.html#ante-sec"><i class="fa fa-check"></i><b>10.2</b> Antedependence</a></li>
<li class="chapter" data-level="10.3" data-path="path.html"><a href="path.html#scaling"><i class="fa fa-check"></i><b>10.3</b> Scaling</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="technical-details.html"><a href="technical-details.html"><i class="fa fa-check"></i><b>11</b> Technical Details</a>
<ul>
<li class="chapter" data-level="11.1" data-path="technical-details.html"><a href="technical-details.html#model-form"><i class="fa fa-check"></i><b>11.1</b> Model Form</a></li>
<li class="chapter" data-level="11.2" data-path="technical-details.html"><a href="technical-details.html#MCMC-app"><i class="fa fa-check"></i><b>11.2</b> MCMC Sampling Schemes</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="technical-details.html"><a href="technical-details.html#updating-the-latent-variables-bf-l"><i class="fa fa-check"></i><b>11.2.1</b> Updating the latent variables <span class="math inline">\({\bf l}\)</span></a></li>
<li class="chapter" data-level="11.2.2" data-path="technical-details.html"><a href="technical-details.html#updating-the-location-vector-boldsymboltheta-leftboldsymbolmathbfbeta-bf-uright"><i class="fa fa-check"></i><b>11.2.2</b> Updating the location vector <span class="math inline">\(\boldsymbol{\theta} = \left[{\boldsymbol{\mathbf{\beta}}}^{&#39;}\; {\bf u}^{&#39;}\right]^{&#39;}\)</span></a></li>
<li class="chapter" data-level="11.2.3" data-path="technical-details.html"><a href="technical-details.html#updating-the-variance-structures-bf-g-and-bf-r"><i class="fa fa-check"></i><b>11.2.3</b> Updating the variance structures <span class="math inline">\({\bf G}\)</span> and <span class="math inline">\({\bf R}\)</span></a></li>
<li class="chapter" data-level="11.2.4" data-path="technical-details.html"><a href="technical-details.html#ordinal-models"><i class="fa fa-check"></i><b>11.2.4</b> Ordinal Models</a></li>
<li class="chapter" data-level="11.2.5" data-path="technical-details.html"><a href="technical-details.html#path-analyses"><i class="fa fa-check"></i><b>11.2.5</b> Path Analyses</a></li>
<li class="chapter" data-level="11.2.6" data-path="technical-details.html"><a href="technical-details.html#deviance-and-dic"><i class="fa fa-check"></i><b>11.2.6</b> Deviance and DIC</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="technical-details.html"><a href="technical-details.html#parameter-expansion"><i class="fa fa-check"></i><b>11.3</b> Parameter Expansion</a></li>
<li class="chapter" data-level="11.4" data-path="technical-details.html"><a href="technical-details.html#priors-for-corg-and-corgh-structures"><i class="fa fa-check"></i><b>11.4</b> Priors for <code>corg</code> and <code>corgh</code> structures</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>12</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MCMCglmm Course Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multi" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">7</span> Multi-response Models<a href="multi.html#multi" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>So far we have only fitted models to a single response variable, and even then, each response variable came from a distribution that only required one location parameter to be estimated, such as the mean of the Poisson or the probability of the binomial. In this section we will first cover multi-response models and then move on to models of multi-parameter distributions.</p>
<p>Since they are much less widely used than single-response models, let’s start by motivating why anyone would want to use them. Imagine we knew how much money 200 people had spent on their holiday and on their car in each of four years, and we want to know whether a relationship exists between the two. A simple correlation would be one possibility, but then how do we control for the repeated measures? An often used solution to this problem is to choose one variable as the response (lets say the amount spent on a car) and have the other variable as a predictor (the amount spent on a holiday) for which a fixed effect is estimated. The choice is essentially arbitrary, highlighting the belief that any relationship between the two types of spending maybe in part due to unmeasured variables, rather than being completely causal.</p>
<p>In practice does this matter? Let’s imagine there was only one unmeasured variable: disposable income. There are repeatable differences between individuals in their disposable income, but also some variation within individuals across the four years. Likewise, people vary in what proportion of their disposable income they are willing to spend on a holiday versus a car, but this also changes from year to year. We can simulate some toy data to get a feel for the issues:</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="multi.html#cb233-1" tabindex="-1"></a>id<span class="ot">&lt;-</span><span class="fu">gl</span>(<span class="dv">200</span>,<span class="dv">4</span>)   <span class="co"># 200 people recorded four times                      </span></span>
<span id="cb233-2"><a href="multi.html#cb233-2" tabindex="-1"></a></span>
<span id="cb233-3"><a href="multi.html#cb233-3" tabindex="-1"></a>av_wealth<span class="ot">&lt;-</span><span class="fu">rlnorm</span>(<span class="dv">200</span>, <span class="dv">0</span>, <span class="dv">1</span>)               </span>
<span id="cb233-4"><a href="multi.html#cb233-4" tabindex="-1"></a>ac_wealth<span class="ot">&lt;-</span><span class="fu">rlnorm</span>(<span class="dv">800</span>, <span class="fu">log</span>(av_wealth[id]), <span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>) </span>
<span id="cb233-5"><a href="multi.html#cb233-5" tabindex="-1"></a><span class="co"># expected disposable incomes + some year to year variation</span></span>
<span id="cb233-6"><a href="multi.html#cb233-6" tabindex="-1"></a></span>
<span id="cb233-7"><a href="multi.html#cb233-7" tabindex="-1"></a>av_ratio<span class="ot">&lt;-</span><span class="fu">rbeta</span>(<span class="dv">200</span>,<span class="dv">10</span>,<span class="dv">10</span>)                 </span>
<span id="cb233-8"><a href="multi.html#cb233-8" tabindex="-1"></a>ac_ratio<span class="ot">&lt;-</span><span class="fu">rbeta</span>(<span class="dv">800</span>, <span class="dv">3</span><span class="sc">*</span>(av_ratio[id]), <span class="dv">3</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>av_ratio[id])) </span>
<span id="cb233-9"><a href="multi.html#cb233-9" tabindex="-1"></a><span class="co"># expected proportion spent on car + some year to year variation</span></span>
<span id="cb233-10"><a href="multi.html#cb233-10" tabindex="-1"></a></span>
<span id="cb233-11"><a href="multi.html#cb233-11" tabindex="-1"></a>y.car<span class="ot">&lt;-</span>ac_wealth<span class="sc">*</span>ac_ratio      <span class="co"># disposable income * proportion spent on car</span></span>
<span id="cb233-12"><a href="multi.html#cb233-12" tabindex="-1"></a>y.hol<span class="ot">&lt;-</span>ac_wealth<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ac_ratio)  <span class="co"># disposable income * proportion spent on holiday                              </span></span>
<span id="cb233-13"><a href="multi.html#cb233-13" tabindex="-1"></a></span>
<span id="cb233-14"><a href="multi.html#cb233-14" tabindex="-1"></a>Spending<span class="ot">&lt;-</span><span class="fu">data.frame</span>(<span class="at">y.hol=</span><span class="fu">log</span>(y.hol), <span class="at">y.car=</span><span class="fu">log</span>(y.car), <span class="at">id=</span>id)</span></code></pre></div>
<p>A simple model suggests the two types of spending (on the log-scale) are positively related:</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="multi.html#cb234-1" tabindex="-1"></a>mspending<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(y.car <span class="sc">~</span> y.hol, <span class="at">data =</span> Spending)</span>
<span id="cb234-2"><a href="multi.html#cb234-2" tabindex="-1"></a><span class="fu">summary</span>(mspending<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
##  Iterations = 3001:12991
##  Thinning interval  = 10
##  Sample size  = 1000 
## 
##  DIC: 2634.549 
## 
##  R-structure:  ~units
## 
##       post.mean l-95% CI u-95% CI eff.samp
## units      1.57    1.416    1.733     1000
## 
##  Location effects: y.car ~ y.hol 
## 
##             post.mean l-95% CI u-95% CI eff.samp  pMCMC    
## (Intercept)   -0.6410  -0.7455  -0.5447     1000 &lt;0.001 ***
## y.hol          0.3129   0.2485   0.3785     1000 &lt;0.001 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This conclusion seems to be supported by just looking at a scatter plot of the two variables (Figure <a href="multi.html#fig:spending">7.1</a>).</p>
<div class="figure"><span style="display:block;" id="fig:spending"></span>
<img src="_bookdown_files/fig/spending-1.png" alt="Money spent on car versus money spent on holiday (both logged) with the regression line from a simple regression (model `mspending.1`)" width="672" />
<p class="caption">
Figure 7.1: Money spent on car versus money spent on holiday (both logged) with the regression line from a simple regression (model <code>mspending.1</code>)
</p>
</div>
<p>An obvious problem with the model is that we have repeated measures (the spending habits of each individual have been recorded for each of four years) and yet we haven’t dealt with any possible non-independence. We can remedy this by fitting <code>id</code> effects as random:</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="multi.html#cb236-1" tabindex="-1"></a>mspending<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(y.car <span class="sc">~</span> y.hol, <span class="at">random =</span> <span class="sc">~</span>id, <span class="at">data =</span> Spending)</span>
<span id="cb236-2"><a href="multi.html#cb236-2" tabindex="-1"></a><span class="fu">summary</span>(mspending<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
##  Iterations = 3001:12991
##  Thinning interval  = 10
##  Sample size  = 1000 
## 
##  DIC: 1922.517 
## 
##  G-structure:  ~id
## 
##    post.mean l-95% CI u-95% CI eff.samp
## id     1.674    1.313    2.045     1000
## 
##  R-structure:  ~units
## 
##       post.mean l-95% CI u-95% CI eff.samp
## units    0.5132   0.4589   0.5733     1131
## 
##  Location effects: y.car ~ y.hol 
## 
##             post.mean l-95% CI u-95% CI eff.samp  pMCMC    
## (Intercept)   -1.1801  -1.3688  -0.9852     1000 &lt;0.001 ***
## y.hol         -0.2762  -0.3447  -0.2111     1053 &lt;0.001 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Strangely, and in contradiction to the scatter plot, the model suggests that spending more on a holiday means less is spent on a car - the regression slope is negative. If I hadn’t looked at the raw data, I would probably report the negative relationship and move on. But I have looked at the raw data and simply reporting a negative relationship without caveats makes me feel uneasy.</p>
<p>Lets proceed with a multi-response model of the problem to see what is going on. The two responses are passed as a matrix using <code>cbind()</code>, and the rows of this matrix are indexed by the reserved variable <code>units</code>, and the columns by the reserved variable <code>trait</code>. It is useful to think of a new data frame where the response variables have been stacked column-wise and the other predictors duplicated accordingly. Below is the original data frame on the left (<code>Spending</code>) and the stacked data frame on the right when <code>cbind(y.hol, y.car)</code> is passed as the response:</p>
<p><span class="math display" id="eq:multi">\[\begin{array}{cc}
\begin{array}{cccc}
&amp;{\color{blue}{\texttt{y.hol}}}&amp;{\color{blue}{\texttt{y.car}}}&amp;\texttt{id}\\
{\color{red}{\texttt{1}}}&amp;\texttt{0.058057}&amp;\texttt{1.475391}&amp;\texttt{1}\\
{\color{red}{\texttt{2}}}&amp;\texttt{0.763508}&amp;\texttt{0.759238}&amp;\texttt{1}\\
\vdots&amp;\vdots&amp;\vdots\\
{\color{red}{\texttt{800}}}&amp;\texttt{-2.304347}&amp;\texttt{0.774078}&amp;\texttt{200}\\
\end{array}&amp;
\Longrightarrow
\begin{array}{ccccc}
&amp;\texttt{y}&amp;{\color{blue}{\texttt{trait}}}&amp;\texttt{id}&amp;{\color{red}{\texttt{units}}}\\
1&amp;\texttt{0.058057}&amp;{\color{blue}{\texttt{y.hol}}}&amp;\texttt{1}&amp;{\color{red}{\texttt{1}}}\\
2&amp;\texttt{0.763508}&amp;{\color{blue}{\texttt{y.hol}}}&amp;\texttt{1}&amp;{\color{red}{\texttt{2}}}\\
\vdots&amp;\vdots&amp;\vdots&amp;\vdots\\
800&amp;\texttt{-2.304347}&amp;{\color{blue}{\texttt{y.hol}}}&amp;\texttt{200}&amp;{\color{red}{\texttt{800}}}\\
801&amp;\texttt{1.475391}&amp;{\color{blue}{\texttt{y.car}}}&amp;\texttt{1}&amp;{\color{red}{\texttt{1}}}\\
802&amp;\texttt{0.759238}&amp;{\color{blue}{\texttt{y.car}}}&amp;\texttt{1}&amp;{\color{red}{\texttt{2}}}\\
\vdots&amp;\vdots&amp;\vdots&amp;\vdots\\
1600&amp;\texttt{0.774078}&amp;{\color{blue}{\texttt{y.car}}}&amp;\texttt{200}&amp;{\color{red}{\texttt{800}}}\\
\end{array}
\end{array}
\label{multi-eq}   \tag{7.1}\]</span></p>
<p>From this we can see that fitting a multi-response model is a direct extension to how we fitted models with categorical random interactions (Chapter <a href="cat-int.html#cat-int">5</a>):</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="multi.html#cb238-1" tabindex="-1"></a>prior.mspending<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">R =</span> <span class="fu">IW</span>(<span class="dv">1</span>, <span class="fl">0.002</span>), <span class="at">G =</span> <span class="fu">F</span>(<span class="dv">2</span>, <span class="dv">1000</span>))</span>
<span id="cb238-2"><a href="multi.html#cb238-2" tabindex="-1"></a></span>
<span id="cb238-3"><a href="multi.html#cb238-3" tabindex="-1"></a>mspending<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(<span class="fu">cbind</span>(y.hol, y.car) <span class="sc">~</span> trait <span class="sc">-</span> <span class="dv">1</span>, <span class="at">random =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>id,</span>
<span id="cb238-4"><a href="multi.html#cb238-4" tabindex="-1"></a>    <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>units, <span class="at">data =</span> Spending, <span class="at">prior =</span> prior.mspending<span class="fl">.3</span>, <span class="at">family =</span> <span class="fu">c</span>(<span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb238-5"><a href="multi.html#cb238-5" tabindex="-1"></a>        <span class="st">&quot;gaussian&quot;</span>))</span></code></pre></div>
<p>The only real difference is that we must now specify the distribution for each response in <span class="math inline">\(\texttt{family}\)</span>. While the interpretation of the model is identical to that covered in Chapter <a href="cat-int.html#cat-int">5</a>, it does take a little time to get used to working with the new categorical factor, <span class="math inline">\(\texttt{trait}\)</span>.</p>
<p>I have fitted a fixed <span class="math inline">\(\texttt{trait}\)</span> effect so that the two types of spending can have different intercepts. I usually suppress the global intercept (<code>-1</code>) for these types of models so the second coefficient is not the difference between the intercept for the first level of <span class="math inline">\(\texttt{trait}\)</span> (<code>y.hol</code>) and the second level (<code>y.car</code>) but the actual trait specific intercepts. Note that the levels of <span class="math inline">\(\texttt{trait}\)</span> are ordered as they appear in the response (<span class="math inline">\(\texttt{y.hol}\)</span> then <span class="math inline">\(\texttt{y.car}\)</span> in this instance). A <span class="math inline">\(2\times2\)</span> covariance matrix is estimated for the random term where the diagonal elements are the variance in consistent individual (<span class="math inline">\(\texttt{id}\)</span>) effects for each type of spending. The off-diagonal is the covariance between these effects which if positive suggests that people that consistently spend more on their holidays consistently spend more on their cars. A <span class="math inline">\(2\times2\)</span> residual covariance matrix is also fitted. In Section<a href="cat-int.html#idh-sec">5.1.1</a> we fitted heterogeneous error models using <code>idh():units</code> which made sense for single-response models because each level of <code>unit</code> was specific to a particular observation and so any covariances could not be estimated. In multi-response models this is not the case because both traits have often been measured on the same observational unit and so the covariance can be measured. In the context of this example a positive covariance would indicate that in those years an individual spent a lot on their car they also spent a lot on their holiday. Let’s take a look at the model summary:</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="multi.html#cb239-1" tabindex="-1"></a><span class="fu">summary</span>(mspending<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
##  Iterations = 3001:12991
##  Thinning interval  = 10
##  Sample size  = 1000 
## 
##  DIC: 4011.721 
## 
##  G-structure:  ~us(trait):id
## 
##                          post.mean l-95% CI u-95% CI eff.samp
## traity.hol:traity.hol.id    1.0040   0.7859    1.264     1000
## traity.car:traity.hol.id    0.8399   0.6449    1.040     1000
## traity.hol:traity.car.id    0.8399   0.6449    1.040     1000
## traity.car:traity.car.id    1.1357   0.8967    1.404     1000
## 
##  R-structure:  ~us(trait):units
## 
##                             post.mean l-95% CI u-95% CI eff.samp
## traity.hol:traity.hol.units    0.7258   0.6525   0.8182   1000.0
## traity.car:traity.hol.units   -0.3025  -0.3649  -0.2497   1000.0
## traity.hol:traity.car.units   -0.3025  -0.3649  -0.2497   1000.0
## traity.car:traity.car.units    0.6231   0.5573   0.6940    909.4
## 
##  Location effects: cbind(y.hol, y.car) ~ trait - 1 
## 
##            post.mean l-95% CI u-95% CI eff.samp  pMCMC    
## traity.hol   -0.9060  -1.0823  -0.7671     1000 &lt;0.001 ***
## traity.car   -0.9268  -1.0699  -0.7610     1000 &lt;0.001 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>we can see that the between-individual covariance (<span class="math inline">\(\texttt{traity.car:traity.hol.id}\)</span>) is strongly positive but the with-individual covariance (<span class="math inline">\(\texttt{traity.car:traity.hol.unit}\)</span>) is strongly negative.</p>
<p>With a single predictors, a regression is defined as the covariance between the response and the predictor divided by the variance in the predictor<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a>. We can therefore obtain the coefficients of a regression of <span class="math inline">\(\texttt{y.car}\)</span> on <span class="math inline">\(\texttt{y.hol}\)</span> at the level of both <span class="math inline">\(\texttt{id}\)</span> and <span class="math inline">\(\texttt{units}\)</span><a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a>:</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="multi.html#cb241-1" tabindex="-1"></a>id.regression <span class="ot">&lt;-</span> mspending<span class="fl">.3</span><span class="sc">$</span>VCV[, <span class="st">&quot;traity.car:traity.hol.id&quot;</span>]</span>
<span id="cb241-2"><a href="multi.html#cb241-2" tabindex="-1"></a><span class="co"># covariance between individuals</span></span>
<span id="cb241-3"><a href="multi.html#cb241-3" tabindex="-1"></a>id.regression <span class="ot">&lt;-</span> id.regression<span class="sc">/</span>mspending<span class="fl">.3</span><span class="sc">$</span>VCV[, <span class="st">&quot;traity.hol:traity.hol.id&quot;</span>]</span>
<span id="cb241-4"><a href="multi.html#cb241-4" tabindex="-1"></a><span class="co"># regression across individual</span></span>
<span id="cb241-5"><a href="multi.html#cb241-5" tabindex="-1"></a></span>
<span id="cb241-6"><a href="multi.html#cb241-6" tabindex="-1"></a>units.regression <span class="ot">&lt;-</span> mspending<span class="fl">.3</span><span class="sc">$</span>VCV[, <span class="st">&quot;traity.car:traity.hol.units&quot;</span>]</span>
<span id="cb241-7"><a href="multi.html#cb241-7" tabindex="-1"></a><span class="co"># covariance within individuals</span></span>
<span id="cb241-8"><a href="multi.html#cb241-8" tabindex="-1"></a>units.regression <span class="ot">&lt;-</span> units.regression<span class="sc">/</span>mspending<span class="fl">.3</span><span class="sc">$</span>VCV[, <span class="st">&quot;traity.hol:traity.hol.units&quot;</span>]</span>
<span id="cb241-9"><a href="multi.html#cb241-9" tabindex="-1"></a><span class="co"># regression within individuals</span></span></code></pre></div>
<p>Conceptually, the regression at the level of <span class="math inline">\(\texttt{id}\)</span> is a regression of average expenditures across people, whereas the regression at the level of <span class="math inline">\(\texttt{units}\)</span> is a regression of yearly expenditures within individuals. We can compare these two regression with those that we got from the single response models that did (<code>mspending.2</code>) or did not (<code>mspending.1</code>) fit <span class="math inline">\(\texttt{id}\)</span> effects (Figure <a href="multi.html#fig:asUV">7.2</a>).</p>
<div class="figure"><span style="display:block;" id="fig:asUV"></span>
<img src="_bookdown_files/fig/asUV-1.png" alt="MCMC summary plot of the coefficient from a regression of car spending on holiday spending in black. The red and green traces are from a model where the regression coefficient is estimated at two levels: within an individual (blue) and across individuals (red). The relationship between the two types of spending is in part mediating by a third unmeasured variable, disposable income." width="672" />
<p class="caption">
Figure 7.2: MCMC summary plot of the coefficient from a regression of car spending on holiday spending in black. The red and green traces are from a model where the regression coefficient is estimated at two levels: within an individual (blue) and across individuals (red). The relationship between the two types of spending is in part mediating by a third unmeasured variable, disposable income.
</p>
</div>
<p>The regression coefficients differ substantially at the within individual (blue) and between
individual (red) levels, and neither is entirely consistent with the regression coefficient from the single response models (black). The process by which we generated the data gives rise to this phenomenon - large variation between individuals in their disposable income means that people who are able to spend a lot on their holiday can also afford to spend a lot on their holidays (hence positive covariation between <span class="math inline">\(\texttt{id}\)</span> effects). However, a person that spent a large proportion of their disposable income in a particular year on a holiday, must have less to spend that year on a car (hence negative residual (within year) covariation).</p>
<p>When fitting the simpler single-response models we make the assumption that the effect of spending money on a holiday directly effects how much you spend on a car. If this relationship was purely causal then the regression coefficients at the level of <span class="math inline">\(\texttt{id}\)</span> and <span class="math inline">\(\texttt{units}\)</span> would have the same expectation, and the simpler model would be justified. For example, we could simulate data where the expected car expenditure depends directly on holiday expenditure (using a regression coefficient of -0.3) with some variation around this due to between and within-individual effects:</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="multi.html#cb242-1" tabindex="-1"></a>Spending<span class="sc">$</span>y.car2 <span class="ot">&lt;-</span> Spending<span class="sc">$</span>y.hol <span class="sc">*</span> <span class="sc">-</span><span class="fl">0.3</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">200</span>, <span class="dv">0</span>, <span class="dv">1</span>)[Spending<span class="sc">$</span>id] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">800</span>,</span>
<span id="cb242-2"><a href="multi.html#cb242-2" tabindex="-1"></a>    <span class="dv">0</span>, <span class="fu">sqrt</span>(<span class="dv">2</span>))</span></code></pre></div>
<p>We can fit the univariate and multivariate models to these data, and compare the regression coefficients as we did before. Figure <a href="multi.html#fig:MVvUV2">7.3</a> shows that the regression coefficients are all similar and a value of -0.3 has a reasonably high posterior probability.</p>
<div class="figure"><span style="display:block;" id="fig:MVvUV2"></span>
<img src="_bookdown_files/fig/MVvUV2-1.png" alt="MCMC trace plot of the coefficient from a regression of car spending on holiday spending in black. The red and blue traces are from a model where the regression coefficient is estimated at two levels: within an individual (blue) and across individuals (red). In simulated data the relationship between the two types of spending is causal and the regression coefficients have the same expectation. However, the posterior standard deviation from the simple regression is smaller because information from the two different levels is pooled." width="672" />
<p class="caption">
Figure 7.3: MCMC trace plot of the coefficient from a regression of car spending on holiday spending in black. The red and blue traces are from a model where the regression coefficient is estimated at two levels: within an individual (blue) and across individuals (red). In simulated data the relationship between the two types of spending is causal and the regression coefficients have the same expectation. However, the posterior standard deviation from the simple regression is smaller because information from the two different levels is pooled.
</p>
</div>
<p>However, it should be noted that the posterior standard deviation is smaller in the simpler model because the more strict assumptions have allowed us to pool information across the two levels to get a more precise answer. This is one of the downsides of multi-response models - if the regressions at each level are the same we can get a more precise estimate using a standard single-response model. The other major benefit of the single-response model is that we only have to worry whether the conditional distribution of the response variable is modelled well (<span class="math inline">\(\texttt{y.car}\)</span> in this case) . In a multi-response model, we have to consider whether the model for the joint distribution of all responses is doing a good job.</p>
<div id="multi-response-non-gaussian-models" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Multi-response Non-Gaussian Models<a href="multi.html#multi-response-non-gaussian-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Model specification for multi-response models does not depend on whether the response variables are Gaussian or not. However, there is an important difference between models involving non-Gaussian variables and those involving only Gaussian variables. For Gaussian responses, the linear predictor is defined as</p>
<p><span class="math display">\[\boldsymbol{\eta} = E[{\bf y}|{\bf X}\boldsymbol{\beta}+{\bf Z}{\bf u}]\]</span></p>
<p>and any observation-level deviations from this expectation appear as <span class="math inline">\(\texttt{units}\)</span> effects:</p>
<p><span class="math display">\[{\bf e} = {\bf y}-\boldsymbol{\eta}\]</span></p>
<p>For non-Gaussian data the linear predictor is defined</p>
<p><span class="math display">\[\boldsymbol{\eta} = E[{\bf l}|{\bf X}\boldsymbol{\beta}+{\bf Z}{\bf u}+{\bf e}]\]</span></p>
<p>where <span class="math inline">\({\bf l}\)</span> is a vector of latent variables (Section <a href="glm.html#addod-sec">3.4.2</a>). Here the <span class="math inline">\(\texttt{units}\)</span> effects appear inside the linear predictor and model any overdispersion with respect to the named distribution. The ‘residual’ due to the named distribution is then</p>
<p><span class="math display">\[{\bf y} -\textrm{link}^{-1}(\boldsymbol{\eta})\]</span></p>
<p>Consequently, with non-Gaussian data the covariances are set up in terms of the underlying parameters of the distribution (on the link scale) not in terms of the response directly. This is not always appropriate. Let’s take the example of the Sweedish road accident data analysed in Chapter <a href="glm.html#glm">3</a>. We saw that the number of accidents per day can be modelled using an overdispersed Poisson. Let’s say we also had data on how much money car insurance companies paid out each day. A sensible way of modelling insurance pay-outs would to treat it as Gaussian and include the number of accidents as a covariate. However, if we analysed the accident and insurance pay-out data in a multi-response model, we would be measuring the covariance between insurance pay-outs and the <em>expected</em> number of accidents per day (<span class="math inline">\(l\)</span>). Insurance companies don’t pay settlements to hypothetical accidents but actual accidents (<span class="math inline">\(\texttt{y}\)</span>) and so the multi-response model is questionable. In contrast, let’s say we also had data on how icy the road was on each day. Here, I would be quite happy to say that iciness determines the <em>expected</em> number of accidents per day (<span class="math inline">\(l\)</span>) but the actual number of accidents (<span class="math inline">\(\texttt{y}\)</span>) will vary around this expectation. However, even here care still needs to be taken.</p>
<p>In Section <a href="glm.html#od-sec">3.4</a> we saw that overdispersion arises if there are unmeasured variables that affect the response of interest. If iciness (<span class="math inline">\(\texttt{ice}\)</span>) was an important predictor of the number of accidents, then including it as a covariate in a single-response model of the number of accidents would bring the overdsipsersion, and hence <span class="math inline">\(\sigma^2_\texttt{units}\)</span>, down. In a multi-response model we can obtain the shift in the <span class="math inline">\(\texttt{units}\)</span> variance had we done this. The <span class="math inline">\(\texttt{units}\)</span> variance for road accidents (<span class="math inline">\(\sigma^2_\texttt{traity.unit}\)</span>) would be equivalent to the units variance in a single-response model <em>without</em> iciness as a covariate. However, <span class="math inline">\(\sigma^2_\texttt{traity.unit}-\sigma^2_\texttt{traity:traitice.unit}/\sigma^2_\texttt{traitice.unit}\)</span> is equivalent to the units variance in the single-response model had iciness been fitted<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a>. Let’s call this <span class="math inline">\(\sigma^2_\texttt{traity|ice.unit}\)</span> since it is the <span class="math inline">\(\texttt{units}\)</span> variance in <span class="math inline">\(\texttt{y}\)</span> after conditioning on <span class="math inline">\(\texttt{ice}\)</span>. If, in the single-response model, the number of accidents had become underdispersed when adding <span class="math inline">\(\texttt{ice}\)</span>, the best estimate of <span class="math inline">\(\sigma^2_\texttt{traity|ice.unit}\)</span> is negative (Section <a href="ranef.html#sec-underdispersion">4.5</a>). However, because covariance matrices are constrained to be positive-definite, <span class="math inline">\(\sigma^2_\texttt{traity|ice.unit}\)</span> is constrained to be positive and we would see that the estimate of <span class="math inline">\(\sigma^2_\texttt{traity|ice.unit}\)</span> is at the boundary (zero) and the residual correlation between the two responses (<span class="math inline">\(\sigma_\texttt{traity:traitice.unit}/\sigma_\texttt{traity.unit}\sigma_\texttt{traitice.unit}\)</span>) is at 1 or -1<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a>. In practice this rarely happens, but when it does I would argue that it arises because the number of accidents, <span class="math inline">\(\texttt{y}\)</span>, is incompatible with a Poisson distribution and alternative distribution should be sought (Section <a href="ranef.html#sec-underdispersion">4.5</a>).</p>
</div>
<div id="multi-response-bernoulli-models" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Multi-response Bernoulli Models<a href="multi.html#multi-response-bernoulli-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As in single-response models, Bernoulli responses require some thought because the <span class="math inline">\(\texttt{units}\)</span> variance is not identifiable in the likelihood. However, the <span class="math inline">\(\texttt{units}\)</span> correlation between a Bernoulli response and other responses (including other Bernoulli responses) is identifiable. To explore multi-response Bernoulli models we will use longitudinal data collected on patients with primary biliary cirrhosis from the Mayo Clinic. The data are available from the <span class="math inline">\(\texttt{survival}\)</span> package</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="multi.html#cb243-1" tabindex="-1"></a><span class="fu">data</span>(pbc)</span>
<span id="cb243-2"><a href="multi.html#cb243-2" tabindex="-1"></a><span class="fu">head</span>(pbcseq[, <span class="fu">c</span>(<span class="st">&quot;id&quot;</span>, <span class="st">&quot;age&quot;</span>, <span class="st">&quot;sex&quot;</span>, <span class="st">&quot;ascites&quot;</span>, <span class="st">&quot;bili&quot;</span>, <span class="st">&quot;hepato&quot;</span>)])</span></code></pre></div>
<pre><code>##   id      age sex ascites bili hepato
## 1  1 58.76523   f       1 14.5      1
## 2  1 58.76523   f       1 21.3      1
## 3  2 56.44627   f       0  1.1      1
## 4  2 56.44627   f       0  0.8      1
## 5  2 56.44627   f       0  1.0      1
## 6  2 56.44627   f       0  1.9      1</code></pre>
<p>The data consist of 1945 records from 312 patients (<span class="math inline">\(\texttt{id}\)</span>). The age and sex of the patient were recorded and whether they suffered from ascites (<span class="math inline">\(\texttt{ascites}\)</span>) and hepatomegaly or enlarged liver (<span class="math inline">\(\texttt{hepato}\)</span>). The serum concentration of bilirunbin was also recorded (<span class="math inline">\(\texttt{bili}\)</span>). We will consider two multi-response models.</p>
<div id="bern-gaus-sec" class="section level3 hasAnchor" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Bernoulli-Gaussian<a href="multi.html#bern-gaus-sec" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>First, we will simultaneously model log(<span class="math inline">\(\texttt{bili}\)</span>) as Gaussian and <span class="math inline">\(\texttt{ascites}\)</span> as Bernoulli with threshold link (probit). As we will see, in multi-response models, modelling Bernoulli responses as <span class="math inline">\(\texttt{family=&quot;threshold&quot;}\)</span> has some nice advantages.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="multi.html#cb245-1" tabindex="-1"></a>prior.pbc1 <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">R =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="fu">diag</span>(<span class="dv">2</span>), <span class="at">nu =</span> <span class="fl">1.002</span>, <span class="at">fix =</span> <span class="dv">2</span>), <span class="at">G =</span> <span class="fu">F</span>(<span class="dv">2</span>, <span class="dv">1000</span>))</span>
<span id="cb245-2"><a href="multi.html#cb245-2" tabindex="-1"></a></span>
<span id="cb245-3"><a href="multi.html#cb245-3" tabindex="-1"></a>m.pbc1 <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(<span class="fu">cbind</span>(<span class="fu">log</span>(bili), ascites) <span class="sc">~</span> trait <span class="sc">-</span> <span class="dv">1</span> <span class="sc">+</span> trait<span class="sc">:</span>(age <span class="sc">+</span> sex), <span class="at">random =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>id,</span>
<span id="cb245-4"><a href="multi.html#cb245-4" tabindex="-1"></a>    <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>units, <span class="at">data =</span> pbcseq, <span class="at">family =</span> <span class="fu">c</span>(<span class="st">&quot;gaussian&quot;</span>, <span class="st">&quot;threshold&quot;</span>),</span>
<span id="cb245-5"><a href="multi.html#cb245-5" tabindex="-1"></a>    <span class="at">prior =</span> prior.pbc1, <span class="at">longer =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>One difference from the previous model on car and holiday expenditure is that I’ve added some predictors to the fixed effect model. Interacting <span class="math inline">\(\texttt{trait}\)</span> with <code>age+sex</code> fits an <span class="math inline">\(\texttt{age}\)</span> effect for each trait and a <span class="math inline">\(\texttt{sex}\)</span> effect for each trait. If <code>age+sex</code> had not been interacted with <span class="math inline">\(\texttt{trait}\)</span> the effects of the predictors are assumed to be the same for the two traits. It is also possible to specify response-specific fixed-effect models using the function <span class="math inline">\(\texttt{at.level}\)</span>. For example, <span class="math inline">\(\texttt{at.level(trait, 1):(age+sex)+at.level(trait, 2):(sex)}\)</span> would fit an age and sex effect for <span class="math inline">\(\texttt{trait}\)</span> 1 (log(<span class="math inline">\(\texttt{bili}\)</span>)) and a sex effect for <span class="math inline">\(\texttt{trait}\)</span> 2 (<span class="math inline">\(\texttt{ascites}\)</span>)<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a>. The main difference, however, from the previous model of two Gaussian responses is that <code>fix=2</code> has been added to the prior specification. For a <span class="math inline">\(2\times 2\)</span> covariance matrix this simply fixes the second variance (the <span class="math inline">\(\texttt{units}\)</span> variance for the Bernoulli trait, <span class="math inline">\(\texttt{ascites}\)</span>) at whatever is specified in <span class="math inline">\(\texttt{V}\)</span> (1 in this case)<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a>. However, the <span class="math inline">\(\texttt{units}\)</span> variance for the Gaussian trait, and the <span class="math inline">\(\texttt{units}\)</span> covariance between the Gaussian and Bernoulii trait, are still estimated.</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="multi.html#cb246-1" tabindex="-1"></a><span class="fu">summary</span>(m.pbc1)</span></code></pre></div>
<pre><code>## 
##  Iterations = 30001:129901
##  Thinning interval  = 100
##  Sample size  = 1000 
## 
##  DIC: 4333.734 
## 
##  G-structure:  ~us(trait):id
## 
##                              post.mean l-95% CI u-95% CI eff.samp
## traitbili:traitbili.id          1.0291   0.8707   1.2147    810.6
## traitascites:traitbili.id       0.6457   0.4465   0.8523   1000.0
## traitbili:traitascites.id       0.6457   0.4465   0.8523   1000.0
## traitascites:traitascites.id    0.8721   0.4709   1.2919    808.9
## 
##  R-structure:  ~us(trait):units
## 
##                                 post.mean l-95% CI u-95% CI eff.samp
## traitbili:traitbili.units          0.3197   0.2982   0.3421    912.9
## traitascites:traitbili.units       0.2673   0.2205   0.3113   1000.0
## traitbili:traitascites.units       0.2673   0.2205   0.3113   1000.0
## traitascites:traitascites.units    1.0000   1.0000   1.0000      0.0
## 
##  Location effects: cbind(log(bili), ascites) ~ trait - 1 + trait:(age + sex) 
## 
##                   post.mean  l-95% CI  u-95% CI eff.samp  pMCMC    
## traitbili          1.371771  0.592765  2.075652   1000.0 &lt;0.001 ***
## traitascites      -3.060259 -4.055639 -2.021530   1000.0 &lt;0.001 ***
## traitbili:age     -0.004100 -0.016049  0.006663   1000.0  0.464    
## traitascites:age   0.027939  0.012933  0.042015    573.4  0.002 ** 
## traitbili:sexf    -0.446576 -0.851819 -0.069735   1000.0  0.032 *  
## traitascites:sexf  0.033496 -0.468967  0.494346   1000.0  0.898    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We can see that the covariance between the traits is strongly positive both across and within patients. Patients with constitutively high concentrations of bilirunbin are prone to ascites, and periods when a patient has high concentrations of bilirunbin they are more prone to ascites. Looking at the correlations can give a better feel for the magnitude of the associations.</p>
<div class="figure"><span style="display:block;" id="fig:pbc1-cor"></span>
<img src="_bookdown_files/fig/pbc1-cor-1.png" alt="Posterior distributions for the correlations between log($\texttt{bili}$) and the presence of ascites (on the latent scale)." width="672" />
<p class="caption">
Figure 7.4: Posterior distributions for the correlations between log(<span class="math inline">\(\texttt{bili}\)</span>) and the presence of ascites (on the latent scale).
</p>
</div>
<p>In the model with two Gaussian responses we also thought about the association between the two traits in terms of regression. If we follow the same recipe for the Bernoulii response (<span class="math inline">\(\texttt{ascites}\)</span>) regressed on the Gaussian response (log(<span class="math inline">\(\texttt{bili}\)</span>)) we end up with regression coefficients had we fitted log(<span class="math inline">\(\texttt{bili}\)</span>) as a predictor and also the true expected log(<span class="math inline">\(\texttt{bili}\)</span>) of each patient (which of course we don’t know, but constitute the <span class="math inline">\(\texttt{id}\)</span> effects for that trait). The change in the risk of <span class="math inline">\(\texttt{acites}\)</span> when increasing a patient’s log(<span class="math inline">\(\texttt{bili}\)</span>) by one unit is greater than the difference in risk between two patient’s that on average differ in log(<span class="math inline">\(\texttt{bili}\)</span>) by one unit (Figure <a href="multi.html#fig:pbc1-reg">7.5</a>).</p>
<div class="figure"><span style="display:block;" id="fig:pbc1-reg"></span>
<img src="_bookdown_files/fig/pbc1-reg-1.png" alt="MCMC trace plot of the coefficient from a probit regression of ascites presence ($\texttt{ascites}$) on log serum concentration of bilirunbin ($\texttt{bili}$). The red and blue traces are from a model where the regression coefficient is estimated at two levels: within an individual (blue) and across individuals (red)." width="672" />
<p class="caption">
Figure 7.5: MCMC trace plot of the coefficient from a probit regression of ascites presence (<span class="math inline">\(\texttt{ascites}\)</span>) on log serum concentration of bilirunbin (<span class="math inline">\(\texttt{bili}\)</span>). The red and blue traces are from a model where the regression coefficient is estimated at two levels: within an individual (blue) and across individuals (red).
</p>
</div>
<p>Note that this conclusion is opposite to the one you might draw from looking at the correlations. Why? The reason is that the proportion of variation that is within patients (Section <a href="ranef.html#ICC">4.4</a>) is quite different for the two traits: for log(<span class="math inline">\(\texttt{bili}\)</span>) the posterior mean is 0.24 and for <span class="math inline">\(\texttt{acites}\)</span> it is 0.54. The within-patient effects for log(<span class="math inline">\(\texttt{bili}\)</span>) have proportionally little variation yet they still strongly correlate with the within-patient <span class="math inline">\(\texttt{acites}\)</span> effects which have proportionally greater variation. We can also more formally assess whether the within-patient (<span class="math inline">\(\texttt{units}\)</span>) regression is stronger than the between-patient regression:</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="multi.html#cb248-1" tabindex="-1"></a>preg.id <span class="ot">&lt;-</span> m.pbc1<span class="sc">$</span>VCV[, <span class="st">&quot;traitbili:traitascites.id&quot;</span>]<span class="sc">/</span>m.pbc1<span class="sc">$</span>VCV[, <span class="st">&quot;traitbili:traitbili.id&quot;</span>]</span>
<span id="cb248-2"><a href="multi.html#cb248-2" tabindex="-1"></a>preg.units <span class="ot">&lt;-</span> m.pbc1<span class="sc">$</span>VCV[, <span class="st">&quot;traitbili:traitascites.units&quot;</span>]<span class="sc">/</span>m.pbc1<span class="sc">$</span>VCV[, <span class="st">&quot;traitbili:traitbili.units&quot;</span>]</span>
<span id="cb248-3"><a href="multi.html#cb248-3" tabindex="-1"></a><span class="fu">HPDinterval</span>(preg.units <span class="sc">-</span> preg.id)</span></code></pre></div>
<pre><code>##            lower     upper
## var1 -0.02136848 0.4267755
## attr(,&quot;Probability&quot;)
## [1] 0.95</code></pre>
<p>The 95% credible interval overlaps zero, just.</p>
<p>If we consider the opposite regression - the Gaussian response (log(<span class="math inline">\(\texttt{bili}\)</span>)) on the Bernoulii response (<span class="math inline">\(\texttt{ascites}\)</span>) things aren’t quite as straight forward. In a single response-model the actual presence or not of <span class="math inline">\(\texttt{ascites}\)</span> would be fitted, yet in the multi response-model the association is at the level of the latent variable. As noted above for car accidents and insurance payouts, there is an important distinction between measuring an association directly on the data scale versus the latent scale. However, when Bernoulli models are conceptualised in terms of threshold models we can make this distinction disappear. If we designate the Gaussian response as <span class="math inline">\(y\)</span> and the Bernoulli response as <span class="math inline">\(x\)</span> (0 or 1) with associated latent variable <span class="math inline">\(l\)</span>, we can calculate the two expectations</p>
<p><span class="math display">\[E[y|x=1]=E[y | l&gt;0]\]</span></p>
<p>and</p>
<p><span class="math display">\[E[y|x=0]=E[y | l&lt;0]\]</span></p>
<p>The difference between these expectations is the coefficient you would obtain by fitting the Bernoulli variable (<span class="math inline">\(\texttt{ascites}\)</span>) as a predictor in a model for the Gaussian response (log(<span class="math inline">\(\texttt{bili}\)</span>)). The difference is given by</p>
<p><span class="math display">\[E[y|x=1]-E[y|x=0]=\frac{f_N(\alpha)\sigma^2_{y,l}}{F_N(\alpha)(1-F_N(\alpha))\sigma_{l}}\]</span></p>
<p>where <span class="math inline">\(f_N\)</span> and <span class="math inline">\(F_N\)</span> are the density and cumulative density functions for the unit normal, and <span class="math inline">\(\alpha = \mu_l/\sigma_{l}\)</span><a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a>.</p>
<p>We can visualise what we have done. Figure <a href="multi.html#fig:biserial">7.6</a> plots the 95% prediction interval for the latent variable associated with <span class="math inline">\(\texttt{ascites}\)</span> presence (x-axis) and log(<span class="math inline">\(\texttt{bili}\)</span>) (y-axis) assuming the mean is at the central black point (this is the posterior mean prediction for the data). Conditioning on the posterior mean estimates of <span class="math inline">\({\bf V}_{\texttt{id}}\)</span> and <span class="math inline">\({\bf V}_{\texttt{units}}\)</span>, the predictive distribution is multivariate normal with covariance matrix <span class="math inline">\({\bf V}_{\texttt{id}}+{\bf V}_{\texttt{units}}\)</span> and so the 95% prediction interval is an ellipse. When the latent variable exceeds zero (vertical dashed line) the <span class="math inline">\(y=1\)</span> (<span class="math inline">\(\texttt{ascites}\)</span> is present). Consequently, the blue shaded area is the region of the predictive distribution for individuals with <span class="math inline">\(\texttt{ascites}\)</span> and the white region of the ellipse is for individuals without <span class="math inline">\(\texttt{ascites}\)</span>. The expectation of <span class="math inline">\(log(\texttt{bili})\)</span> for these two groups are plotted as arrows.</p>
<div class="figure"><span style="display:block;" id="fig:biserial"></span>
<img src="_bookdown_files/fig/biserial-1.png" alt="Representation of a Gaussian ($log(\texttt{bili})$) and Bernoulli ($\texttt{ascites}$) multi-response model. The ellipse is the 95% prediction interval for the Gaussian trait and the Bernoulli latent variable (on the probit scale). Observations to the right of the threshold (vertical dashed line) are successes and have $\texttt{ascites}$ and those to the left do not. The means of the Gaussian variable in these two groups are plotted as arrows." width="672" />
<p class="caption">
Figure 7.6: Representation of a Gaussian (<span class="math inline">\(log(\texttt{bili})\)</span>) and Bernoulli (<span class="math inline">\(\texttt{ascites}\)</span>) multi-response model. The ellipse is the 95% prediction interval for the Gaussian trait and the Bernoulli latent variable (on the probit scale). Observations to the right of the threshold (vertical dashed line) are successes and have <span class="math inline">\(\texttt{ascites}\)</span> and those to the left do not. The means of the Gaussian variable in these two groups are plotted as arrows.
</p>
</div>
<p>We can also plot the MCMC trace of the difference, and we can see that the difference is large and certainly not zero.</p>
<div class="figure"><span style="display:block;" id="fig:pbc1-reg2"></span>
<img src="_bookdown_files/fig/pbc1-reg2-1.png" alt="MCMC trace plot of the regression coefficient of log serum concentration of bilirunbin ($\texttt{bili}$) on ascites presence ($\texttt{ascites}$) as obtained from a multi-response model. " width="672" />
<p class="caption">
Figure 7.7: MCMC trace plot of the regression coefficient of log serum concentration of bilirunbin (<span class="math inline">\(\texttt{bili}\)</span>) on ascites presence (<span class="math inline">\(\texttt{ascites}\)</span>) as obtained from a multi-response model.
</p>
</div>
</div>
<div id="all-bernoulli" class="section level3 hasAnchor" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> All Bernoulli<a href="multi.html#all-bernoulli" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can also consider a bivariate model of the two Bernoulli variables <span class="math inline">\(\texttt{ascites}\)</span> and <span class="math inline">\(\texttt{hepato}\)</span>. The model set-up is almost identical, although we need to add the constraint that the residual variances of both traits are not identifiable in the likelihood but the residual correlation is: we need o restrict the residual covariance matrix to a residual correlation matrix. Replacing the <span class="math inline">\(\texttt{us}\)</span> variance structure with <span class="math inline">\(\texttt{corg}\)</span> achieves this. The prior specification only requires a degree-belief parameter <span class="math inline">\(\texttt{nu}\)</span> which results in a beta distribution for each correlation with shape and scale equal to <span class="math inline">\((\texttt{nu}-k+1)/2\)</span>. Since <span class="math inline">\(k=2\)</span>, I set <span class="math inline">\(\texttt{nu}=3\)</span> which results in a flat prior for the correlation. Note that specifying the marginal prior <code>F(2,1000)</code> for the (co)variance matrix of <span class="math inline">\(\texttt{id}\)</span> effects also results in <span class="math inline">\(\texttt{nu}=3\)</span> (See Section <a href="cat-int.html#VCVprior-r-sec">5.3.2</a>).</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="multi.html#cb251-1" tabindex="-1"></a>prior.pbc2 <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">R =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="fu">diag</span>(<span class="dv">2</span>), <span class="at">nu =</span> <span class="dv">3</span>), <span class="at">G =</span> <span class="fu">F</span>(<span class="dv">2</span>, <span class="dv">1000</span>))</span>
<span id="cb251-2"><a href="multi.html#cb251-2" tabindex="-1"></a></span>
<span id="cb251-3"><a href="multi.html#cb251-3" tabindex="-1"></a>m.pbc2 <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(<span class="fu">cbind</span>(hepato, ascites) <span class="sc">~</span> trait <span class="sc">-</span> <span class="dv">1</span> <span class="sc">+</span> trait<span class="sc">:</span>(age <span class="sc">+</span> sex), <span class="at">random =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>id,</span>
<span id="cb251-4"><a href="multi.html#cb251-4" tabindex="-1"></a>    <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">corg</span>(trait)<span class="sc">:</span>units, <span class="at">data =</span> pbcseq, <span class="at">family =</span> <span class="fu">c</span>(<span class="st">&quot;threshold&quot;</span>, <span class="st">&quot;threshold&quot;</span>),</span>
<span id="cb251-5"><a href="multi.html#cb251-5" tabindex="-1"></a>    <span class="at">prior =</span> prior.pbc2, <span class="at">longer =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>On the latent scale we see a reasonably strong correlation between the two outcomes:</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="multi.html#cb252-1" tabindex="-1"></a><span class="fu">summary</span>(m.pbc2)</span></code></pre></div>
<pre><code>## 
##  Iterations = 30001:129901
##  Thinning interval  = 100
##  Sample size  = 1000 
## 
##  DIC: 
## 
##  G-structure:  ~us(trait):id
## 
##                              post.mean l-95% CI u-95% CI eff.samp
## traithepato:traithepato.id      1.8991   1.3529    2.525     1000
## traitascites:traithepato.id     0.9516   0.6336    1.296     1000
## traithepato:traitascites.id     0.9516   0.6336    1.296     1000
## traitascites:traitascites.id    1.0250   0.5998    1.520      849
## 
##  R-structure:  ~corg(trait):units
## 
##                                 post.mean l-95% CI u-95% CI eff.samp
## traithepato:traithepato.units      1.0000  1.00000   1.0000        0
## traitascites:traithepato.units     0.2441  0.08559   0.4155     1000
## traithepato:traitascites.units     0.2441  0.08559   0.4155     1000
## traitascites:traitascites.units    1.0000  1.00000   1.0000        0
## 
##  Location effects: cbind(hepato, ascites) ~ trait - 1 + trait:(age + sex) 
## 
##                   post.mean  l-95% CI  u-95% CI eff.samp  pMCMC    
## traithepato        0.377939 -0.699259  1.422358     1000  0.492    
## traitascites      -3.051553 -4.090771 -1.907037     1000 &lt;0.001 ***
## traithepato:age    0.007085 -0.009985  0.023202     1000  0.408    
## traitascites:age   0.024262  0.007002  0.038508     1000  0.004 ** 
## traithepato:sexf  -0.577105 -1.112530 -0.013496     1000  0.044 *  
## traitascites:sexf  0.118815 -0.391260  0.657897     1000  0.658    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>If we wish, we can also characterise the relationship in terms of a contingency table. The model defines a multivariate normal distribution of latent variables around the fixed-effect prediction, and the probability of falling in any of the four quadrants defined by the origin can be calculated. We can imagine a population of individuals all of which have the same expected latent variables (the weighted average of the male and female means at the average age, where the weights are the frequencies of males and females in the data frame):</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="multi.html#cb254-1" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb254-2"><a href="multi.html#cb254-2" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(pbcseq)  <span class="co"># number of obseravtions</span></span>
<span id="cb254-3"><a href="multi.html#cb254-3" tabindex="-1"></a></span>
<span id="cb254-4"><a href="multi.html#cb254-4" tabindex="-1"></a>mu[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">predict</span>(m.pbc2, <span class="at">type =</span> <span class="st">&quot;terms&quot;</span>)[<span class="dv">1</span><span class="sc">:</span>nobs])</span>
<span id="cb254-5"><a href="multi.html#cb254-5" tabindex="-1"></a><span class="co"># predicted mean for hepato latent variable</span></span>
<span id="cb254-6"><a href="multi.html#cb254-6" tabindex="-1"></a></span>
<span id="cb254-7"><a href="multi.html#cb254-7" tabindex="-1"></a>mu[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">predict</span>(m.pbc2, <span class="at">type =</span> <span class="st">&quot;terms&quot;</span>)[nobs <span class="sc">+</span> <span class="dv">1</span><span class="sc">:</span>nobs])</span>
<span id="cb254-8"><a href="multi.html#cb254-8" tabindex="-1"></a><span class="co"># predicted mean for ascites latent variable</span></span></code></pre></div>
<p>Around these means the latent variables for a particular individual at a particular time (as a vector are) <span class="math inline">\({\bf u}_i+{\bf e}_{ij}\)</span>. These vectors are a drawn from a multivariate normal with zero mean and (co)variance <span class="math inline">\({\bf V}_{\texttt{id}}+{\bf V}_{\texttt{units}}\)</span>:</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="multi.html#cb255-1" tabindex="-1"></a>V <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">colMeans</span>(m.pbc2<span class="sc">$</span>VCV[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>] <span class="sc">+</span> m.pbc2<span class="sc">$</span>VCV[, <span class="dv">4</span> <span class="sc">+</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]), <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb255-2"><a href="multi.html#cb255-2" tabindex="-1"></a><span class="co"># posterior mean covariance matrix</span></span></code></pre></div>
<p>Figure <a href="multi.html#fig:terachoric">7.8</a> gives a visual representation of this distribution, and the quadrants that correspond to different outcomes.</p>
<div class="figure"><span style="display:block;" id="fig:terachoric"></span>
<img src="_bookdown_files/fig/terachoric-1.png" alt="Representation of a bivariate Bernoulli model. The solid point  represents the means of the two Bernoulli latent variables and the ellipse is the 95% prediction interval for the latent variables. The pair of latent variable lie in one of the four quadrants corresponding to the observed outcome (white: hepato=0 and ascites=0, pink: 1/0, blue: 0/1 and purple: 1/1)." width="672" />
<p class="caption">
Figure 7.8: Representation of a bivariate Bernoulli model. The solid point represents the means of the two Bernoulli latent variables and the ellipse is the 95% prediction interval for the latent variables. The pair of latent variable lie in one of the four quadrants corresponding to the observed outcome (white: hepato=0 and ascites=0, pink: 1/0, blue: 0/1 and purple: 1/1).
</p>
</div>
<p>The raw contingency table for the data is:</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="multi.html#cb256-1" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">table</span>(<span class="at">hepato =</span> pbcseq<span class="sc">$</span>hepato, <span class="at">ascites =</span> pbcseq<span class="sc">$</span>ascites))</span></code></pre></div>
<pre><code>##       ascites
## hepato          0          1
##      0 0.49016481 0.01594896
##      1 0.41998937 0.07389686</code></pre>
<p>The <span class="math inline">\(\texttt{pmnorm}\)</span> function in the package <span class="math inline">\(\texttt{mnorm}\)</span> calculates the cumulative density function for the multivariate normal, and we can use this to calculate the four probabilities. I’ve done this in a rather long winded way so that the code could be extended to ordinal data that falls into more than two categories (Section <a href="glm.html#ordinal-sec">3.7</a>):</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="multi.html#cb258-1" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb258-2"><a href="multi.html#cb258-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb258-3"><a href="multi.html#cb258-3" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, n, m)</span>
<span id="cb258-4"><a href="multi.html#cb258-4" tabindex="-1"></a></span>
<span id="cb258-5"><a href="multi.html#cb258-5" tabindex="-1"></a>thresh1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="cn">Inf</span>, <span class="dv">0</span>, <span class="cn">Inf</span>)</span>
<span id="cb258-6"><a href="multi.html#cb258-6" tabindex="-1"></a>thresh2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="cn">Inf</span>, <span class="dv">0</span>, <span class="cn">Inf</span>)</span>
<span id="cb258-7"><a href="multi.html#cb258-7" tabindex="-1"></a></span>
<span id="cb258-8"><a href="multi.html#cb258-8" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n) {</span>
<span id="cb258-9"><a href="multi.html#cb258-9" tabindex="-1"></a>    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>m) {</span>
<span id="cb258-10"><a href="multi.html#cb258-10" tabindex="-1"></a>        lower <span class="ot">&lt;-</span> <span class="fu">c</span>(thresh1[i], thresh2[j])</span>
<span id="cb258-11"><a href="multi.html#cb258-11" tabindex="-1"></a>        upper <span class="ot">&lt;-</span> <span class="fu">c</span>(thresh1[i <span class="sc">+</span> <span class="dv">1</span>], thresh2[j <span class="sc">+</span> <span class="dv">1</span>])</span>
<span id="cb258-12"><a href="multi.html#cb258-12" tabindex="-1"></a>        P[i, j] <span class="ot">&lt;-</span> mnorm<span class="sc">::</span><span class="fu">pmnorm</span>(lower, upper, <span class="at">mean =</span> mu, <span class="at">sigma =</span> V)<span class="sc">$</span>prob</span>
<span id="cb258-13"><a href="multi.html#cb258-13" tabindex="-1"></a>    }</span>
<span id="cb258-14"><a href="multi.html#cb258-14" tabindex="-1"></a>}</span></code></pre></div>
<p>We don’t expect the predicted probabilities to perfectly match what is observed since the data are unbalanced (individuals vary in how many times they are observed) and individuals vary in their sex and age but our prediction is for a population of individuals that are in some way average. Nevertheless, the predicted probabilities are close:</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="multi.html#cb259-1" tabindex="-1"></a>P</span></code></pre></div>
<pre><code>##           [,1]       [,2]
## [1,] 0.4335509 0.01500272
## [2,] 0.4573340 0.09411244</code></pre>
</div>
</div>
<div id="wide-versus-long-format" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Wide versus Long Format<a href="multi.html#wide-versus-long-format" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the multi-response models we have fitted so far, all responses have been observed for every unit of observation. For example, there were no cases where a patient was assessed for <span class="math inline">\(\texttt{ascites}\)</span> but <span class="math inline">\(\texttt{bili}\)</span> was not measured. If there had been missing observations, these could have been recorded as <span class="math inline">\(\texttt{NA}\)</span> and <span class="math inline">\(\texttt{MCMCglmm}\)</span> will treat them as unknown observations to be sampled and averaged over. If the amount of missingness is low then this is generally not an issue. However, if there is a lot of missing data then updating the missing observations can be slow and result in poor mixing. In these cases it is usually best to store the data in long-format and remove the missing values <a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a>. When fitting multi-response models to long-format data it needs to be in a format shown in Equation <a href="multi.html#eq:multi">(7.1)</a>. There needs to be two columns in the data-frame: <span class="math inline">\(\texttt{family}\)</span> specifying the distribution for each observation and <span class="math inline">\(\texttt{trait}\)</span> which has factors indexing the observation type. In such cases the <span class="math inline">\(\texttt{family}\)</span> argument to <span class="math inline">\(\texttt{family}\)</span> should be <span class="math inline">\(\texttt{NULL}\)</span>.</p>
<p>In the next section we will fit a bivariate model to log(<span class="math inline">\(\texttt{bili}\)</span>) and the categorical variable <span class="math inline">\(\texttt{status}\)</span>. <span class="math inline">\(\texttt{status}\)</span> has three levels indicating whether the final outcome for the patient was censored (0) had a liver transplant (1) or died (2). Let’s reshape the data and add the necessary columns:</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="multi.html#cb261-1" tabindex="-1"></a>pbcseq_long <span class="ot">&lt;-</span> tidyr<span class="sc">::</span><span class="fu">pivot_longer</span>(pbcseq,</span>
<span id="cb261-2"><a href="multi.html#cb261-2" tabindex="-1"></a>  <span class="at">cols      =</span> <span class="fu">c</span>(status, bili),</span>
<span id="cb261-3"><a href="multi.html#cb261-3" tabindex="-1"></a>  <span class="at">values_to =</span> <span class="st">&quot;y&quot;</span>,</span>
<span id="cb261-4"><a href="multi.html#cb261-4" tabindex="-1"></a>  <span class="at">names_to =</span> <span class="st">&quot;trait&quot;</span>,</span>
<span id="cb261-5"><a href="multi.html#cb261-5" tabindex="-1"></a>  <span class="at">cols_vary =</span> <span class="st">&quot;slowest&quot;</span>)</span>
<span id="cb261-6"><a href="multi.html#cb261-6" tabindex="-1"></a><span class="co"># merge status and bili columns into a single column: y</span></span>
<span id="cb261-7"><a href="multi.html#cb261-7" tabindex="-1"></a><span class="co"># trait is the column indicating if y belongs to status or bili</span></span>
<span id="cb261-8"><a href="multi.html#cb261-8" tabindex="-1"></a></span>
<span id="cb261-9"><a href="multi.html#cb261-9" tabindex="-1"></a>pbcseq_long<span class="sc">$</span>trait<span class="ot">&lt;-</span><span class="fu">as.factor</span>(pbcseq_long<span class="sc">$</span>trait)</span>
<span id="cb261-10"><a href="multi.html#cb261-10" tabindex="-1"></a></span>
<span id="cb261-11"><a href="multi.html#cb261-11" tabindex="-1"></a>pbcseq_long<span class="sc">$</span>family <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">recode</span>(pbcseq_long<span class="sc">$</span>trait, <span class="at">bili =</span> <span class="st">&quot;gaussian&quot;</span>, <span class="at">status =</span> <span class="st">&quot;threshold&quot;</span>)</span>
<span id="cb261-12"><a href="multi.html#cb261-12" tabindex="-1"></a><span class="co"># family specifies the distribution type for the two sets of observations.</span></span></code></pre></div>
</div>
<div id="covu-sec" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Covariances between random and residual terms (<span class="math inline">\(\texttt{covu}\)</span>)<a href="multi.html#covu-sec" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the previous section we generated a long-format data-frame <span class="math inline">\(\texttt{pbcseq_long}\)</span> with the response variable <span class="math inline">\(\texttt{y}\)</span> being associated with two traits: <span class="math inline">\(\texttt{status}\)</span> with three levels and then the continuous variable <span class="math inline">\(\texttt{bili}\)</span>. In reality, <span class="math inline">\(\texttt{status}\)</span> is not a repeat-measure trait, it is the final outcome (censored, transplant or dead) duplicated across all of the patients records. Consequently we should only retain a single record:</p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="multi.html#cb262-1" tabindex="-1"></a>remove<span class="ot">&lt;-</span><span class="fu">with</span>(pbcseq_long, <span class="fu">duplicated</span>(id) <span class="sc">&amp;</span> trait<span class="sc">==</span><span class="st">&quot;status&quot;</span>)</span>
<span id="cb262-2"><a href="multi.html#cb262-2" tabindex="-1"></a><span class="co"># cols_vary = &quot;slowest&quot; in pivot_longer means status records are followed by bili</span></span>
<span id="cb262-3"><a href="multi.html#cb262-3" tabindex="-1"></a><span class="co"># Then, `remove` is TRUE for all status observations except the first for each id.</span></span>
<span id="cb262-4"><a href="multi.html#cb262-4" tabindex="-1"></a></span>
<span id="cb262-5"><a href="multi.html#cb262-5" tabindex="-1"></a>pbcseq_long<span class="ot">&lt;-</span>pbcseq_long[<span class="sc">-</span><span class="fu">which</span>(remove),]</span>
<span id="cb262-6"><a href="multi.html#cb262-6" tabindex="-1"></a></span>
<span id="cb262-7"><a href="multi.html#cb262-7" tabindex="-1"></a><span class="co"># rows of data-frame for first patient</span></span>
<span id="cb262-8"><a href="multi.html#cb262-8" tabindex="-1"></a><span class="fu">subset</span>(pbcseq_long[,<span class="fu">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;trait&quot;</span>, <span class="st">&quot;family&quot;</span>, <span class="st">&quot;id&quot;</span>)], id<span class="sc">==</span><span class="dv">1</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 4
##       y trait  family       id
##   &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;     &lt;int&gt;
## 1   2   status threshold     1
## 2  14.5 bili   gaussian      1
## 3  21.3 bili   gaussian      1</code></pre>
<p>In addition lets log transform <span class="math inline">\(\texttt{bili}\)</span> and turn <span class="math inline">\(\texttt{status}\)</span> into a 2-level outcome dead (1) or not (0):</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="multi.html#cb264-1" tabindex="-1"></a>pbcseq_long <span class="ot">&lt;-</span> pbcseq_long <span class="sc">%&gt;%</span></span>
<span id="cb264-2"><a href="multi.html#cb264-2" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">if_else</span>(trait <span class="sc">==</span> <span class="st">&quot;bili&quot;</span>, <span class="fu">log</span>(y), y))</span>
<span id="cb264-3"><a href="multi.html#cb264-3" tabindex="-1"></a>pbcseq_long <span class="ot">&lt;-</span> pbcseq_long <span class="sc">%&gt;%</span></span>
<span id="cb264-4"><a href="multi.html#cb264-4" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">if_else</span>(trait <span class="sc">==</span> <span class="st">&quot;status&quot;</span>, <span class="fu">as.numeric</span>(y <span class="sc">==</span> <span class="dv">2</span>), y))</span></code></pre></div>
<p>If we wish to model death and <span class="math inline">\(\texttt{bili}\)</span> simultaneously, the Bernoulli-Gaussian model covered in Section <a href="multi.html#bern-gaus-sec">7.2.1</a> seems appropriate. However, since we only have a single-record of <span class="math inline">\(\texttt{status}\)</span> for each patient, it doesn’t make sense to fit <span class="math inline">\(\texttt{id}\)</span> effects for <span class="math inline">\(\texttt{status}\)</span> as they are not identifiable from the <span class="math inline">\(\texttt{unit}\)</span> effects (which themselves have non-identifiable variance because <span class="math inline">\(\texttt{status}\)</span> is Bernoulli). However, <span class="math inline">\(\texttt{bili}\)</span> is repeat-measure and so it does make sense to fit <span class="math inline">\(\texttt{id}\)</span> effects for this traits. In addition, allowing the <span class="math inline">\(\texttt{id}\)</span> effects for <span class="math inline">\(\texttt{bili}\)</span> to be correlated with the <span class="math inline">\(\texttt{unit}\)</span> effects of <span class="math inline">\(\texttt{status}\)</span> also seems reasonable - perhaps the long-term concentration of bilirunbin dictates whether a patient will live or not. In Section <a href="cat-int.html#link-func-sec">5.2</a> we covered ways in which we could link two (or more) sets of random effects and estimate their covariance matrix. Here, we need to link a set of random effects with a set of residuals. <span class="math inline">\(\texttt{MCMCglmm}\)</span> allows the set of random effects appearing in the final random term of the <code>random</code> specification to be correlated with the set of residuals appearing in the first residual term of the <code>rcov</code> specification. The linking is specified by adding a <code>covu=TRUE</code> to the prior specification for the first residual term.</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="multi.html#cb265-1" tabindex="-1"></a>prior.pbc_long<span class="ot">&lt;-</span><span class="fu">list</span>(<span class="at">R=</span><span class="fu">list</span>(<span class="at">R1=</span><span class="fu">list</span>(<span class="at">V=</span><span class="fu">diag</span>(<span class="dv">2</span>),<span class="at">nu=</span><span class="dv">3</span>, <span class="at">covu=</span><span class="cn">TRUE</span>, <span class="at">fix=</span><span class="dv">2</span>), </span>
<span id="cb265-2"><a href="multi.html#cb265-2" tabindex="-1"></a>                            <span class="at">R2=</span><span class="fu">IW</span>(<span class="dv">1</span>, <span class="fl">0.002</span>)))</span>
<span id="cb265-3"><a href="multi.html#cb265-3" tabindex="-1"></a></span>
<span id="cb265-4"><a href="multi.html#cb265-4" tabindex="-1"></a>m.pbc_long<span class="ot">&lt;-</span><span class="fu">MCMCglmm</span>(y<span class="sc">~</span>trait<span class="dv">-1</span><span class="sc">+</span><span class="fu">at.level</span>(trait, <span class="st">&quot;bili&quot;</span>)<span class="sc">:</span>(age<span class="sc">+</span>sex)<span class="sc">-</span><span class="dv">1</span><span class="sc">+</span><span class="fu">at.level</span>(trait, <span class="st">&quot;status&quot;</span>)<span class="sc">:</span>sex, </span>
<span id="cb265-5"><a href="multi.html#cb265-5" tabindex="-1"></a>                <span class="at">random=</span><span class="sc">~</span><span class="fu">us</span>(<span class="fu">at.level</span>(trait, <span class="st">&quot;bili&quot;</span>))<span class="sc">:</span>id, </span>
<span id="cb265-6"><a href="multi.html#cb265-6" tabindex="-1"></a>                <span class="at">rcov=</span><span class="sc">~</span><span class="fu">us</span>(<span class="fu">at.level</span>(trait, <span class="st">&quot;status&quot;</span>))<span class="sc">:</span>id<span class="sc">+</span><span class="fu">us</span>(<span class="fu">at.level</span>(trait, <span class="st">&quot;bili&quot;</span>))<span class="sc">:</span>units, </span>
<span id="cb265-7"><a href="multi.html#cb265-7" tabindex="-1"></a>                <span class="at">data=</span>pbcseq_long, <span class="at">family=</span><span class="cn">NULL</span>, <span class="at">prior=</span>prior.pbc_long)</span></code></pre></div>
<p>The model specification requires a bit of unpacking. <code>trait-1</code> fits intercepts for both traits. <code>at.level(trait, "bili"):(age+sex)</code> fits an age effect and a sex effect to (log) <span class="math inline">\(\texttt{bili}\)</span> and <code>at.level(trait, "status"):sex</code> fits a sex effect for <span class="math inline">\(\texttt{status}\)</span>. <code>random=~us(at.level(trait, "bili")):id</code> fits <span class="math inline">\(\texttt{id}\)</span> effects for <span class="math inline">\(\texttt{bili}\)</span>. This works because <code>at.level(trait, "bili")</code> defines a vector of zero’s (if <span class="math inline">\(\texttt{trait}=\texttt{status}\)</span>) and one’s (if <span class="math inline">\(\texttt{trait}=\texttt{bili}\)</span>) for which random slopes are defined (see Chapter <a href="cont-int.html#cont-int">6</a>). Consequently, when <span class="math inline">\(\texttt{trait}=\texttt{status}\)</span> the model is <span class="math inline">\(0\times u =0\)</span> and when <span class="math inline">\(\texttt{trait}=\texttt{bili}\)</span> the model is <span class="math inline">\(1\times u =u\)</span>, where <span class="math inline">\(u\)</span> is the <span class="math inline">\(\texttt{id}\)</span> effect. Similarly, the first part of the residual specification <code>us(at.level(trait, "status")):id</code> defines a complementary set of residuals for <span class="math inline">\(\texttt{status}\)</span>. This works because for <span class="math inline">\(\texttt{status}\)</span> there is only one observation per level of <span class="math inline">\(\texttt{id}\)</span> and so the specification satisfies the condition for a residual: the effect must be unique to an observation. Using <code>us(at.level(trait, "status")):units</code> would also have satisfied this condition, but the levels in the residual specification need to correspond to those in the random term for them to be linked, hence <span class="math inline">\(\texttt{id}\)</span> was used rather than <span class="math inline">\(\texttt{units}\)</span>. Finally, we have a second residual component that defines the residuals for <span class="math inline">\(\texttt{bili}\)</span>: <code>us(at.level(trait, "bili")):units</code>. The prior for the first residual term (<span class="math inline">\(\texttt{R1}\)</span>) contains the argument <code>covu=TRUE</code> indicating that covariances between the set of residuals and the set of random effects defined by the final random term are present. The prior for the resulting (<span class="math inline">\(2\times 2\)</span>) covariance matrix is also specified here and the prior for the final random term (the only random term in this model) is omitted. Note that the variance structure is that specified by the residual term (<span class="math inline">\(\texttt{us}\)</span> in this instance). We have fixed the second variance in this covariance matrix to one, since these are the <span class="math inline">\(\texttt{unit}\)</span> effects for a Bernoulli trait and so the variance isn’t identified. Using <span class="math inline">\(\texttt{nu=3}\)</span> places a flat prior on the correlation (Section <a href="cat-int.html#VCVprior-r-sec">5.3.2</a>) but the marginal prior for the variance of the <span class="math inline">\(\texttt{id}\)</span> effects on <span class="math inline">\(\texttt{bili}\)</span> is inverse-Wishart with <span class="math inline">\(\texttt{V=1.5}\)</span> and <span class="math inline">\(\texttt{nu=2}\)</span>. Not ideal, but it is not possible to use parameter-expansion (Section <a href="ranef.html#PXprior-sec">4.6</a>) with <span class="math inline">\(\texttt{covu}\)</span> structures.</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="multi.html#cb266-1" tabindex="-1"></a><span class="fu">summary</span>(m.pbc_long)</span></code></pre></div>
<pre><code>## 
##  Iterations = 3001:12991
##  Thinning interval  = 10
##  Sample size  = 1000 
## 
##  DIC: 3890.949 
## 
##  G-structure:  ~us(at.level(trait, &quot;bili&quot;)):id
## 
##  G-R structure below
## 
##  R-structure:  ~us(at.level(trait, &quot;status&quot;)):id
## 
##                                                           post.mean l-95% CI
## at.level(trait, &quot;bili&quot;).id:at.level(trait, &quot;bili&quot;).id         1.048   0.8714
## at.level(trait, &quot;status&quot;).id:at.level(trait, &quot;bili&quot;).id       0.683   0.5624
## at.level(trait, &quot;bili&quot;).id:at.level(trait, &quot;status&quot;).id       0.683   0.5624
## at.level(trait, &quot;status&quot;).id:at.level(trait, &quot;status&quot;).id     1.000   1.0000
##                                                           u-95% CI eff.samp
## at.level(trait, &quot;bili&quot;).id:at.level(trait, &quot;bili&quot;).id       1.2256    828.9
## at.level(trait, &quot;status&quot;).id:at.level(trait, &quot;bili&quot;).id     0.7957   1132.5
## at.level(trait, &quot;bili&quot;).id:at.level(trait, &quot;status&quot;).id     0.7957   1132.5
## at.level(trait, &quot;status&quot;).id:at.level(trait, &quot;status&quot;).id   1.0000      0.0
## 
##                ~us(at.level(trait, &quot;bili&quot;)):units
## 
##                                                       post.mean l-95% CI
## at.level(trait, &quot;bili&quot;):at.level(trait, &quot;bili&quot;).units     0.319   0.2966
##                                                       u-95% CI eff.samp
## at.level(trait, &quot;bili&quot;):at.level(trait, &quot;bili&quot;).units   0.3388     1000
## 
##  Location effects: y ~ trait - 1 + at.level(trait, &quot;bili&quot;):(age + sex) - 1 + at.level(trait, &quot;status&quot;):sex 
## 
##                                post.mean l-95% CI u-95% CI eff.samp  pMCMC    
## traitbili                        2.22043  1.56302  2.86707     1112 &lt;0.001 ***
## traitstatus                     -0.20370 -0.34516 -0.04858     1000  0.006 ** 
## at.level(trait, &quot;bili&quot;):age     -0.01884 -0.02855 -0.00846     1000  0.004 ** 
## at.level(trait, &quot;bili&quot;):sexf    -0.56767 -0.93859 -0.22381     1093 &lt;0.001 ***
## sexm:at.level(trait, &quot;status&quot;)   0.73497  0.29862  1.16791     1000 &lt;0.001 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>There is a strong positive association between the expected long-term value of (log) <span class="math inline">\(\texttt{bili}\)</span> and whether a patient dies before the end of the study. Figure <a href="multi.html#fig:covu-r">7.9</a> shows the posterior distribution for the correlation in <span class="math inline">\(\texttt{id}\)</span> effects.</p>
<div class="figure"><span style="display:block;" id="fig:covu-r"></span>
<img src="_bookdown_files/fig/covu-r-1.png" alt="Posterior distribution of the correlation between patient effects on (log) $\texttt{bili}$ and residual $\texttt{status}$ (death) from model $\texttt{m.pbc_long}$." width="672" />
<p class="caption">
Figure 7.9: Posterior distribution of the correlation between patient effects on (log) <span class="math inline">\(\texttt{bili}\)</span> and residual <span class="math inline">\(\texttt{status}\)</span> (death) from model <span class="math inline">\(\texttt{m.pbc_long}\)</span>.
</p>
</div>
<p>A more usual way to fit this type of model is to use a single-response for death and simply fit the average of each patient’s (log) <span class="math inline">\(\texttt{bili}\)</span> as a predictor.</p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="multi.html#cb268-1" tabindex="-1"></a>pbcseq_status <span class="ot">&lt;-</span> <span class="fu">subset</span>(pbcseq_long, trait <span class="sc">==</span> <span class="st">&quot;status&quot;</span>)</span>
<span id="cb268-2"><a href="multi.html#cb268-2" tabindex="-1"></a>pbcseq_status<span class="sc">$</span>mean.bili <span class="ot">&lt;-</span> <span class="fu">with</span>(pbcseq, <span class="fu">tapply</span>(<span class="fu">log</span>(bili), id, mean))[pbcseq_status<span class="sc">$</span>id]</span>
<span id="cb268-3"><a href="multi.html#cb268-3" tabindex="-1"></a></span>
<span id="cb268-4"><a href="multi.html#cb268-4" tabindex="-1"></a>m.pbc_status <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(y <span class="sc">~</span> mean.bili, <span class="at">data =</span> pbcseq_status, <span class="at">family =</span> <span class="cn">NULL</span>, <span class="at">prior =</span> <span class="fu">list</span>(<span class="at">R =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="dv">1</span>,</span>
<span id="cb268-5"><a href="multi.html#cb268-5" tabindex="-1"></a>    <span class="at">fix =</span> <span class="dv">1</span>)))</span></code></pre></div>
<p>In Figure <a href="multi.html#fig:mu-vs-sing">7.10</a> the regression coefficient from the multi-response model (in black) is compared to that from the single-response model (in red) and we can see that the multi-response model gives a regression coefficient that is greater in magnitude<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a>.</p>
<div class="figure"><span style="display:block;" id="fig:mu-vs-sing"></span>
<img src="_bookdown_files/fig/mu-vs-sing-1.png" alt="Posterior distributions for the probit regression of $\texttt{status}$ (death) on a patient's (log) $\texttt{bili}$ value. The black trace is obtained from a multi-response model and the predictor is the expected value of log $\texttt{bili}$ for each patient, whereas the red trace is obtained from a single-response model and the predictor is the sample mean of log $\texttt{bili}$ for each patient." width="672" />
<p class="caption">
Figure 7.10: Posterior distributions for the probit regression of <span class="math inline">\(\texttt{status}\)</span> (death) on a patient’s (log) <span class="math inline">\(\texttt{bili}\)</span> value. The black trace is obtained from a multi-response model and the predictor is the expected value of log <span class="math inline">\(\texttt{bili}\)</span> for each patient, whereas the red trace is obtained from a single-response model and the predictor is the sample mean of log <span class="math inline">\(\texttt{bili}\)</span> for each patient.
</p>
</div>
<p>The reason for this pattern is that the coefficient in the single-response model is attenuated because of the measurement error in the expected (log) <span class="math inline">\(\texttt{bili}\)</span>. If <span class="math inline">\(r\)</span> is the correlation between the true value of a predictor and its measured value, we expect the regression using measured values to be equal to the regression obtained from the true values multiplied by <span class="math inline">\(r^2\)</span> (see Chapter <a href="measurement.html#measurement">9</a>). However, the attenuation is small in this example because on average <span class="math inline">\(\texttt{bili}\)</span> has been measured 6 times per patient and the within-patient variability is quite low - the intra-class correlation for log <span class="math inline">\(\texttt{bili}\)</span> from the multi-response model is 0.77. Together the <span class="math inline">\(r^2\)</span> is predicted to be 0.95 (<span class="math inline">\(\sigma^2_\texttt{bili.id}/(\sigma^2_\texttt{bili.id}+\sigma^2_\texttt{bili.units}/6)\)</span>) - almost identical to the attenuation seen. In addition to dealing with the attenuation, the multi-response model also makes more efficient use of the data when the design is unbalanced (some patients only have a single measurement whereas others have up to 16) and the posterior standard deviation of the regression coefficient is 0.06 from the multi-response model but 0.08 from the standard single response model.</p>
</div>
<div id="scaled-linear-predictors-texttttheta_scale" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Scaled linear predictors: <span class="math inline">\(\texttt{theta_scale}\)</span><a href="multi.html#scaled-linear-predictors-texttttheta_scale" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the previous sections of this Chapter we’ve often thought about multi-response models in terms of regression. In some cases, the regression coefficient was different at different levels. For example, in Section <a href="multi.html#bern-gaus-sec">7.2.1</a> the regression within patients differed from the regression across patients. In other cases, the regression coefficient was only fitted for specific levels. For example, in Section <a href="multi.html#covu-sec">7.4</a> the regression was only fitted across patients not within. Although we parameterised the model in terms of unstructured covariance matrices (<span class="math inline">\(\texttt{us}\)</span>) we could have fitted the same model parameterised in terms of regression coefficients and innovation variances using antedependence structures (see Section <a href="cont-int.html#ante-sec">6.5</a>). Sometimes, however, we would like a model where the regression is held constant across two or more levels but is allowed to be different (or zero) at others. The <span class="math inline">\(\texttt{theta_scale}\)</span> argument in <span class="math inline">\(\texttt{MCMCglmm}\)</span> allows two sets of parameters to be fitted that differ by a common scaling factor. For example, we may have two vectors of random effects <span class="math inline">\(\{{\bf u}_1 {\bf u}_2\}\)</span> that appear in the linear predictor of one set of observations and would like to fit the effects <span class="math inline">\(\{\theta_s{\bf u}_1 \theta_s{\bf u}_2\}\)</span> for another set of observations. By fitting the first set of effects for one trait (the predictor) and the second set of effects to the other trait (the response) we can hold the regression constant (<span class="math inline">\(\theta_s\)</span>) at the two levels defined by the random effects.</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="multi.html#cb269-1" tabindex="-1"></a><span class="co"># library(mlmRev) data(star)</span></span></code></pre></div>
</div>
<div id="multinomial-models" class="section level2 hasAnchor" number="7.6">
<h2><span class="header-section-number">7.6</span> Multinomial Models<a href="multi.html#multinomial-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The previous sections of this chapter have covered multi-response models where each response comes from a single parameter distribution. <span class="math inline">\(\texttt{MCMCglmm}\)</span> also allows some distributions that are multi-parameter such as the multinomial and a range of zero-flated distributions. The syntax for fitting these models is similar to that for multi-response models with <span class="math inline">\(\texttt{trait}\)</span> indexing the different parameters of the distribution and <span class="math inline">\(\texttt{units}\)</span> indexing the observation.</p>
<p>We will start with multinomial models where the response is the number of counts in two or more nominal categories. When the number of categories is two we have the binomial which was covered in Section <a href="glm.html#binom-sec">3.6</a>. In binomial models we condition on the total number of counts (the size) and the model is parameterised in terms of the probability of success, with failure being the base-line category. In multinomial models we also condition on the total number of counts and model the probabilities of belonging to each category. However, as with the binomial, if we have <span class="math inline">\(K\)</span> categories we only need to model <span class="math inline">\(K-1\)</span> parameters: if we know <span class="math inline">\(K-1\)</span> probabilities the final probability is known since the sum of all probabilities must equal one. Consequently, we chose a base-line category to which the other categories are compared to. As with binomial models the number in each category can be passed as columns using cbind or, if the total number of counts is one, the response can be passed as a single vector of categories for each observation. In both cases a logit-link is used and the base-line category is either the category associated with the final column or the first factor level if a single column is passed as the response.</p>
<p>To explore multinomial models we will analyse data collected by the Alaska Science Center on the prey items of seabirds breeding on Middleton Island in the Gulf of Alaska (soon to be renamed the Gulf of Canada) - <a href="https://www.sciencebase.gov/catalog/item/64134381d34eb496d1ce3c82">see here</a>. We will restrict ourselves to data obtained on the chicks of the wonderful Tufted Puffin. 44 different prey items were recorded but we will lump all but the top four prey items (Walleye pollock, Pacific herring, Pacific sand lance and Capelin) into a single category, <span class="math inline">\(\texttt{other}\)</span>. After a little formatting we have the data-frame <span class="math inline">\(\texttt{tufted_mm}\)</span>:</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="multi.html#cb270-1" tabindex="-1"></a><span class="fu">head</span>(tufted_mm)</span></code></pre></div>
<pre><code>##   Capelin Other Herring SandLance Pollock year month
## 1       0     0       0         1       0 1978   Jul
## 2       0     0       0         1       0 1978   Aug
## 3       0     0       0         6       0 1978   Aug
## 4       0     0       0         1       0 1978   Aug
## 5       0     0       0         1       0 1978   Aug
## 6       0     0       0         1       0 1978   Aug</code></pre>
<p>Each row corresponds to one of 565 samples and the first 5 columns are the counts of each prey item in the sample. The final two columns are the collection year (of which there are 0) and collection month (July or August). Figure <a href="multi.html#fig:tufted-num">7.11</a> plots the number of prey items for 150 random samples.</p>
<div class="figure"><span style="display:block;" id="fig:tufted-num"></span>
<img src="_bookdown_files/fig/tufted-num-1.png" alt="Number of prey items of different types in 150 randomly selected samples from Tufted Puffin chicks. The tick-marks on the x-axis delimit samples taken in the same year." width="864" />
<p class="caption">
Figure 7.11: Number of prey items of different types in 150 randomly selected samples from Tufted Puffin chicks. The tick-marks on the x-axis delimit samples taken in the same year.
</p>
</div>
<p>In terms of numbers, Capelin and the Pacific sand lance are the most common prey items, with ‘Other’ being the rarest</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="multi.html#cb272-1" tabindex="-1"></a><span class="fu">colMeans</span>(tufted_mm[, <span class="fu">c</span>(<span class="st">&quot;Other&quot;</span>, <span class="st">&quot;Herring&quot;</span>, <span class="st">&quot;Pollock&quot;</span>, <span class="st">&quot;SandLance&quot;</span>, <span class="st">&quot;Capelin&quot;</span>)])</span></code></pre></div>
<pre><code>##     Other   Herring   Pollock SandLance   Capelin 
## 0.5150442 1.1522124 0.6141593 1.6300885 1.7238938</code></pre>
<p>However, there is tremendous variation in the total number of prey items per sample and it looks as if those samples with many prey items are dominated by Capelin. The multinomial ignores (conditions on) the total number of prey items and essentially works with the proportions of each prey item, as shown in Figure <a href="multi.html#fig:tufted-prop">7.12</a>.</p>
<div class="figure"><span style="display:block;" id="fig:tufted-prop"></span>
<img src="_bookdown_files/fig/tufted-prop-1.png" alt="Proportion of prey items that are of each type in 150 randomly selected samples from Tufted Puffin chicks. The tick-marks on the x-axis delimit samples taken in the same year." width="864" />
<p class="caption">
Figure 7.12: Proportion of prey items that are of each type in 150 randomly selected samples from Tufted Puffin chicks. The tick-marks on the x-axis delimit samples taken in the same year.
</p>
</div>
<p>Once we control for the total number of prey items we see that Capelin actually makes up the lowest proportion of the diet and Pacific sand lance dominates:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="multi.html#cb274-1" tabindex="-1"></a>tot_counts <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(tufted_mm[, <span class="fu">c</span>(<span class="st">&quot;Other&quot;</span>, <span class="st">&quot;Herring&quot;</span>, <span class="st">&quot;Pollock&quot;</span>, <span class="st">&quot;SandLance&quot;</span>, <span class="st">&quot;Capelin&quot;</span>)])</span>
<span id="cb274-2"><a href="multi.html#cb274-2" tabindex="-1"></a><span class="fu">colMeans</span>(tufted_mm[, <span class="fu">c</span>(<span class="st">&quot;Other&quot;</span>, <span class="st">&quot;Herring&quot;</span>, <span class="st">&quot;Pollock&quot;</span>, <span class="st">&quot;SandLance&quot;</span>, <span class="st">&quot;Capelin&quot;</span>)]<span class="sc">/</span>tot_counts)</span></code></pre></div>
<pre><code>##     Other   Herring   Pollock SandLance   Capelin 
## 0.1971235 0.1316400 0.1449124 0.4062647 0.1200594</code></pre>
<p>It is also apparent from Figure <a href="multi.html#fig:tufted-prop">7.12</a> (and Figure <a href="multi.html#fig:tufted-num">7.11</a>) that samples from the same year seem to have very similar compositions. Although less obvious, it also looks like there will be overdispersion - even within years samples seem to vary in composition more than you would expect from multinomial sampling alone. In Figure <a href="multi.html#fig:tufted-sim">7.13</a> I have sampled from the multinomial with the probabilities given above and the observed total number of prey items for each of the 150 samples. It is clear that the simulated data are much less structured than the real data.</p>
<div class="figure"><span style="display:block;" id="fig:tufted-sim"></span>
<img src="_bookdown_files/fig/tufted-sim-1.png" alt="Simulated proportion of prey items that are of each type assuming that the probability of a prey item is constant over the samples. The tick-marks on the x-axis delimit samples taken in the same year." width="864" />
<p class="caption">
Figure 7.13: Simulated proportion of prey items that are of each type assuming that the probability of a prey item is constant over the samples. The tick-marks on the x-axis delimit samples taken in the same year.
</p>
</div>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="multi.html#cb276-1" tabindex="-1"></a>prior.tufted <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">R =</span> <span class="fu">IW</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">G =</span> <span class="fu">F</span>(<span class="dv">2</span>, <span class="dv">1000</span>))</span>
<span id="cb276-2"><a href="multi.html#cb276-2" tabindex="-1"></a>m.tufted <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(<span class="fu">cbind</span>(Herring, Pollock, Capelin, SandLance, Other) <span class="sc">~</span> trait <span class="sc">-</span></span>
<span id="cb276-3"><a href="multi.html#cb276-3" tabindex="-1"></a>    <span class="dv">1</span>, <span class="at">data =</span> tufted_mm, <span class="at">random =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>year, <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>units, <span class="at">family =</span> <span class="st">&quot;multinomial&quot;</span>,</span>
<span id="cb276-4"><a href="multi.html#cb276-4" tabindex="-1"></a>    <span class="at">longer =</span> <span class="dv">20</span>, <span class="at">prior =</span> prior.tufted, <span class="at">pr =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Multinomial models are difficult - both to fit and interpret. With <span class="math inline">\(K=5\)</span> categories we have <span class="math inline">\(K-1=4\)</span> latent variables (traits) that are the log-odds ratio of observing a particular prey item versus the base-line prey item, in this case <span class="math inline">\(\texttt{Other}\)</span>. Abbreviating the prey types by their initial the latent variables for sample <span class="math inline">\(i\)</span> in year <span class="math inline">\(j\)</span> are</p>
<p><span class="math display">\[
\begin{array}{rcl}
l_{ij,\texttt{H}} =&amp; \textrm{log}\left(\frac{Pr(\texttt{H}_{ij})}{Pr(\texttt{O}_{ij})}\right)&amp;= \beta^{(0)}_\texttt{H}+u_{j, \texttt{H}}+e_{ij, \texttt{H}}\\
l_{ij,\texttt{P}} =&amp; \textrm{log}\left(\frac{Pr(\texttt{P}_{ij})}{Pr(\texttt{O}_{ij})}\right)&amp;= \beta^{(0)}_\texttt{P}+u_{j, \texttt{P}}+e_{ij, \texttt{P}}\\
l_{ij,\texttt{C}} =&amp; \textrm{log}\left(\frac{Pr(\texttt{C}_{ij})}{Pr(\texttt{O}_{ij}}\right)&amp;= \beta^{(0)}_\texttt{C}+u_{j, \texttt{C}}+e_{ij, \texttt{C}}\\
l_{ij,\texttt{S}} =&amp; \textrm{log}\left(\frac{Pr(\texttt{S}_{ij})}{Pr(\texttt{O}_{ij}}\right)&amp;= \beta^{(0)}_\texttt{S}+u_{j, \texttt{S}}+e_{ij, \texttt{S}}\\
\end{array}
\]</span></p>
<p>where the <span class="math inline">\(\beta^{(0)}\)</span> are trait-specific intercepts, the <span class="math inline">\(u\)</span> are trait-specific year effects and and the <span class="math inline">\(e\)</span> are trait-observation specific <span class="math inline">\(\texttt{unit}\)</span> effects that capture overdispersion.</p>
<p>The difficulty, I think, is that the effects are comparisons with the base-line category, yet it is easy to forget this. For example, let’s imagine that Pollock and Herring appear in the diet completely independently of each other and so knowing there are many Pollock in a particular year is not informative about the abundance of Herring. It might then be tempting to assume that two sets of year effects, <span class="math inline">\(u_{\texttt{P}}\)</span> and <span class="math inline">\(u_{\texttt{H}}\)</span> are uncorrelated. However, they may be correlated through their shared dependence on ‘Other’ prey items:</p>
<p><span class="math display">\[
\begin{array}{rl}
Cov(l_{\texttt{H}}, l_{\texttt{P}}) =&amp; Cov(\textrm{log}(Pr(\texttt{H}))-\textrm{log}(Pr(\texttt{O})), \textrm{log}(Pr(\texttt{P}))-\textrm{log}(Pr(\texttt{O})))\\
=&amp; Cov(\textrm{log}(Pr(\texttt{H})), \textrm{log}(Pr(\texttt{P})))-Cov(\textrm{log}(Pr(\texttt{H})), \textrm{log}(Pr(\texttt{O})))\\
&amp;-Cov(\textrm{log}(Pr(\texttt{O})), \textrm{log}(Pr(\texttt{P})))+Var(\textrm{log}(Pr(\texttt{O})))\\
\end{array}
\]</span></p>
<p>Even if the (log) probabilities are uncorrelated between all pairs of prey items, the log-contrasts between pairs (the latent variables) are expected to be correlated. For example, if the probabilities of Pollock, Herring and Other are all uncorrelated the above equation simplifies to</p>
<p><span class="math display">\[
Cov(l_{\texttt{H}}, l_{\texttt{P}}) =Var(\textrm{log}(Pr(\texttt{O})))\\
\]</span></p>
<p>and a non-zero covariance exists whenever there is variation in the probability of success in the base-line category. Similarly, if we look at the variability in a particular latent variable we have:</p>
<p><span class="math display">\[
\begin{array}{rl}
Var(l_{\texttt{H}})=&amp;Var(\textrm{log}(Pr(\texttt{H}))-\textrm{log}(Pr(\texttt{O}))\\
=&amp;Var(\textrm{log}(Pr(\texttt{H})))+Var(\textrm{log}(Pr(\texttt{O})))-2Cov(\textrm{log}(Pr(\texttt{H})), \textrm{log}(Pr(\texttt{O}))) \\
\end{array}
\]</span></p>
<p>which simplifies to</p>
<p><span class="math display">\[
Var(l_{\texttt{H}})=Var(\textrm{log}(Pr(\texttt{H})))+Var(\textrm{log}(Pr(\texttt{O})))
\]</span></p>
<p>when the probabilities of Herring and Other are uncorrelated. When we fitted multi-response models previously we naturally assumed that a diagonal covariance matrix somehow represents a null - the two traits are independent of each other. However, the above results suggest that we may need to modify our null when thinking about multinomial models. If we think that the log probabilities have the same yearly variation for all categories, and categories are independent then our null for the covariance matrix of year effects would have <span class="math inline">\(2\sigma^2_{u}\)</span> along the diagonal and <span class="math inline">\(\sigma^2_{u}\)</span> on the off-diagonals. We can represent this as <span class="math inline">\({\bf V}_{\texttt{year}} = \sigma^2_{u}({\bf I}+{\bf J})\)</span> where <span class="math inline">\({\bf I}\)</span> and <span class="math inline">\({\bf J}\)</span> are <span class="math inline">\(4\times 4\)</span> identity and unit matrices, respectively<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a>. If we believe that the amount of yearly variation differs across categories, yet the categories remain independent then our null would be <span class="math inline">\({\bf V}_{\texttt{year}} = {\bf D}+\sigma^2_{\texttt{O}}{\bf J}\)</span> where <span class="math inline">\({\bf D}\)</span> is a diagonal matrix with four variances to be estimated in addition to <span class="math inline">\(\sigma^2_{\texttt{O}}\)</span>.</p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="multi.html#cb277-1" tabindex="-1"></a>m.tuftedb <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(<span class="fu">cbind</span>(Herring, Pollock, Capelin, SandLance, Other) <span class="sc">~</span> trait <span class="sc">-</span></span>
<span id="cb277-2"><a href="multi.html#cb277-2" tabindex="-1"></a>    <span class="dv">1</span>, <span class="at">data =</span> tufted_mm, <span class="at">random =</span> <span class="sc">~</span><span class="fu">idv</span>(<span class="dv">1</span> <span class="sc">+</span> trait)<span class="sc">:</span>year, <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>units,</span>
<span id="cb277-3"><a href="multi.html#cb277-3" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;multinomial&quot;</span>, <span class="at">longer =</span> <span class="dv">20</span>, <span class="at">prior =</span> prior.tufted, <span class="at">pr =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="multi.html#cb278-1" tabindex="-1"></a>m.tuftedc <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(<span class="fu">cbind</span>(Herring, Pollock, Capelin, SandLance, Other) <span class="sc">~</span> trait <span class="sc">-</span></span>
<span id="cb278-2"><a href="multi.html#cb278-2" tabindex="-1"></a>    <span class="dv">1</span>, <span class="at">data =</span> tufted_mm, <span class="at">random =</span> <span class="sc">~</span><span class="fu">idh</span>(trait)<span class="sc">:</span>year <span class="sc">+</span> year, <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>units,</span>
<span id="cb278-3"><a href="multi.html#cb278-3" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;multinomial&quot;</span>, <span class="at">longer =</span> <span class="dv">20</span>, <span class="at">prior =</span> prior.tufted, <span class="at">pr =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>The two latent variables are indexed as <code>trait</code>, and the unit of observation (<span class="math inline">\(i\)</span>) as <code>units</code>, as in multi-response models. As with binary models the residual variance is not identified, and can be set to any arbitrary value. For reasons that will become clearer later I like to work with the residual covariance matrix <span class="math inline">\(\frac{1}{J}({\bf I}+{\bf J})\)</span> where <span class="math inline">\({\bf I}\)</span> and <span class="math inline">\({\bf J}\)</span> are <span class="math inline">\(J-1\)</span> dimensional identity and unit matrices, respectively.</p>
<p>To start we will try a simple model with an intercept:</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="multi.html#cb279-1" tabindex="-1"></a><span class="fu">data</span>(SShorns)</span>
<span id="cb279-2"><a href="multi.html#cb279-2" tabindex="-1"></a>Ctable <span class="ot">&lt;-</span> <span class="fu">table</span>(SShorns<span class="sc">$</span>horn, SShorns<span class="sc">$</span>sex)</span></code></pre></div>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="multi.html#cb280-1" tabindex="-1"></a>IJ <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>) <span class="sc">*</span> (<span class="fu">diag</span>(<span class="dv">2</span>) <span class="sc">+</span> <span class="fu">matrix</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb280-2"><a href="multi.html#cb280-2" tabindex="-1"></a>prior <span class="ot">=</span> <span class="fu">list</span>(<span class="at">R =</span> <span class="fu">list</span>(<span class="at">V =</span> IJ, <span class="at">fix =</span> <span class="dv">1</span>))</span>
<span id="cb280-3"><a href="multi.html#cb280-3" tabindex="-1"></a>m5c<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(horn <span class="sc">~</span> trait <span class="sc">-</span> <span class="dv">1</span>, <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>units, <span class="at">prior =</span> prior, <span class="at">data =</span> SShorns,</span>
<span id="cb280-4"><a href="multi.html#cb280-4" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;categorical&quot;</span>)</span></code></pre></div>
<p>The posterior distribution for the intercepts is shown in Figure <a href="multi.html#fig:MN1">7.14</a>, and the model
clearly needs to be run for longer (Figure <a href="multi.html#fig:MN1">7.14</a>. However…</p>
<div class="figure"><span style="display:block;" id="fig:MN1"></span>
<img src="_bookdown_files/fig/MN1-1.png" alt="Posterior distribution of fixed effects from model `m5c.1`: a simple multinomial logit model with intercepts only}" width="672" />
<p class="caption">
Figure 7.14: Posterior distribution of fixed effects from model <code>m5c.1</code>: a simple multinomial logit model with intercepts only}
</p>
</div>
<p>The problem can also be represented using the contrast matrix <span class="math inline">\({\bf \Delta}\)</span> <span class="citation">(<a href="#ref-Bunch.1991">Bunch 1991</a>)</span>:</p>
<p><span class="math display">\[{\boldsymbol{\mathbf{\Delta}}}=
\left[
\begin{array}{c c}
-1&amp;-1\\
1&amp;0\\
0&amp;1\\
\end{array}
\right]\]</span></p>
<p>where the rows correspond to the factor levels (<code>normal</code>, <code>polled</code> and <code>scurred</code>) and the columns to the two latent variables. For example column one corresponds to <span class="math inline">\(l_{i,\textrm{polled}}\)</span> which on the log scale is
<span class="math inline">\(Pr(\texttt{horn[i]}=\textrm{polled}) - Pr(\texttt{horn[i]}=\textrm{normal})\)</span>.</p>
<p><span class="math display">\[\textrm{exp}\left(({\boldsymbol{\mathbf{\Delta}}}{\boldsymbol{\mathbf{\Delta}}}^{&#39;})^{-1}{\boldsymbol{\mathbf{\Delta}}}{\bf l}_{i}\right) \propto E\left[\begin{array}{c} Pr(\texttt{horn[i]}=\textrm{normal})\\ Pr(\texttt{horn[i]}=\textrm{polled})\\ Pr(\texttt{horn[i]}=\textrm{scurred}) \end{array} \right]\]</span></p>
<p>The residual and any random effect covariance matrices are for identifiability purposes estimated on the <span class="math inline">\(J-1\)</span> space with <span class="math inline">\({\boldsymbol{\mathbf{V}}}={\boldsymbol{\mathbf{\Delta}}}^{&#39;}\tilde{\bf V}{\boldsymbol{\mathbf{\Delta}}}\)</span> where <span class="math inline">\(\tilde{\bf V}\)</span> is the covariance matrix estimated on the <span class="math inline">\(J-1\)</span> space. To illustrate, we will rescale the intercepts as if the residual covariance matrix was zero (see Sections <a href="#pred-sec"><strong>??</strong></a> and <a href="cat-int.html#cat-int">5</a>) and predict the expected
probability for each horn type:</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="multi.html#cb281-1" tabindex="-1"></a>Delta <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb281-2"><a href="multi.html#cb281-2" tabindex="-1"></a>c2 <span class="ot">&lt;-</span> (<span class="dv">16</span> <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="dv">3</span>)<span class="sc">/</span>(<span class="dv">15</span> <span class="sc">*</span> pi))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb281-3"><a href="multi.html#cb281-3" tabindex="-1"></a>D <span class="ot">&lt;-</span> <span class="fu">ginv</span>(Delta <span class="sc">%*%</span> <span class="fu">t</span>(Delta)) <span class="sc">%*%</span> Delta</span>
<span id="cb281-4"><a href="multi.html#cb281-4" tabindex="-1"></a>Int <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">apply</span>(m5c<span class="fl">.1</span><span class="sc">$</span>Sol, <span class="dv">1</span>, <span class="cf">function</span>(x) {</span>
<span id="cb281-5"><a href="multi.html#cb281-5" tabindex="-1"></a>    D <span class="sc">%*%</span> (x<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> c2 <span class="sc">*</span> <span class="fu">diag</span>(IJ)))</span>
<span id="cb281-6"><a href="multi.html#cb281-6" tabindex="-1"></a>}))</span>
<span id="cb281-7"><a href="multi.html#cb281-7" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">mcmc</span>(<span class="fu">exp</span>(Int)<span class="sc">/</span><span class="fu">rowSums</span>(<span class="fu">exp</span>(Int))))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:1000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 1000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##        Mean      SD  Naive SE Time-series SE
## [1,] 0.6481 0.01841 0.0005822       0.001720
## [2,] 0.1029 0.01084 0.0003427       0.001352
## [3,] 0.2489 0.01635 0.0005171       0.001667
## 
## 2. Quantiles for each variable:
## 
##        2.5%     25%    50%    75%  97.5%
## var1 0.6116 0.63533 0.6485 0.6612 0.6825
## var2 0.0829 0.09554 0.1024 0.1099 0.1246
## var3 0.2169 0.23722 0.2488 0.2608 0.2800</code></pre>
<p>which agrees well with those observed:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="multi.html#cb283-1" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">rowSums</span>(Ctable))</span></code></pre></div>
<pre><code>##    normal    polled   scurred 
## 0.6531532 0.0975976 0.2492492</code></pre>
<p>To test for the effects of sex specific expression we can also fit a model with a sex effect:</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="multi.html#cb285-1" tabindex="-1"></a>m5c<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(horn <span class="sc">~</span> trait <span class="sc">+</span> sex <span class="sc">-</span> <span class="dv">1</span>, <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>units, <span class="at">data =</span> SShorns,</span>
<span id="cb285-2"><a href="multi.html#cb285-2" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;categorical&quot;</span>, <span class="at">prior =</span> prior)</span></code></pre></div>
<p>In this case we have not interacted sex with trait, and so we are estimating the difference between the sexes in their expression of normal and polled+scurred jointly. The posterior distribution is plotted in Figure <a href="multi.html#fig:MN2">7.15</a> and clearly shows that males are more likely to express the normal horn phenotype than females.</p>
<div class="figure"><span style="display:block;" id="fig:MN2"></span>
<img src="_bookdown_files/fig/MN2-1.png" alt="Posterior distribution of fixed effects from model `m5c.2` in which a main effect of sex was included" width="672" />
<p class="caption">
Figure 7.15: Posterior distribution of fixed effects from model <code>m5c.2</code> in which a main effect of sex was included
</p>
</div>
<p>A more general model would be to estimate separate probabilities for each cell, but the contingency table indicates that one cell (polled males) has zero counts which will cause extreme separation problems. We could choose to have a better prior for the fixed effects, that is close to being flat for the two-way (i.e. polled vs scurred, normal vs.scurred &amp; polled vs. normal) marginal probabilities within each sex:</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="multi.html#cb286-1" tabindex="-1"></a>prior<span class="sc">$</span>B <span class="ot">=</span> <span class="fu">list</span>(<span class="at">mu =</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>), <span class="at">V =</span> <span class="fu">kronecker</span>(IJ, <span class="fu">diag</span>(<span class="dv">2</span>)) <span class="sc">*</span> (<span class="fl">1.7</span> <span class="sc">+</span> pi<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>))</span>
<span id="cb286-2"><a href="multi.html#cb286-2" tabindex="-1"></a>m5c<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(horn <span class="sc">~</span> <span class="fu">at.level</span>(sex, <span class="dv">1</span>)<span class="sc">:</span>trait <span class="sc">+</span> <span class="fu">at.level</span>(sex, <span class="dv">2</span>)<span class="sc">:</span>trait <span class="sc">-</span> <span class="dv">1</span>, <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">us</span>(trait)<span class="sc">:</span>units,</span>
<span id="cb286-3"><a href="multi.html#cb286-3" tabindex="-1"></a>    <span class="at">data =</span> SShorns, <span class="at">family =</span> <span class="st">&quot;categorical&quot;</span>, <span class="at">prior =</span> prior)</span></code></pre></div>
<p>The female specific probabilities appear reasonable:</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="multi.html#cb287-1" tabindex="-1"></a>Int <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">apply</span>(m5c<span class="fl">.3</span><span class="sc">$</span>Sol[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="dv">1</span>, <span class="cf">function</span>(x) {</span>
<span id="cb287-2"><a href="multi.html#cb287-2" tabindex="-1"></a>    D <span class="sc">%*%</span> (x<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> c2 <span class="sc">*</span> <span class="fu">diag</span>(IJ)))</span>
<span id="cb287-3"><a href="multi.html#cb287-3" tabindex="-1"></a>}))</span>
<span id="cb287-4"><a href="multi.html#cb287-4" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">mcmc</span>(<span class="fu">exp</span>(Int)<span class="sc">/</span><span class="fu">rowSums</span>(<span class="fu">exp</span>(Int))))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:1000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 1000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##        Mean      SD  Naive SE Time-series SE
## [1,] 0.3451 0.02906 0.0009189       0.002056
## [2,] 0.2609 0.02726 0.0008620       0.002391
## [3,] 0.3941 0.03158 0.0009985       0.003846
## 
## 2. Quantiles for each variable:
## 
##        2.5%    25%    50%    75%  97.5%
## var1 0.2901 0.3258 0.3441 0.3640 0.4010
## var2 0.2109 0.2421 0.2594 0.2775 0.3185
## var3 0.3354 0.3723 0.3924 0.4157 0.4587</code></pre>
<p>compared to the observed frequencies:</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="multi.html#cb289-1" tabindex="-1"></a><span class="fu">prop.table</span>(Ctable[, <span class="dv">1</span>])</span></code></pre></div>
<pre><code>##    normal    polled   scurred 
## 0.3401639 0.2663934 0.3934426</code></pre>
<p>as do the male probabilities:</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="multi.html#cb291-1" tabindex="-1"></a>Int <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">apply</span>(<span class="fu">cbind</span>(m5c<span class="fl">.3</span><span class="sc">$</span>Sol[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>]), <span class="dv">1</span>, <span class="cf">function</span>(x) {</span>
<span id="cb291-2"><a href="multi.html#cb291-2" tabindex="-1"></a>    D <span class="sc">%*%</span> (x<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> c2 <span class="sc">*</span> <span class="fu">diag</span>(IJ)))</span>
<span id="cb291-3"><a href="multi.html#cb291-3" tabindex="-1"></a>}))</span>
<span id="cb291-4"><a href="multi.html#cb291-4" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">mcmc</span>(<span class="fu">exp</span>(Int)<span class="sc">/</span><span class="fu">rowSums</span>(<span class="fu">exp</span>(Int))))</span></code></pre></div>
<pre><code>## 
## Iterations = 1:1000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 1000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##         Mean       SD  Naive SE Time-series SE
## [1,] 0.83255 0.016714 0.0005285      0.0019138
## [2,] 0.00856 0.003264 0.0001032      0.0009153
## [3,] 0.15889 0.016290 0.0005151      0.0019286
## 
## 2. Quantiles for each variable:
## 
##          2.5%      25%      50%     75%   97.5%
## var1 0.797973 0.820923 0.833381 0.84392 0.86485
## var2 0.004052 0.006222 0.007649 0.01026 0.01652
## var3 0.127873 0.147763 0.158103 0.17068 0.19161</code></pre>
<p>compared to the observed frequencies:</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="multi.html#cb293-1" tabindex="-1"></a><span class="fu">prop.table</span>(Ctable[, <span class="dv">2</span>])</span></code></pre></div>
<pre><code>##    normal    polled   scurred 
## 0.8341232 0.0000000 0.1658768</code></pre>
</div>
<div id="zero-inflated-models" class="section level2 hasAnchor" number="7.7">
<h2><span class="header-section-number">7.7</span> Zero-inflated Models<a href="multi.html#zero-inflated-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Each datum in a zero-inflated model is associated with two latent variables. The first latent variable is associated with the named distribution and the second latent variable is associated with zero inflation. I’ll work through a zero-inflated Poisson (ZIP) model to make things clearer. As the name suggests, a ZIP distribution is a Poisson distribution with extra zero’s. The observed zeros are modelled as a mixture distribution of zero’s originating form the Poisson process and zero’s arising through zero-inflation. It is the probability (on the logit scale) that a zero is from the zero-inflation process that we aim to model with the second latent variable. The likelihood has the form:</p>
<p><span class="math display">\[\begin{array}{rl}
Pr(y=0) =&amp; \texttt{plogis}(l_{2})+\texttt{plogis}(-l_{2})\ast \texttt{dpois}(0, \texttt{exp}(l_{1}))\\
Pr(y | y&gt;0) =&amp; \texttt{plogis}(-l_{2})\ast \texttt{dpois}(y, \texttt{exp}(l_{1}))\\
\end{array}\]</span></p>
<p><span class="math inline">\(\texttt{pscl}\)</span> fits zero-inflated models very well through the <code>zeroinfl</code> function, and I strongly recommend using it if you do not want to fit random effects. To illustrate the syntax for fitting ZIP models in MCMCglmm I will take one of their examples:</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="multi.html#cb295-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;bioChemists&quot;</span>, <span class="at">package =</span> <span class="st">&quot;pscl&quot;</span>)</span>
<span id="cb295-2"><a href="multi.html#cb295-2" tabindex="-1"></a><span class="fu">head</span>(bioChemists)</span></code></pre></div>
<pre><code>##   art   fem     mar kid5  phd ment
## 1   0   Men Married    0 2.52    7
## 2   0 Women  Single    0 2.05    6
## 3   0 Women  Single    0 3.75    6
## 4   0   Men Married    1 1.18    3
## 5   0 Women  Single    0 3.75   26
## 6   0 Women Married    2 3.59    2</code></pre>
<p><code>art</code> is the response variable - the number of papers published by a Ph.D student - and the remaining variables are to be fitted as fixed effects. Naively, we may expect zero-inflation to be a problem given 30% of the data are zeros, and based on the global mean we only expect around 18%.</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="multi.html#cb297-1" tabindex="-1"></a><span class="fu">table</span>(bioChemists<span class="sc">$</span>art <span class="sc">==</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>## 
## FALSE  TRUE 
##   640   275</code></pre>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="multi.html#cb299-1" tabindex="-1"></a><span class="fu">ppois</span>(<span class="dv">0</span>, <span class="fu">mean</span>(bioChemists<span class="sc">$</span>art))</span></code></pre></div>
<pre><code>## [1] 0.1839859</code></pre>
<p>As with binary models we do not observe any residual variance for the zero-inflated process, and in addition the residual covariance between the zero-inflation and the Poisson process cannot be estimated because both processes cannot be observed in a single data point. To deal with this I’ve fixed the residual variance for the zero-inflation at 1, and the covariance is set to zero using the idh structure. Setting <code>V=diag(2)</code> and <code>nu=0.002</code> we have the inverse-gamma prior with <code>shape=scale=0.001</code> for the residual component of the Poisson process which captures overdispersion:</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="multi.html#cb301-1" tabindex="-1"></a>prior.m5d<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">list</span>(<span class="at">R =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="fu">diag</span>(<span class="dv">2</span>), <span class="at">nu =</span> <span class="fl">0.002</span>, <span class="at">fix =</span> <span class="dv">2</span>))</span>
<span id="cb301-2"><a href="multi.html#cb301-2" tabindex="-1"></a>m5d<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(art <span class="sc">~</span> trait <span class="sc">-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>fem <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>mar <span class="sc">+</span></span>
<span id="cb301-3"><a href="multi.html#cb301-3" tabindex="-1"></a>    <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>kid5 <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>phd <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>ment, <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">idh</span>(trait)<span class="sc">:</span>units,</span>
<span id="cb301-4"><a href="multi.html#cb301-4" tabindex="-1"></a>    <span class="at">data =</span> bioChemists, <span class="at">prior =</span> prior.m5d<span class="fl">.1</span>, <span class="at">family =</span> <span class="st">&quot;zipoisson&quot;</span>)</span></code></pre></div>
<p>As is often the case the parameters of the zero-inflation model mixes poorly (See Figure <a href="multi.html#fig:ZIP">7.16</a> especially when compared to equivalent hurdle models (See Section <a href="multi.html#Hurdle">7.8</a>). Poor mixing is often associated with distributions that may <em>not</em> be zero-inflated but instead overdispersed.</p>
<div class="figure"><span style="display:block;" id="fig:ZIP"></span>
<img src="_bookdown_files/fig/ZIP-1.png" alt="Posterior distribution of fixed effects from model `m5d.1` in which trait 1 ($\texttt{art}$) is the Poisson process and trait 2 ($\texttt{zi.art}$) is the zero-inflation." width="672" />
<p class="caption">
Figure 7.16: Posterior distribution of fixed effects from model <code>m5d.1</code> in which trait 1 (<span class="math inline">\(\texttt{art}\)</span>) is the Poisson process and trait 2 (<span class="math inline">\(\texttt{zi.art}\)</span>) is the zero-inflation.
</p>
</div>
<p>The model would have to be run for (much) longer to say something concrete about the level of zero-inflation but my guess would be it’s not a big issue, given the probability is probably quite small:</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="multi.html#cb302-1" tabindex="-1"></a><span class="fu">quantile</span>(<span class="fu">plogis</span>(m5d<span class="fl">.1</span><span class="sc">$</span>Sol[, <span class="dv">2</span>]<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> c2)))</span></code></pre></div>
<pre><code>##          0%         25%         50%         75%        100% 
## 0.002411913 0.006275172 0.008380651 0.012331379 0.068352559</code></pre>
<div id="posterior-predictive-checks" class="section level3 hasAnchor" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> Posterior predictive checks<a href="multi.html#posterior-predictive-checks" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another useful check is to fit the standard Poisson model and use posterior predictive checks to see how many zero’s you would expect under the simple model:</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="multi.html#cb304-1" tabindex="-1"></a>prior.m5d<span class="fl">.2</span> <span class="ot">=</span> <span class="fu">list</span>(<span class="at">R =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="fu">diag</span>(<span class="dv">1</span>), <span class="at">nu =</span> <span class="fl">0.002</span>))</span>
<span id="cb304-2"><a href="multi.html#cb304-2" tabindex="-1"></a>m5d<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(art <span class="sc">~</span> fem <span class="sc">+</span> mar <span class="sc">+</span> kid5 <span class="sc">+</span> phd <span class="sc">+</span> ment, <span class="at">data =</span> bioChemists, <span class="at">prior =</span> prior.m5d<span class="fl">.2</span>,</span>
<span id="cb304-3"><a href="multi.html#cb304-3" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;poisson&quot;</span>, <span class="at">saveX =</span> <span class="cn">TRUE</span>)</span>
<span id="cb304-4"><a href="multi.html#cb304-4" tabindex="-1"></a></span>
<span id="cb304-5"><a href="multi.html#cb304-5" tabindex="-1"></a>nz <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span></span>
<span id="cb304-6"><a href="multi.html#cb304-6" tabindex="-1"></a>oz <span class="ot">&lt;-</span> <span class="fu">sum</span>(bioChemists<span class="sc">$</span>art <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb304-7"><a href="multi.html#cb304-7" tabindex="-1"></a></span>
<span id="cb304-8"><a href="multi.html#cb304-8" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) {</span>
<span id="cb304-9"><a href="multi.html#cb304-9" tabindex="-1"></a>    pred.l <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">915</span>, (m5d<span class="fl">.2</span><span class="sc">$</span>X <span class="sc">%*%</span> m5d<span class="fl">.2</span><span class="sc">$</span>Sol[i, ])<span class="sc">@</span>x, <span class="fu">sqrt</span>(m5d<span class="fl">.2</span><span class="sc">$</span>VCV[i]))</span>
<span id="cb304-10"><a href="multi.html#cb304-10" tabindex="-1"></a>    nz[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">rpois</span>(<span class="dv">915</span>, <span class="fu">exp</span>(pred.l)) <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb304-11"><a href="multi.html#cb304-11" tabindex="-1"></a>}</span></code></pre></div>
<p>Figure <a href="multi.html#fig:PPZIP">7.17</a> shows a histogram of the posterior predictive distribution of zero’s (<code>nz</code>) from the model compared to the observed number of zeros (<code>oz</code>). The simpler model seems to be consistent with the data, suggesting that a ZIP model may not be required.</p>
<div class="figure"><span style="display:block;" id="fig:PPZIP"></span>
<img src="_bookdown_files/fig/PPZIP-1.png" alt="Posterior predictive distribution of zeros from model `m5d.2` with the observed number in red." width="672" />
<p class="caption">
Figure 7.17: Posterior predictive distribution of zeros from model <code>m5d.2</code> with the observed number in red.
</p>
</div>
</div>
</div>
<div id="Hurdle" class="section level2 hasAnchor" number="7.8">
<h2><span class="header-section-number">7.8</span> Hurdle Models<a href="multi.html#Hurdle" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hurdle models are very similar to zero-inflated models but they can be used to model zero-deflation as well as zero-inflation and seem to have much better mixing properties in <span class="math inline">\(\texttt{MCMCglmm}\)</span>. As in ZIP models each datum
in the hurdle model is associated with two latent variables. However, whereas in a ZIP model the first latent variable is the mean parameter of a Poisson distribution the equivalent latent variable in the hurdle model is the mean parameter of a zero-truncated Possion distribution (i.e. a Poisson distribution without the zeros observed). In addition the second latent variable in a ZIP model is the probability that an observed zero is due to zero-inflation rather than the Poisson process. In hurdle models the second latent variable is simply the probability (on the logit scale) that the response variable is zero or not. The likelihood is:</p>
<p><span class="math display">\[\begin{array}{rl}
Pr(y=0) =&amp; \texttt{plogis}(l_{2})\\
Pr(y | y&gt;0) =&amp; \texttt{plogis}(-l_{2})\ast \texttt{dpois}(y, \texttt{exp}(l_{1}))/(1-\texttt{ppois}(0, \texttt{exp}(l_{1})))\\
\end{array}\]</span></p>
<p>To illustrate, we will refit the ZIP model (<code>m5d.1</code>) as a hurdle-Poisson model.</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="multi.html#cb305-1" tabindex="-1"></a>m5d<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(art <span class="sc">~</span> trait <span class="sc">-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>fem <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>mar <span class="sc">+</span></span>
<span id="cb305-2"><a href="multi.html#cb305-2" tabindex="-1"></a>    <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>kid5 <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>phd <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>ment, <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">idh</span>(trait)<span class="sc">:</span>units,</span>
<span id="cb305-3"><a href="multi.html#cb305-3" tabindex="-1"></a>    <span class="at">data =</span> bioChemists, <span class="at">prior =</span> prior.m5d<span class="fl">.1</span>, <span class="at">family =</span> <span class="st">&quot;hupoisson&quot;</span>)</span></code></pre></div>
<p>Plotting the Markov chain for the equivalent parameters that were plotted for the ZIP model shows that the mixing properties are much better (compare Figure <a href="multi.html#fig:ZIP">7.16</a> with Figure <a href="multi.html#fig:HU">7.18</a>).</p>
<div class="figure"><span style="display:block;" id="fig:HU"></span>
<img src="_bookdown_files/fig/HU-1.png" alt="Posterior distribution of fixed effects from model `m5d.3` in which trait 1 ($\texttt{art}$) is the zero-truncated Poisson process and trait 2 ($\texttt{hu.art}$) is the binary trait zero or non-zero." width="672" />
<p class="caption">
Figure 7.18: Posterior distribution of fixed effects from model <code>m5d.3</code> in which trait 1 (<span class="math inline">\(\texttt{art}\)</span>) is the zero-truncated Poisson process and trait 2 (<span class="math inline">\(\texttt{hu.art}\)</span>) is the binary trait zero or non-zero.
</p>
</div>
<p>The interpretation of the model is slightly different. Fitting just an intercept in the hurdle model implies that the proportion of zeros observed across different combinations of those fixed effects fitted for the Poisson process is constant. Our 95% credible intervals for this proportion is (See section <a href="#pred-sec"><strong>??</strong></a>):</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="multi.html#cb306-1" tabindex="-1"></a>c2 <span class="ot">&lt;-</span> (<span class="dv">16</span> <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="dv">3</span>)<span class="sc">/</span>(<span class="dv">15</span> <span class="sc">*</span> pi))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb306-2"><a href="multi.html#cb306-2" tabindex="-1"></a><span class="fu">HPDinterval</span>(<span class="fu">plogis</span>(m5d<span class="fl">.3</span><span class="sc">$</span>Sol[, <span class="dv">2</span>]<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> c2)))</span></code></pre></div>
<pre><code>##          lower     upper
## var1 0.2669255 0.3255151
## attr(,&quot;Probability&quot;)
## [1] 0.95</code></pre>
<p>and we can compare this to the predicted number of zero’s from the Poisson process if it had not been zero-truncated:</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="multi.html#cb308-1" tabindex="-1"></a><span class="fu">HPDinterval</span>(<span class="fu">ppois</span>(<span class="dv">0</span>, <span class="fu">exp</span>(m5d<span class="fl">.3</span><span class="sc">$</span>Sol[, <span class="dv">1</span>] <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> m5d<span class="fl">.3</span><span class="sc">$</span>VCV[, <span class="dv">1</span>])))</span></code></pre></div>
<pre><code>##          lower     upper
## var1 0.1359227 0.3528413
## attr(,&quot;Probability&quot;)
## [1] 0.95</code></pre>
<p>The credible intervals largely overlap, strongly suggesting a standard Poisson model would be adequate. However, our prediction for the number of zero’s that would arise form a non-truncated Poisson process only involved the intercept term. This prediction therefore pertains to the number of articles published by single women with no young children who obtained their Ph.D’s from departments scoring zero for prestige (<code>phd</code>) and whose mentors had published nothing in the previous 3 years. Our equivalent prediction for men is a little lower</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="multi.html#cb310-1" tabindex="-1"></a><span class="fu">HPDinterval</span>(<span class="fu">ppois</span>(<span class="dv">0</span>, <span class="fu">exp</span>(m5d<span class="fl">.3</span><span class="sc">$</span>Sol[, <span class="dv">1</span>] <span class="sc">+</span> m5d<span class="fl">.3</span><span class="sc">$</span>Sol[, <span class="dv">3</span>] <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> m5d<span class="fl">.3</span><span class="sc">$</span>VCV[, <span class="dv">1</span>])))</span></code></pre></div>
<pre><code>##           lower     upper
## var1 0.09385229 0.2910297
## attr(,&quot;Probability&quot;)
## [1] 0.95</code></pre>
<p>suggesting that perhaps the number of zero’s is greater than we expected for this group. However, this may just be a consequence of us fixing the proportion of zero’s to be constant across these groups. We can relax this assumption by fitting a separate term for the proportion of zeros for men:</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="multi.html#cb312-1" tabindex="-1"></a>m5d<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(art <span class="sc">~</span> trait <span class="sc">-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)<span class="sc">:</span>fem <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>mar <span class="sc">+</span></span>
<span id="cb312-2"><a href="multi.html#cb312-2" tabindex="-1"></a>    <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>kid5 <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>phd <span class="sc">+</span> <span class="fu">at.level</span>(trait, <span class="dv">1</span>)<span class="sc">:</span>ment, <span class="at">rcov =</span> <span class="sc">~</span><span class="fu">idh</span>(trait)<span class="sc">:</span>units,</span>
<span id="cb312-3"><a href="multi.html#cb312-3" tabindex="-1"></a>    <span class="at">data =</span> bioChemists, <span class="at">prior =</span> prior.m5d<span class="fl">.1</span>, <span class="at">family =</span> <span class="st">&quot;hupoisson&quot;</span>)</span></code></pre></div>
<p>which reveals that although this proportion is expected to be (slightly) smaller:</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="multi.html#cb313-1" tabindex="-1"></a><span class="fu">HPDinterval</span>(<span class="fu">plogis</span>((m5d<span class="fl">.4</span><span class="sc">$</span>Sol[, <span class="dv">2</span>] <span class="sc">+</span> m5d<span class="fl">.4</span><span class="sc">$</span>Sol[, <span class="dv">4</span>])<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> c2)))</span></code></pre></div>
<pre><code>##          lower     upper
## var1 0.2312673 0.3072587
## attr(,&quot;Probability&quot;)
## [1] 0.95</code></pre>
<p>the proportion of zeros expected for men is probably still less than what we expect from a non-truncated Poisson process for which the estimates have changed very little:</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="multi.html#cb315-1" tabindex="-1"></a><span class="fu">HPDinterval</span>(<span class="fu">ppois</span>(<span class="dv">0</span>, <span class="fu">exp</span>(m5d<span class="fl">.4</span><span class="sc">$</span>Sol[, <span class="dv">1</span>] <span class="sc">+</span> m5d<span class="fl">.4</span><span class="sc">$</span>Sol[, <span class="dv">3</span>] <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> m5d<span class="fl">.4</span><span class="sc">$</span>VCV[, <span class="dv">1</span>])))</span></code></pre></div>
<pre><code>##           lower    upper
## var1 0.07276588 0.248731
## attr(,&quot;Probability&quot;)
## [1] 0.95</code></pre>
<p>This highlights one of the disadvantages of hurdle models. If explanatory variables have been fitted that affect the expectation of the Poisson process then this implies that the proportion of zero’s observed will also vary across these same explanatory variables, even in the absence of zero-inflation. It may then be necessary to fit an equally complicated model for both processes even though a single parameter would suffice in a ZIP model. However, in the absence of zero-inflation the intercept of the zero-inflation process in a ZIP model is <span class="math inline">\(-\infty\)</span> on the logit scale causing numerical and inferential problems. An alternative type of model are zero-altered models.</p>
</div>
<div id="ZAP" class="section level2 hasAnchor" number="7.9">
<h2><span class="header-section-number">7.9</span> Zero-altered Models<a href="multi.html#ZAP" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Zero-altered Poisson (ZAP) models are identical to Poisson-hurdle models except a complementary log-log link is used instead of the logit link when modelling the proportion of zeros. However for reasons that will become clearer below, the zero-altered process (<code>za</code>) is predicting non-zeros as opposed to the ZIP and hurdle-Poisson models where it is
the number of zeros. The likelihood is:</p>
<p><span class="math display">\[\begin{array}{rl}
Pr(y=0) =&amp; 1-\texttt{pexp}(\texttt{exp}(l_{2}))\\
Pr(y | y&gt;0) =&amp; \texttt{pexp}(\texttt{exp}(l_{2}))\ast \texttt{dpois}(y, \texttt{exp}(l_{1}))/(1-\texttt{ppois}(0, \texttt{exp}(l_{1})))\\
\end{array}\]</span></p>
<p>since the inverse of the complementary log-log transformation is the distribution function of the extreme value (log-exponential) distribution.</p>
<p>It happens that <span class="math inline">\(\texttt{ppois}(0,\texttt{exp}(l)) = \texttt{dpois}(0,\texttt{exp}(l)) = 1-\texttt{pexp}(\texttt{exp}(l))\)</span>
so that if <span class="math inline">\(l = l_{1} = l_{2}\)</span> then the likelihood reduces to:</p>
<p><span class="math display">\[\begin{array}{rl}
Pr(y=0) =&amp; \texttt{dpois}(0,\texttt{exp}(l))\\
Pr(y | y&gt;0) =&amp; \texttt{dpois}(y, \texttt{exp}(l))\\
\end{array}\]</span></p>
<p>which is equivalent to a standard Poisson model.</p>
<p>We can then test for zero-flation by constraining the overdispersion to be the same for both process using a <code>trait</code> by <code>units</code> interaction in the R-structure, and by setting up the contrasts so that the zero-altered regression coefficients are expressed as differences from the Poisson regression coefficients. When this difference is zero the variable causes no zero-flation, when it is negative it causes zero-inflation and when it is positive it causes zero-deflation:</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="multi.html#cb317-1" tabindex="-1"></a>m5d<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">MCMCglmm</span>(art <span class="sc">~</span> trait <span class="sc">*</span> (fem <span class="sc">+</span> mar <span class="sc">+</span> kid5 <span class="sc">+</span> phd <span class="sc">+</span> ment), <span class="at">rcov =</span> <span class="sc">~</span>trait<span class="sc">:</span>units,</span>
<span id="cb317-2"><a href="multi.html#cb317-2" tabindex="-1"></a>    <span class="at">data =</span> bioChemists, <span class="at">family =</span> <span class="st">&quot;zapoisson&quot;</span>)</span>
<span id="cb317-3"><a href="multi.html#cb317-3" tabindex="-1"></a><span class="fu">summary</span>(m5d<span class="fl">.5</span>)</span></code></pre></div>
<pre><code>## 
##  Iterations = 3001:12991
##  Thinning interval  = 10
##  Sample size  = 1000 
## 
##  DIC: 3038.879 
## 
##  R-structure:  ~trait:units
## 
##             post.mean l-95% CI u-95% CI eff.samp
## trait:units    0.3644   0.2541   0.4827    50.15
## 
##  Location effects: art ~ trait * (fem + mar + kid5 + phd + ment) 
## 
##                        post.mean  l-95% CI  u-95% CI eff.samp  pMCMC    
## (Intercept)             0.336746 -0.002718  0.644566    272.8  0.044 *  
## traitza_art            -0.527132 -1.109418  0.010963    189.4  0.058 .  
## femWomen               -0.201442 -0.367876 -0.044271    350.2  0.006 ** 
## marMarried              0.078166 -0.118030  0.262194    262.6  0.402    
## kid5                   -0.125775 -0.264035 -0.005271    199.9  0.066 .  
## phd                     0.017631 -0.068209  0.096252    307.5  0.692    
## ment                    0.019415  0.012902  0.027132    500.3 &lt;0.001 ***
## traitza_art:femWomen    0.048930 -0.220809  0.288344    216.1  0.720    
## traitza_art:marMarried  0.141315 -0.171269  0.475263    201.6  0.376    
## traitza_art:kid5       -0.080008 -0.266962  0.128955    181.7  0.424    
## traitza_art:phd         0.007655 -0.137684  0.129547    227.9  0.928    
## traitza_art:ment        0.028197  0.013272  0.044048    140.1 &lt;0.001 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>we can see from this that the more papers a mentor produces, the more zero-deflation (or conversely the less papers a mentor produces, the more zero-inflation).</p>

</div>
</div>
<h3> References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Bunch.1991" class="csl-entry">
Bunch, D. S. 1991. <span>“Estimability in the Multinomial Probit Model.”</span> <em>Transportation Research Part B-Methodological</em> 25 (1): 1–12.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="29">
<li id="fn29"><p>If the model has &gt;2 responses and you want to regress response <span class="math inline">\(\texttt{i}\)</span> effects on the remainder (i.e. a multiple regression), the coefficients can be obtained as <code>solve(V[-i,-i], V[i,-i])</code> where <span class="math inline">\(\texttt{V}\)</span> is the (co)variance matrix of effects.<a href="multi.html#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>We could also have parameterised the model directly as a regression using <span class="math inline">\(\texttt{ante1(trait):id}\)</span> <span class="math inline">\(\texttt{ante1(trait):units}\)</span> - see Section <a href="cont-int.html#ante-sec">6.5</a>.<a href="multi.html#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p>If we had an additional covariate, let’s say <span class="math inline">\(\texttt{rain}\)</span>, we can also obtain the <span class="math inline">\(\texttt{units}\)</span> variance had we fitted both <span class="math inline">\(\texttt{rain}\)</span> and <span class="math inline">\(\texttt{ice}\)</span>. Define <span class="math inline">\({\bf c}\)</span> as the <span class="math inline">\(2\times 1\)</span> vector of residual covariances between road accidents and the weather variables and <span class="math inline">\({\bf V}\)</span> as the <span class="math inline">\(2\times 2\)</span> residual covariance matrix for the weather variables. Then <span class="math inline">\(\sigma^2_\texttt{traity|weather.unit} = \sigma^2_\texttt{traity.unit}-{\bf c}^{\top}{\bf V}^{-1}{\bf c}\)</span>.<a href="multi.html#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p>For a <span class="math inline">\(2\times 2\)</span> covariance matrix, positive-definitness requires both variances to be positive and the correlation to lie between -1 and 1. For covariance matrices of larger dimension, the conditions for positive-definitness are more complicated. Perhaps the simplest definition is that all eigenvalues are positive. The function <span class="math inline">\(\textttt{posterior.evals}\)</span> returns the posterior distribution of the <span class="math inline">\(k\)</span> eigenvalues given the posterior samples of a <span class="math inline">\(k\)</span> dimensional covariance matrix (obtained for the appropriate <span class="math inline">\(k^2\)</span> columns of the <span class="math inline">\(\texttt{VCV}\)</span> element of the <span class="math inline">\(\texttt{MCMCglmm}\)</span> model object.)<a href="multi.html#fnref32" class="footnote-back">↩︎</a></p></li>
<li id="fn33"><p><span class="math inline">\(\texttt{at.level}\)</span> takes the name of categorical variable together with a vector of specified levels. It creates an <span class="math inline">\(n\times k\)</span> incidence matrix where <span class="math inline">\(n\)</span> is the length of the categorical variable and <span class="math inline">\(k\)</span> the number of specified levels. The matrix element <span class="math inline">\(ij\)</span> has a one if the categorical variable for observation <span class="math inline">\(i\)</span>is of level <span class="math inline">\(j\)</span>, and zero otherwise. When <span class="math inline">\(\texttt{at.level}\)</span> is used in a model formula, and interacted with other terms, it restricts those terms to only having effects when the observations are associated with the <span class="math inline">\(k\)</span> specified levels. For example, imagine a categorical variable <span class="math inline">\(\texttt{fac}\)</span> with three levels <span class="math inline">\(\texttt{a}\)</span>, <span class="math inline">\(\texttt{b}\)</span>, and <span class="math inline">\(\texttt{c}\)</span> and a continuous variable <span class="math inline">\(\texttt{x}\)</span>. <span class="math inline">\(\texttt{at.level(fac, c(&quot;a&quot;, &quot;c&quot;)):x}\)</span> would fit two effects - an effect of <span class="math inline">\(x\)</span> when <span class="math inline">\(\texttt{fac}=\texttt{a}\)</span> and an effect of <span class="math inline">\(x\)</span> when <span class="math inline">\(\texttt{fac}=\texttt{c}\)</span>. <span class="math inline">\(\texttt{at.set}\)</span> is similar although it creates an <span class="math inline">\(n\times 1\)</span> incidence matrix where element <span class="math inline">\(i\)</span> is one if the categorical variable for observation <span class="math inline">\(i\)</span> is <em>any</em> of the specified levels. The term <span class="math inline">\(\texttt{at.set(fac, c(&quot;a&quot;, &quot;c&quot;)):x}\)</span> would then fit <em>one</em> effect - the effect of <span class="math inline">\(x\)</span> when <span class="math inline">\(\texttt{fac}\)</span> is equal to <span class="math inline">\(\texttt{a}\)</span> <em>or</em> <span class="math inline">\(\texttt{c}\)</span>.<a href="multi.html#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>For more complicated models a (co)variance matrix may be estimated for a particular random component rather than just a single variance as here. In such cases, <code>V</code> is a matrix. The value at which (part of) the (co)variance matrix is fixed at is determined by <code>V</code>. Any elements of the covariance matrix in rows and/or columns equal to or greater than <code>fix</code> are fixed. In the case of a single variance <code>fix=1</code> simply fixes the variance (element 1,1 of the (co)variance matrix) at whatever is specified in <code>V</code> (one in this example).<a href="multi.html#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>Obtaining this expression is involved. We can express the expected value of <span class="math inline">\(y\)</span> given <span class="math inline">\(l\)</span> is less than, or greater than, some value <span class="math inline">\(c\)</span> using the law of total expectation</p>
<p><span class="math display">\[E[y | l&gt;c] = E[E[y|l] | l&gt;c]\]</span></p>
<p>and</p>
<p><span class="math display">\[E[y | l&lt;c] = E[E[y|l] | l&lt;c]\]</span></p>
<p><span class="math inline">\(E[y|l]\)</span> is the mean of a conditional normal which has a well known form: <span class="math inline">\(\mu_y+\frac{\sigma_{y,l}}{\sigma^2_{l}}(l-\mu_l)\)</span>. The expectation of this when <span class="math inline">\(l&gt;c\)</span> is then <span class="math inline">\(\mu_y+\frac{\sigma_{y,l}}{\sigma^2_{l}}(E[l|l&gt;c]-\mu_l)\)</span>. <span class="math inline">\(E[l|l&gt;c]\)</span> can be obtained using the inverse Mills ratio:</p>
<p><span class="math display">\[E[l|l&gt;c] = \mu_l + \sigma_{l}\frac{f_N(\alpha)}{(1 - F_N(\alpha))}\]</span></p>
<p>and when <span class="math inline">\(l&lt;c\)</span> we have</p>
<p><span class="math display">\[E[l|l&lt;c] = \mu_l - \sigma_{l}\frac{f_N(\alpha)}{F_N(\alpha)}\]</span></p>
where <span class="math inline">\(f_N\)</span> and <span class="math inline">\(F_N\)</span> are the density and cumulative density functions for the unit normal, and <span class="math inline">\(\alpha = \mu_l/\sigma_{l}\)</span>. Code for obtaining <span class="math inline">\(E[y | l&gt;c]\)</span> and <span class="math inline">\(E[y | l&gt;c]\)</span> can be found
<details>
<summary>
here
</summary>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="#cb250-1" tabindex="-1"></a>condE <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, V, <span class="at">c =</span> <span class="dv">0</span>, <span class="at">greater =</span> <span class="cn">TRUE</span>) {</span>
<span id="cb250-2"><a href="#cb250-2" tabindex="-1"></a></span>
<span id="cb250-3"><a href="#cb250-3" tabindex="-1"></a>    <span class="co"># A bivariate normal with mean vector mu and covariance matrix V is</span></span>
<span id="cb250-4"><a href="#cb250-4" tabindex="-1"></a>    <span class="co"># assumed.  condE give expectation of 1st variable given 2nd variable is &gt;</span></span>
<span id="cb250-5"><a href="#cb250-5" tabindex="-1"></a>    <span class="co"># c (greater=TRUE) or &lt; c (greater=FALSE)</span></span>
<span id="cb250-6"><a href="#cb250-6" tabindex="-1"></a></span>
<span id="cb250-7"><a href="#cb250-7" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">nrow</span>(V) <span class="sc">!=</span> <span class="fu">ncol</span>(V) <span class="sc">|</span> <span class="fu">nrow</span>(V) <span class="sc">!=</span> <span class="dv">2</span>) {</span>
<span id="cb250-8"><a href="#cb250-8" tabindex="-1"></a>        <span class="fu">stop</span>(<span class="st">&quot;V should be a 2x2 matrix&quot;</span>)</span>
<span id="cb250-9"><a href="#cb250-9" tabindex="-1"></a>    }</span>
<span id="cb250-10"><a href="#cb250-10" tabindex="-1"></a></span>
<span id="cb250-11"><a href="#cb250-11" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">length</span>(mu) <span class="sc">!=</span> <span class="dv">2</span>) {</span>
<span id="cb250-12"><a href="#cb250-12" tabindex="-1"></a>        <span class="fu">stop</span>(<span class="st">&quot;mu should be length 2&quot;</span>)</span>
<span id="cb250-13"><a href="#cb250-13" tabindex="-1"></a>    }</span>
<span id="cb250-14"><a href="#cb250-14" tabindex="-1"></a></span>
<span id="cb250-15"><a href="#cb250-15" tabindex="-1"></a>    alpha <span class="ot">&lt;-</span> (c <span class="sc">-</span> mu[<span class="dv">2</span>])<span class="sc">/</span><span class="fu">sqrt</span>(V[<span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb250-16"><a href="#cb250-16" tabindex="-1"></a></span>
<span id="cb250-17"><a href="#cb250-17" tabindex="-1"></a>    <span class="cf">if</span> (greater) {</span>
<span id="cb250-18"><a href="#cb250-18" tabindex="-1"></a>        lambda <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(alpha)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(alpha))</span>
<span id="cb250-19"><a href="#cb250-19" tabindex="-1"></a>        <span class="co"># inverse Mills ratio</span></span>
<span id="cb250-20"><a href="#cb250-20" tabindex="-1"></a>        expectation <span class="ot">&lt;-</span> mu[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">sqrt</span>(V[<span class="dv">2</span>, <span class="dv">2</span>]) <span class="sc">*</span> lambda</span>
<span id="cb250-21"><a href="#cb250-21" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb250-22"><a href="#cb250-22" tabindex="-1"></a>        lambda <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(alpha)<span class="sc">/</span><span class="fu">pnorm</span>(alpha)</span>
<span id="cb250-23"><a href="#cb250-23" tabindex="-1"></a>        expectation <span class="ot">&lt;-</span> mu[<span class="dv">2</span>] <span class="sc">-</span> <span class="fu">sqrt</span>(V[<span class="dv">2</span>, <span class="dv">2</span>]) <span class="sc">*</span> lambda</span>
<span id="cb250-24"><a href="#cb250-24" tabindex="-1"></a>    }</span>
<span id="cb250-25"><a href="#cb250-25" tabindex="-1"></a>    <span class="co"># Expectation that E[l|l&gt;0] or E[l|l&lt;0]</span></span>
<span id="cb250-26"><a href="#cb250-26" tabindex="-1"></a></span>
<span id="cb250-27"><a href="#cb250-27" tabindex="-1"></a>    expectation <span class="ot">&lt;-</span> mu[<span class="dv">1</span>] <span class="sc">+</span> (expectation <span class="sc">-</span> mu[<span class="dv">2</span>]) <span class="sc">*</span> V[<span class="dv">1</span>, <span class="dv">2</span>]<span class="sc">/</span>V[<span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb250-28"><a href="#cb250-28" tabindex="-1"></a>    <span class="co"># Expectation of x given l|l&gt;0.</span></span>
<span id="cb250-29"><a href="#cb250-29" tabindex="-1"></a></span>
<span id="cb250-30"><a href="#cb250-30" tabindex="-1"></a>    <span class="co"># The whole thing simplifies to mu[1] \pm lambda*V[1,2]/sqrt(V[2,2]) but</span></span>
<span id="cb250-31"><a href="#cb250-31" tabindex="-1"></a>    <span class="co"># easier to see the logic without the simplification</span></span>
<span id="cb250-32"><a href="#cb250-32" tabindex="-1"></a></span>
<span id="cb250-33"><a href="#cb250-33" tabindex="-1"></a>    <span class="fu">return</span>(expectation)</span>
<span id="cb250-34"><a href="#cb250-34" tabindex="-1"></a>}</span></code></pre></div>
</details>
<p><br><a href="multi.html#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p>I should really have an na.option in the call to <span class="math inline">\(\texttt{MCMCglmm}\)</span> that simply ignores missing values in the wide-format.<a href="multi.html#fnref36" class="footnote-back">↩︎</a></p></li>
<li id="fn37"><p>Obtaining comparable regression coefficients between the single and multi-response models is fairly involved. The reason for this is that the standard single-response probit model assumes a <span class="math inline">\(\texttt{units}\)</span> variance of one after conditioning on the predictors, yet the multiple-response model assumes a <span class="math inline">\(\texttt{units}\)</span> variance of one before conditioning on the predictors. Nevertheless, we can easily move between the two parameterisations. As detailed at the start of this Chapter and in the footnote[^schur], the $ variance for death after conditioning on the <span class="math inline">\(\texttt{id}\)</span> effects for <span class="math inline">\(log(\texttt{bili})\)</span> is <span class="math inline">\(V_{2|1}=V_{2,2}-V_{1,2}^2/V_{1,1}\)</span> where <span class="math inline">\({\bf V}\)</span> is the covariance matrix. As covered in Section <a href="glm.html#bernoulli-sec">3.6.3</a> and in footnote[^3.5] we can then rescale the regression coefficient from the multi-response model by <span class="math inline">\(\sqrt{2/(1+V_{2|1})}\)</span> to obtain the value we get if we could have set <span class="math inline">\(V_{2|1}=1\)</span> as in the single-response model.<a href="multi.html#fnref37" class="footnote-back">↩︎</a></p></li>
<li id="fn38"><p>An identity matrix has ones along the diagonal and zero’s on the off-diagonals. A unit matrix is a matrix of all ones.<a href="multi.html#fnref38" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="cont-int.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pedigree.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["MCMCglmm-course-notes.pdf", "MCMCglmm-course-notes.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
